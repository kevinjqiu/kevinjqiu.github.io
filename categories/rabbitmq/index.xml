<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Rabbitmq on Qiu&#39;s Quibble</title>
    <link>http://blog.idempotent.ca/categories/rabbitmq/</link>
    <description>Recent content in Rabbitmq on Qiu&#39;s Quibble</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Thu, 30 Apr 2015 00:37:42 -0400</lastBuildDate>
    <atom:link href="http://blog.idempotent.ca/categories/rabbitmq/index.xml" rel="self" type="application/rss+xml" />
    
    <item>
      <title>Use rabbitmq DLX to implement delayed retry</title>
      <link>http://blog.idempotent.ca/2015/04/30/use-rabbitmq-dlx-to-implement-delayed-retry/</link>
      <pubDate>Thu, 30 Apr 2015 00:37:42 -0400</pubDate>
      
      <guid>http://blog.idempotent.ca/2015/04/30/use-rabbitmq-dlx-to-implement-delayed-retry/</guid>
      <description>

&lt;p&gt;In this post, I&amp;rsquo;m going to describe the experience at &lt;code&gt;$DAYJOB&lt;/code&gt; regarding implementing delayed retry using &lt;a href=&#34;https://www.rabbitmq.com/&#34;&gt;rabbitmq&lt;/a&gt;&amp;rsquo;s &lt;a href=&#34;https://www.rabbitmq.com/dlx.html&#34;&gt;DLX&lt;/a&gt; combined with a TTL. The technique has been described at a few &lt;a href=&#34;http://yuserinterface.com/dev/2013/01/08/how-to-schedule-delay-messages-with-rabbitmq-using-a-dead-letter-exchange/&#34;&gt;places&lt;/a&gt; but it is new to me personally and our company. I&amp;rsquo;d like to capture the experience we had both in implementing and in deploying to production.&lt;/p&gt;

&lt;h1 id=&#34;the-problem:f116081bb98b0fd4ebe93c08e96b2c34&#34;&gt;The problem&lt;/h1&gt;

&lt;p&gt;At &lt;code&gt;$DAYJOB&lt;/code&gt; we have a service that integrates with a 3rd-party API that processes credit card payments and when successful, records a payment object on our customer&amp;rsquo;s invoices, and change the invoice status. Pretty straight-forward stuff. However, lately we&amp;rsquo;ve been experiencing an elevated amount of random failures from our service provider.&lt;/p&gt;

&lt;p&gt;Calls to our provider to create a checkout using the client&amp;rsquo;s credit card information would time out randomly, or return an &amp;ldquo;unknown error&amp;rdquo;. When it happens, we don&amp;rsquo;t record a payment object on the invoice since we don&amp;rsquo;t know the actual status of the checkout, nor do we have the &lt;code&gt;reference_id&lt;/code&gt; for the checkout. However, as we discovered, some of these timed-out calls did go through and the clients&amp;rsquo; credit cards charged.&lt;/p&gt;

&lt;p&gt;We checked with our service provider and were told that they have been experiencing increased volumes and their infrastructure currently can&amp;rsquo;t keep up. However, they suggest that we use an undocumented feature which allows a &lt;code&gt;unique_id&lt;/code&gt; to be passed in along with the checkout call. The &lt;code&gt;unique_id&lt;/code&gt; serves as an idempotent key (similar to &lt;a href=&#34;https://stripe.com/docs/api?lang=curl#idempotent_requests&#34;&gt;Stripe&amp;rsquo;s&lt;/a&gt;). Multiple calls with the same &lt;code&gt;unique_id&lt;/code&gt; won&amp;rsquo;t create multiple checkout objects on their end and thus ensuring the checkout is made but won&amp;rsquo;t double/triple charge the customer&amp;rsquo;s car.&lt;/p&gt;

&lt;h1 id=&#34;architecting-the-solution:f116081bb98b0fd4ebe93c08e96b2c34&#34;&gt;Architecting the solution&lt;/h1&gt;

&lt;p&gt;Armed with this new secret API feature, our team goes back to the drawing board. At work, we use &lt;a href=&#34;https://www.rabbitmq.com/&#34;&gt;rabbitmq&lt;/a&gt; extensively for asynchronous processing. If some operation doesn&amp;rsquo;t have to be carried out synchronously with a web request, we throw a message on the queue and have a queue consumer process that message and update states. We use a library called &lt;a href=&#34;https://github.com/ojacobson/sparkplug&#34;&gt;sparkplug&lt;/a&gt; that makes writing queue consumer super-easy. So, everything seems to fall in friendly terrotiries: we make a checkout call with a random id and when we encounter timeout or unknown error, instead of returning an error response to the user, we return &lt;code&gt;202 Accepted&lt;/code&gt; to our user and throw a message on the queue, so a consumer can grab it and retry the checkout with the same original &lt;code&gt;unique_id&lt;/code&gt;.&lt;/p&gt;

&lt;h1 id=&#34;the-missing-piece:f116081bb98b0fd4ebe93c08e96b2c34&#34;&gt;The missing piece&lt;/h1&gt;

&lt;p&gt;However, we quickly realized it&amp;rsquo;s not that simple. What if the retry encountered the same error? We can put it back on the queue, but when does it get processed by the consumer again? We want to add a time delay to the subsequent retries, and the orginal retry as well.&lt;/p&gt;

&lt;h1 id=&#34;dead-letter-exchange-https-www-rabbitmq-com-dlx-html-and-ttl-https-www-rabbitmq-com-ttl-html:f116081bb98b0fd4ebe93c08e96b2c34&#34;&gt;&lt;a href=&#34;https://www.rabbitmq.com/dlx.html&#34;&gt;Dead-Letter-Exchange&lt;/a&gt; and &lt;a href=&#34;https://www.rabbitmq.com/ttl.html&#34;&gt;TTL&lt;/a&gt;&lt;/h1&gt;

&lt;p&gt;After some research on the internet, seems like this problem has been &lt;a href=&#34;https://www.cloudamqp.com/docs/delayed-messages.html&#34;&gt;solved&lt;/a&gt; &lt;a href=&#34;http://yuserinterface.com/dev/2013/01/08/how-to-schedule-delay-messages-with-rabbitmq-using-a-dead-letter-exchange/&#34;&gt;before&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;The idea here is that you have two queues: &lt;code&gt;Qa&lt;/code&gt; and &lt;code&gt;Qb&lt;/code&gt;.  When a checkout request times out, we put a message on a &lt;code&gt;Qa&lt;/code&gt;.  &lt;code&gt;Qa&lt;/code&gt; is declared with &lt;code&gt;x-dead-letter-exchange&lt;/code&gt;, &lt;code&gt;x-dead-letter-routing-key&lt;/code&gt; and &lt;code&gt;x-message-ttl&lt;/code&gt; (in milliseconds).  When the message is in &lt;code&gt;Qa&lt;/code&gt; for &lt;code&gt;ttl&lt;/code&gt; milliseconds, the message will be re-routed to the specified dead-letter-exchange with the routing key.  We can bind &lt;code&gt;Qb&lt;/code&gt; to the exchange with the routing key, and attach a consumer to only &lt;code&gt;Qb&lt;/code&gt; and retry the checkout call.&lt;/p&gt;

&lt;p&gt;If the retry call fails for the same reason (timeout or unknown error), we re-publish the message to &lt;code&gt;Qa&lt;/code&gt; again and acknowledges the message so it&amp;rsquo;s no longer in &lt;code&gt;Qb&lt;/code&gt;.&lt;/p&gt;


&lt;figure &gt;
    
        &lt;img src=&#34;http://blog.idempotent.ca/images/dlx_1.png&#34; /&gt;
    
    
    &lt;figcaption&gt;
        &lt;h4&gt;Flow diagram&lt;/h4&gt;
        
    &lt;/figcaption&gt;
    
&lt;/figure&gt;


&lt;p&gt;The whole flow looks like this:&lt;/p&gt;


&lt;figure &gt;
    
        &lt;img src=&#34;http://blog.idempotent.ca/images/dlx_2.png&#34; /&gt;
    
    
    &lt;figcaption&gt;
        &lt;h4&gt;Flow diagram&lt;/h4&gt;
        
    &lt;/figcaption&gt;
    
&lt;/figure&gt;


&lt;h1 id=&#34;implementation-testing-strategy-and-deployment-saga:f116081bb98b0fd4ebe93c08e96b2c34&#34;&gt;Implementation, Testing Strategy and Deployment saga&lt;/h1&gt;

&lt;h2 id=&#34;implementation:f116081bb98b0fd4ebe93c08e96b2c34&#34;&gt;Implementation&lt;/h2&gt;

&lt;p&gt;Implementation is probably the most straight-forward phase of the project once we have the design on paper.  The only obstacle is that the library we use for writing rabbitmq consumers (sparkplug) does not support declaring queues with extra parameters, and the DLX related parameters: &lt;code&gt;x-dead-letter-exchange&lt;/code&gt; &lt;code&gt;x-dead-letter-routing-key&lt;/code&gt;, and &lt;code&gt;x-message-ttl&lt;/code&gt; are all &amp;ldquo;extra parameters&amp;rdquo; according to &lt;code&gt;amqplib&lt;/code&gt;, which is used by sparkplug. To solve this, I sent this &lt;a href=&#34;https://github.com/ojacobson/sparkplug/pull/10/files&#34;&gt;PR&lt;/a&gt; to sparkplug, so it recognizes extra parameters and pass them down to amqp library.&lt;/p&gt;

&lt;p&gt;Another road block appeared when we ran the system on our dev images for the first time. The underlying amqplib would error out on startup. Upon closer investigation, it appeared the error happened while talking to rabbitmq and the amqplib can&amp;rsquo;t handle certain rabbitmq frames. So I went searching for the amqp project, only to find out that it was deprecated &lt;a href=&#34;https://pypi.python.org/pypi/amqplib&#34;&gt;long ago&lt;/a&gt;. Fortunately, there&amp;rsquo;s a fork of the library &lt;a href=&#34;https://pypi.python.org/pypi/amqp&#34;&gt;amqp&lt;/a&gt; that&amp;rsquo;s maintained by the reputable &lt;a href=&#34;http://www.celeryproject.org/&#34;&gt;Celery project&lt;/a&gt;. It&amp;rsquo;s has API compatibility with amqplib and appeared to be a drop-in replacement. We dropped it in and everything seems to work. Reading the online literature, it seems to be the case that the old library does not handle the &lt;code&gt;TTL&lt;/code&gt; amqp extension.&lt;/p&gt;

&lt;h2 id=&#34;testing-strategy:f116081bb98b0fd4ebe93c08e96b2c34&#34;&gt;Testing Strategy&lt;/h2&gt;

&lt;p&gt;So, since the 3rd party API timeout is an edge case, they did not provide a way trigger this behaviour the same way we can trigger, say, a declined transaction. We could fake the URL for the 3rd party service in DNS or &lt;code&gt;/etc/hosts&lt;/code&gt; or we can change the SDK to change the base url for their API to somewhere else and cause a timeout that way, but neither is ideal. The biggest disadvantage is that we have no way of getting a request out of the retry state.&lt;/p&gt;

&lt;p&gt;Eventually, we decided to &lt;a href=&#34;http://en.wikipedia.org/wiki/Man-in-the-middle_attack&#34;&gt;MITM&lt;/a&gt; ourselves :) We can write a simple proxy server, and for the most part, it&amp;rsquo;s going to be a pass-through, but on certain requests, we intercept it and return an unknown error (500 series with specific response body).  To trigger it, we set the checkout amount to &lt;code&gt;$666&lt;/code&gt;, and in the proxy, we keep an internal counter based on the checkout&amp;rsquo;s unique id, and increment the counter every time it&amp;rsquo;s retried, and then we can set a max retry threshold in the proxy so the proxy becomes a pass through again if the max retry threshold is reached.&lt;/p&gt;

&lt;p&gt;We used this small nifty library &lt;a href=&#34;https://github.com/allfro/pymiproxy&#34;&gt;pymiproxy&lt;/a&gt; as a base for our proxy server. It turns out the proxy is pretty straight-forward as well, and a big shout-out to the author of pymiproxy.&lt;/p&gt;

&lt;h2 id=&#34;deployment:f116081bb98b0fd4ebe93c08e96b2c34&#34;&gt;Deployment&lt;/h2&gt;

&lt;p&gt;Everything until now is like a cake walk. Sure, there are some problems with the underlying libraries but that requires patching but they were quite easy to identify and fix. Deployment, on the other hand, has been like riding on the &lt;a href=&#34;https://www.youtube.com/watch?v=Mgsbau5qkTE&#34;&gt;Behemoth in Canada&amp;rsquo;s Wonderland&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;First of all, while getting the code onto the testing environment, we encountered the first gremlin. The staging is running on the exact same version of rabbitmq and the exact same configuration. However, on staging, when a message is published on the DLQ (&lt;code&gt;Qa&lt;/code&gt;) in our example, after &lt;code&gt;TTL&lt;/code&gt;, the message would simply disappear and did not get routed to &lt;code&gt;Qb&lt;/code&gt;. What&amp;rsquo;s worse, sometimes even &lt;code&gt;Qa&lt;/code&gt; is completely gone after the message is dropped on the floor! This is terribly frustrating. The queue is declared as durable, and so is the exchange. I even did a side-by-side comparison of the sparkplug log output to see if anything is different. Well, there was! The declaration sequence is different between staging and dev. On dev, the dead-letter exchange is declared before &lt;code&gt;Qa&lt;/code&gt; which specifies &lt;code&gt;x-dead-letter-exchange&lt;/code&gt;. That makes sense! Reading the &lt;a href=&#34;https://github.com/ojacobson/sparkplug/blob/master/sparkplug/config/__init__.py#L57-L77&#34;&gt;sparkplug code&lt;/a&gt;, it calculates the dependencies between queues, exchanges, bindings and consumers to determine the order of which they should be declared. However, our modification that enabled sparkplug to pass down DLX, but sparkplug has no idea that the queue depends on the DLX! Based on this observation, I cooked up another &lt;a href=&#34;https://github.com/freshbooks/sparkplug/pull/2/files&#34;&gt;PR&lt;/a&gt; such that if DLX is specified, make sure we make the DLX a dependency of the queue so the exchange gets declared before it. Did a few tests locally, and hey, it appears to be working!&lt;/p&gt;

&lt;p&gt;Just as I thought my shrewed observation has solved this major mystery, the second day, people reported that the queue started go AWOL again! Grumbled, I sat down and read carefully the documentation on &lt;a href=&#34;https://www.rabbitmq.com/dlx.html&#34;&gt;dead-letter exchange&lt;/a&gt; and discovered this:&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;Note that the exchange does not have to be declared when the queue is declared, but it should exist by the time messages need to be dead-lettered; if it is missing then, the messages will be silently dropped.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;This invalidates my previous hypothesis that the out-of order declaration was the root cause of the problem. There we go, I was back to square one.&lt;/p&gt;

&lt;p&gt;At this time, I wanted to try a different approach. Instead of forming hypothesis from observation, I searched for evidence. I went on the server, and start to look at the logs to search for any traces that can be salvaged. The rabbitmq log is very noisy with all the connection messages. Once in a while you get something remotely interesting, but they were not relevant. Then I manually published a message on the queue, and waited for the message and queue to disappear. Lo and behold, there&amp;rsquo;s something in the logs!&lt;/p&gt;

&lt;script src=&#34;//gist.github.com/kevinjqiu/e626bcc40eb803214968.js&#34;&gt;&lt;/script&gt;

&lt;p&gt;There&amp;rsquo;s our smoking gun! Further gooling revealed &lt;a href=&#34;http://lists.rabbitmq.com/pipermail/rabbitmq-discuss/2012-April/019368.html&#34;&gt;this&lt;/a&gt;. That&amp;rsquo;s EXACTLY our issue! And the version of rabbitmq we&amp;rsquo;re using is EXACTLY 2.8.1! What a relief! We just need to upgrade to 2.8.2 and everything would be fine.&lt;/p&gt;

&lt;p&gt;So there I was, preparing an internal repository to host the rpm (since we&amp;rsquo;re on a hopelessly old version of CentOS), and prepared puppet changes for the new version. Deployed on all the environments and sent it off to QA. QA ok&amp;rsquo;ed it just before the weekend and life is good again.&lt;/p&gt;

&lt;p&gt;Except, not at all! There are a few more surprises waiting for us before the end of tunnel. First of all, our partner whose payment API we&amp;rsquo;re integrating has received an imminent DDOS threat, and fearing not having a retry mechanism would caused a huge burden for us and our support crew, we need to get this out to production ASAP. After pulling some levers and convincing our ops team that this is a relatively low risk point release upgrade (from rabbitmq 2.8.1 to 2.8.2), we got the green light and ops are on their way upgrading rabbitmq. Everything seemed to be going alone well, until, when we switched all components to point to the hosts that&amp;rsquo;s on the new rabbitmq, our app stopped working! Phone calls flooded in, alerts set off everywhere and on top of that, even the streets in front of our building had a couple of emergency vehicles passing by! Goodness, what have we done! Ops quickly rolled it back, and we were left dumbfounded by this yet another surprise.&lt;/p&gt;

&lt;p&gt;Analyzing the logs from various components during the downtime, it appeared the components talking to rabbitmq have timed out trying to publish messages. We checked that the hosts can indeed reach each other, all the names can be resolved and firewall rules are not in effect. So, we hit a wall again.&lt;/p&gt;

&lt;p&gt;On the second day, we regrouped, and experimented on the backup data centre. We upgraded, and tried to put a message on the queue, and guess what, it blocked! It&amp;rsquo;s great that we reproduced the issue. Since the staging environment worked just fine, I captured &lt;code&gt;strace&lt;/code&gt; on the staging environment, and ops did the same on prod, and compared the output. It&amp;rsquo;s pretty clear that the process was waiting on reading socket (syscall was &lt;code&gt;recvfrom(...)&lt;/code&gt;) and it blocked. Then I did &lt;code&gt;tcpdump&lt;/code&gt; and compared that with the output on prod, and also proven to be futile.&lt;/p&gt;

&lt;p&gt;In that afternoon, our fortune suddenly took a positive turn, when one of the ops discovered this in the logs while starting the new rabbitmq:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;=INFO REPORT==== 29-Apr-2015::14:51:09 ===
Disk free space limit now exceeded. Free bytes:19033128960 Limit:50634379264
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;So, this version of rabbitmq started to check free disk space, and &lt;strong&gt;blocks&lt;/strong&gt; incoming message if the disk space is deemed inadequate! Wow, this is so unexpected that we all laughed when we discovered this to be the root cause. However, for me, I need to be convinced that why it wasn&amp;rsquo;t an issue for staging environment.&lt;/p&gt;

&lt;p&gt;So I cloned rabbitmq git repository, and looked for anything that&amp;rsquo;s related to &lt;code&gt;disk_free_limit&lt;/code&gt;. Finally, I found this:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-erlang&#34;&gt;{disk_free_limit, {mem_relative, 1.0}},
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;from &lt;a href=&#34;https://github.com/rabbitmq/rabbitmq-server/blob/rabbitmq_v2_8_2/ebin/rabbit_app.in#L22&#34;&gt;here&lt;/a&gt;. Since we&amp;rsquo;re using the default config, this is in effect, and it essentially says &amp;ldquo;stop accepting message if the disk space is not at least as big as the RAM&amp;rdquo;, and it just so happens on prod, we have 50G of RAM and therefore, require at least 50G of free space for rabbitmq to start accepting messages!&lt;/p&gt;

&lt;p&gt;Reading the rabbitmq 2.8.2 release notes, and they &lt;strong&gt;did&lt;/strong&gt; &lt;a href=&#34;https://www.rabbitmq.com/release-notes/README-2.8.2.txt&#34;&gt;mention&lt;/a&gt; this &amp;ldquo;feature&amp;rdquo;, but failed to mention that it could block your connection &lt;strong&gt;forever&lt;/strong&gt; and bring your site down&amp;hellip;&lt;/p&gt;

&lt;h1 id=&#34;conclusion:f116081bb98b0fd4ebe93c08e96b2c34&#34;&gt;Conclusion&lt;/h1&gt;

&lt;p&gt;There you go.  That&amp;rsquo;s our adventure implementing and deploying delayed retry using rabbitmq&amp;rsquo;s DLX and TTL. It&amp;rsquo;s frustrating and rewarding at the same time, and there&amp;rsquo;s definitely something we can all take home with:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Software is hard, even for experienced developers and ops&lt;/li&gt;
&lt;li&gt;Gather all the evidences before forming hypothesis on the root cause&lt;/li&gt;
&lt;li&gt;Certainly, read the docs thoroughly before hypothesizing&lt;/li&gt;
&lt;li&gt;Expect problems when switching environments&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;I haven&amp;rsquo;t been blogging for a while, partly because life catches up, and partly because I&amp;rsquo;ve been less than disciplined but I spent some time writing down this experience worth remembering :)&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Use rabbitmq DLX to implement delayed retry</title>
      <link>http://blog.idempotent.ca/starred/2015-04-30-use-rabbitmq-dlx-to-implement-delayed-retry/</link>
      <pubDate>Thu, 30 Apr 2015 00:37:42 -0400</pubDate>
      
      <guid>http://blog.idempotent.ca/starred/2015-04-30-use-rabbitmq-dlx-to-implement-delayed-retry/</guid>
      <description>

&lt;p&gt;In this post, I&amp;rsquo;m going to describe the experience at &lt;code&gt;$DAYJOB&lt;/code&gt; regarding implementing delayed retry using &lt;a href=&#34;https://www.rabbitmq.com/&#34;&gt;rabbitmq&lt;/a&gt;&amp;rsquo;s &lt;a href=&#34;https://www.rabbitmq.com/dlx.html&#34;&gt;DLX&lt;/a&gt; combined with a TTL. The technique has been described at a few &lt;a href=&#34;http://yuserinterface.com/dev/2013/01/08/how-to-schedule-delay-messages-with-rabbitmq-using-a-dead-letter-exchange/&#34;&gt;places&lt;/a&gt; but it is new to me personally and our company. I&amp;rsquo;d like to capture the experience we had both in implementing and in deploying to production.&lt;/p&gt;

&lt;h1 id=&#34;the-problem:f116081bb98b0fd4ebe93c08e96b2c34&#34;&gt;The problem&lt;/h1&gt;

&lt;p&gt;At &lt;code&gt;$DAYJOB&lt;/code&gt; we have a service that integrates with a 3rd-party API that processes credit card payments and when successful, records a payment object on our customer&amp;rsquo;s invoices, and change the invoice status. Pretty straight-forward stuff. However, lately we&amp;rsquo;ve been experiencing an elevated amount of random failures from our service provider.&lt;/p&gt;

&lt;p&gt;Calls to our provider to create a checkout using the client&amp;rsquo;s credit card information would time out randomly, or return an &amp;ldquo;unknown error&amp;rdquo;. When it happens, we don&amp;rsquo;t record a payment object on the invoice since we don&amp;rsquo;t know the actual status of the checkout, nor do we have the &lt;code&gt;reference_id&lt;/code&gt; for the checkout. However, as we discovered, some of these timed-out calls did go through and the clients&amp;rsquo; credit cards charged.&lt;/p&gt;

&lt;p&gt;We checked with our service provider and were told that they have been experiencing increased volumes and their infrastructure currently can&amp;rsquo;t keep up. However, they suggest that we use an undocumented feature which allows a &lt;code&gt;unique_id&lt;/code&gt; to be passed in along with the checkout call. The &lt;code&gt;unique_id&lt;/code&gt; serves as an idempotent key (similar to &lt;a href=&#34;https://stripe.com/docs/api?lang=curl#idempotent_requests&#34;&gt;Stripe&amp;rsquo;s&lt;/a&gt;). Multiple calls with the same &lt;code&gt;unique_id&lt;/code&gt; won&amp;rsquo;t create multiple checkout objects on their end and thus ensuring the checkout is made but won&amp;rsquo;t double/triple charge the customer&amp;rsquo;s car.&lt;/p&gt;

&lt;h1 id=&#34;architecting-the-solution:f116081bb98b0fd4ebe93c08e96b2c34&#34;&gt;Architecting the solution&lt;/h1&gt;

&lt;p&gt;Armed with this new secret API feature, our team goes back to the drawing board. At work, we use &lt;a href=&#34;https://www.rabbitmq.com/&#34;&gt;rabbitmq&lt;/a&gt; extensively for asynchronous processing. If some operation doesn&amp;rsquo;t have to be carried out synchronously with a web request, we throw a message on the queue and have a queue consumer process that message and update states. We use a library called &lt;a href=&#34;https://github.com/ojacobson/sparkplug&#34;&gt;sparkplug&lt;/a&gt; that makes writing queue consumer super-easy. So, everything seems to fall in friendly terrotiries: we make a checkout call with a random id and when we encounter timeout or unknown error, instead of returning an error response to the user, we return &lt;code&gt;202 Accepted&lt;/code&gt; to our user and throw a message on the queue, so a consumer can grab it and retry the checkout with the same original &lt;code&gt;unique_id&lt;/code&gt;.&lt;/p&gt;

&lt;h1 id=&#34;the-missing-piece:f116081bb98b0fd4ebe93c08e96b2c34&#34;&gt;The missing piece&lt;/h1&gt;

&lt;p&gt;However, we quickly realized it&amp;rsquo;s not that simple. What if the retry encountered the same error? We can put it back on the queue, but when does it get processed by the consumer again? We want to add a time delay to the subsequent retries, and the orginal retry as well.&lt;/p&gt;

&lt;h1 id=&#34;dead-letter-exchange-https-www-rabbitmq-com-dlx-html-and-ttl-https-www-rabbitmq-com-ttl-html:f116081bb98b0fd4ebe93c08e96b2c34&#34;&gt;&lt;a href=&#34;https://www.rabbitmq.com/dlx.html&#34;&gt;Dead-Letter-Exchange&lt;/a&gt; and &lt;a href=&#34;https://www.rabbitmq.com/ttl.html&#34;&gt;TTL&lt;/a&gt;&lt;/h1&gt;

&lt;p&gt;After some research on the internet, seems like this problem has been &lt;a href=&#34;https://www.cloudamqp.com/docs/delayed-messages.html&#34;&gt;solved&lt;/a&gt; &lt;a href=&#34;http://yuserinterface.com/dev/2013/01/08/how-to-schedule-delay-messages-with-rabbitmq-using-a-dead-letter-exchange/&#34;&gt;before&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;The idea here is that you have two queues: &lt;code&gt;Qa&lt;/code&gt; and &lt;code&gt;Qb&lt;/code&gt;.  When a checkout request times out, we put a message on a &lt;code&gt;Qa&lt;/code&gt;.  &lt;code&gt;Qa&lt;/code&gt; is declared with &lt;code&gt;x-dead-letter-exchange&lt;/code&gt;, &lt;code&gt;x-dead-letter-routing-key&lt;/code&gt; and &lt;code&gt;x-message-ttl&lt;/code&gt; (in milliseconds).  When the message is in &lt;code&gt;Qa&lt;/code&gt; for &lt;code&gt;ttl&lt;/code&gt; milliseconds, the message will be re-routed to the specified dead-letter-exchange with the routing key.  We can bind &lt;code&gt;Qb&lt;/code&gt; to the exchange with the routing key, and attach a consumer to only &lt;code&gt;Qb&lt;/code&gt; and retry the checkout call.&lt;/p&gt;

&lt;p&gt;If the retry call fails for the same reason (timeout or unknown error), we re-publish the message to &lt;code&gt;Qa&lt;/code&gt; again and acknowledges the message so it&amp;rsquo;s no longer in &lt;code&gt;Qb&lt;/code&gt;.&lt;/p&gt;


&lt;figure &gt;
    
        &lt;img src=&#34;http://blog.idempotent.ca/images/dlx_1.png&#34; /&gt;
    
    
    &lt;figcaption&gt;
        &lt;h4&gt;Flow diagram&lt;/h4&gt;
        
    &lt;/figcaption&gt;
    
&lt;/figure&gt;


&lt;p&gt;The whole flow looks like this:&lt;/p&gt;


&lt;figure &gt;
    
        &lt;img src=&#34;http://blog.idempotent.ca/images/dlx_2.png&#34; /&gt;
    
    
    &lt;figcaption&gt;
        &lt;h4&gt;Flow diagram&lt;/h4&gt;
        
    &lt;/figcaption&gt;
    
&lt;/figure&gt;


&lt;h1 id=&#34;implementation-testing-strategy-and-deployment-saga:f116081bb98b0fd4ebe93c08e96b2c34&#34;&gt;Implementation, Testing Strategy and Deployment saga&lt;/h1&gt;

&lt;h2 id=&#34;implementation:f116081bb98b0fd4ebe93c08e96b2c34&#34;&gt;Implementation&lt;/h2&gt;

&lt;p&gt;Implementation is probably the most straight-forward phase of the project once we have the design on paper.  The only obstacle is that the library we use for writing rabbitmq consumers (sparkplug) does not support declaring queues with extra parameters, and the DLX related parameters: &lt;code&gt;x-dead-letter-exchange&lt;/code&gt; &lt;code&gt;x-dead-letter-routing-key&lt;/code&gt;, and &lt;code&gt;x-message-ttl&lt;/code&gt; are all &amp;ldquo;extra parameters&amp;rdquo; according to &lt;code&gt;amqplib&lt;/code&gt;, which is used by sparkplug. To solve this, I sent this &lt;a href=&#34;https://github.com/ojacobson/sparkplug/pull/10/files&#34;&gt;PR&lt;/a&gt; to sparkplug, so it recognizes extra parameters and pass them down to amqp library.&lt;/p&gt;

&lt;p&gt;Another road block appeared when we ran the system on our dev images for the first time. The underlying amqplib would error out on startup. Upon closer investigation, it appeared the error happened while talking to rabbitmq and the amqplib can&amp;rsquo;t handle certain rabbitmq frames. So I went searching for the amqp project, only to find out that it was deprecated &lt;a href=&#34;https://pypi.python.org/pypi/amqplib&#34;&gt;long ago&lt;/a&gt;. Fortunately, there&amp;rsquo;s a fork of the library &lt;a href=&#34;https://pypi.python.org/pypi/amqp&#34;&gt;amqp&lt;/a&gt; that&amp;rsquo;s maintained by the reputable &lt;a href=&#34;http://www.celeryproject.org/&#34;&gt;Celery project&lt;/a&gt;. It&amp;rsquo;s has API compatibility with amqplib and appeared to be a drop-in replacement. We dropped it in and everything seems to work. Reading the online literature, it seems to be the case that the old library does not handle the &lt;code&gt;TTL&lt;/code&gt; amqp extension.&lt;/p&gt;

&lt;h2 id=&#34;testing-strategy:f116081bb98b0fd4ebe93c08e96b2c34&#34;&gt;Testing Strategy&lt;/h2&gt;

&lt;p&gt;So, since the 3rd party API timeout is an edge case, they did not provide a way trigger this behaviour the same way we can trigger, say, a declined transaction. We could fake the URL for the 3rd party service in DNS or &lt;code&gt;/etc/hosts&lt;/code&gt; or we can change the SDK to change the base url for their API to somewhere else and cause a timeout that way, but neither is ideal. The biggest disadvantage is that we have no way of getting a request out of the retry state.&lt;/p&gt;

&lt;p&gt;Eventually, we decided to &lt;a href=&#34;http://en.wikipedia.org/wiki/Man-in-the-middle_attack&#34;&gt;MITM&lt;/a&gt; ourselves :) We can write a simple proxy server, and for the most part, it&amp;rsquo;s going to be a pass-through, but on certain requests, we intercept it and return an unknown error (500 series with specific response body).  To trigger it, we set the checkout amount to &lt;code&gt;$666&lt;/code&gt;, and in the proxy, we keep an internal counter based on the checkout&amp;rsquo;s unique id, and increment the counter every time it&amp;rsquo;s retried, and then we can set a max retry threshold in the proxy so the proxy becomes a pass through again if the max retry threshold is reached.&lt;/p&gt;

&lt;p&gt;We used this small nifty library &lt;a href=&#34;https://github.com/allfro/pymiproxy&#34;&gt;pymiproxy&lt;/a&gt; as a base for our proxy server. It turns out the proxy is pretty straight-forward as well, and a big shout-out to the author of pymiproxy.&lt;/p&gt;

&lt;h2 id=&#34;deployment:f116081bb98b0fd4ebe93c08e96b2c34&#34;&gt;Deployment&lt;/h2&gt;

&lt;p&gt;Everything until now is like a cake walk. Sure, there are some problems with the underlying libraries but that requires patching but they were quite easy to identify and fix. Deployment, on the other hand, has been like riding on the &lt;a href=&#34;https://www.youtube.com/watch?v=Mgsbau5qkTE&#34;&gt;Behemoth in Canada&amp;rsquo;s Wonderland&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;First of all, while getting the code onto the testing environment, we encountered the first gremlin. The staging is running on the exact same version of rabbitmq and the exact same configuration. However, on staging, when a message is published on the DLQ (&lt;code&gt;Qa&lt;/code&gt;) in our example, after &lt;code&gt;TTL&lt;/code&gt;, the message would simply disappear and did not get routed to &lt;code&gt;Qb&lt;/code&gt;. What&amp;rsquo;s worse, sometimes even &lt;code&gt;Qa&lt;/code&gt; is completely gone after the message is dropped on the floor! This is terribly frustrating. The queue is declared as durable, and so is the exchange. I even did a side-by-side comparison of the sparkplug log output to see if anything is different. Well, there was! The declaration sequence is different between staging and dev. On dev, the dead-letter exchange is declared before &lt;code&gt;Qa&lt;/code&gt; which specifies &lt;code&gt;x-dead-letter-exchange&lt;/code&gt;. That makes sense! Reading the &lt;a href=&#34;https://github.com/ojacobson/sparkplug/blob/master/sparkplug/config/__init__.py#L57-L77&#34;&gt;sparkplug code&lt;/a&gt;, it calculates the dependencies between queues, exchanges, bindings and consumers to determine the order of which they should be declared. However, our modification that enabled sparkplug to pass down DLX, but sparkplug has no idea that the queue depends on the DLX! Based on this observation, I cooked up another &lt;a href=&#34;https://github.com/freshbooks/sparkplug/pull/2/files&#34;&gt;PR&lt;/a&gt; such that if DLX is specified, make sure we make the DLX a dependency of the queue so the exchange gets declared before it. Did a few tests locally, and hey, it appears to be working!&lt;/p&gt;

&lt;p&gt;Just as I thought my shrewed observation has solved this major mystery, the second day, people reported that the queue started go AWOL again! Grumbled, I sat down and read carefully the documentation on &lt;a href=&#34;https://www.rabbitmq.com/dlx.html&#34;&gt;dead-letter exchange&lt;/a&gt; and discovered this:&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;Note that the exchange does not have to be declared when the queue is declared, but it should exist by the time messages need to be dead-lettered; if it is missing then, the messages will be silently dropped.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;This invalidates my previous hypothesis that the out-of order declaration was the root cause of the problem. There we go, I was back to square one.&lt;/p&gt;

&lt;p&gt;At this time, I wanted to try a different approach. Instead of forming hypothesis from observation, I searched for evidence. I went on the server, and start to look at the logs to search for any traces that can be salvaged. The rabbitmq log is very noisy with all the connection messages. Once in a while you get something remotely interesting, but they were not relevant. Then I manually published a message on the queue, and waited for the message and queue to disappear. Lo and behold, there&amp;rsquo;s something in the logs!&lt;/p&gt;

&lt;script src=&#34;//gist.github.com/kevinjqiu/e626bcc40eb803214968.js&#34;&gt;&lt;/script&gt;

&lt;p&gt;There&amp;rsquo;s our smoking gun! Further gooling revealed &lt;a href=&#34;http://lists.rabbitmq.com/pipermail/rabbitmq-discuss/2012-April/019368.html&#34;&gt;this&lt;/a&gt;. That&amp;rsquo;s EXACTLY our issue! And the version of rabbitmq we&amp;rsquo;re using is EXACTLY 2.8.1! What a relief! We just need to upgrade to 2.8.2 and everything would be fine.&lt;/p&gt;

&lt;p&gt;So there I was, preparing an internal repository to host the rpm (since we&amp;rsquo;re on a hopelessly old version of CentOS), and prepared puppet changes for the new version. Deployed on all the environments and sent it off to QA. QA ok&amp;rsquo;ed it just before the weekend and life is good again.&lt;/p&gt;

&lt;p&gt;Except, not at all! There are a few more surprises waiting for us before the end of tunnel. First of all, our partner whose payment API we&amp;rsquo;re integrating has received an imminent DDOS threat, and fearing not having a retry mechanism would caused a huge burden for us and our support crew, we need to get this out to production ASAP. After pulling some levers and convincing our ops team that this is a relatively low risk point release upgrade (from rabbitmq 2.8.1 to 2.8.2), we got the green light and ops are on their way upgrading rabbitmq. Everything seemed to be going alone well, until, when we switched all components to point to the hosts that&amp;rsquo;s on the new rabbitmq, our app stopped working! Phone calls flooded in, alerts set off everywhere and on top of that, even the streets in front of our building had a couple of emergency vehicles passing by! Goodness, what have we done! Ops quickly rolled it back, and we were left dumbfounded by this yet another surprise.&lt;/p&gt;

&lt;p&gt;Analyzing the logs from various components during the downtime, it appeared the components talking to rabbitmq have timed out trying to publish messages. We checked that the hosts can indeed reach each other, all the names can be resolved and firewall rules are not in effect. So, we hit a wall again.&lt;/p&gt;

&lt;p&gt;On the second day, we regrouped, and experimented on the backup data centre. We upgraded, and tried to put a message on the queue, and guess what, it blocked! It&amp;rsquo;s great that we reproduced the issue. Since the staging environment worked just fine, I captured &lt;code&gt;strace&lt;/code&gt; on the staging environment, and ops did the same on prod, and compared the output. It&amp;rsquo;s pretty clear that the process was waiting on reading socket (syscall was &lt;code&gt;recvfrom(...)&lt;/code&gt;) and it blocked. Then I did &lt;code&gt;tcpdump&lt;/code&gt; and compared that with the output on prod, and also proven to be futile.&lt;/p&gt;

&lt;p&gt;In that afternoon, our fortune suddenly took a positive turn, when one of the ops discovered this in the logs while starting the new rabbitmq:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;=INFO REPORT==== 29-Apr-2015::14:51:09 ===
Disk free space limit now exceeded. Free bytes:19033128960 Limit:50634379264
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;So, this version of rabbitmq started to check free disk space, and &lt;strong&gt;blocks&lt;/strong&gt; incoming message if the disk space is deemed inadequate! Wow, this is so unexpected that we all laughed when we discovered this to be the root cause. However, for me, I need to be convinced that why it wasn&amp;rsquo;t an issue for staging environment.&lt;/p&gt;

&lt;p&gt;So I cloned rabbitmq git repository, and looked for anything that&amp;rsquo;s related to &lt;code&gt;disk_free_limit&lt;/code&gt;. Finally, I found this:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-erlang&#34;&gt;{disk_free_limit, {mem_relative, 1.0}},
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;from &lt;a href=&#34;https://github.com/rabbitmq/rabbitmq-server/blob/rabbitmq_v2_8_2/ebin/rabbit_app.in#L22&#34;&gt;here&lt;/a&gt;. Since we&amp;rsquo;re using the default config, this is in effect, and it essentially says &amp;ldquo;stop accepting message if the disk space is not at least as big as the RAM&amp;rdquo;, and it just so happens on prod, we have 50G of RAM and therefore, require at least 50G of free space for rabbitmq to start accepting messages!&lt;/p&gt;

&lt;p&gt;Reading the rabbitmq 2.8.2 release notes, and they &lt;strong&gt;did&lt;/strong&gt; &lt;a href=&#34;https://www.rabbitmq.com/release-notes/README-2.8.2.txt&#34;&gt;mention&lt;/a&gt; this &amp;ldquo;feature&amp;rdquo;, but failed to mention that it could block your connection &lt;strong&gt;forever&lt;/strong&gt; and bring your site down&amp;hellip;&lt;/p&gt;

&lt;h1 id=&#34;conclusion:f116081bb98b0fd4ebe93c08e96b2c34&#34;&gt;Conclusion&lt;/h1&gt;

&lt;p&gt;There you go.  That&amp;rsquo;s our adventure implementing and deploying delayed retry using rabbitmq&amp;rsquo;s DLX and TTL. It&amp;rsquo;s frustrating and rewarding at the same time, and there&amp;rsquo;s definitely something we can all take home with:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Software is hard, even for experienced developers and ops&lt;/li&gt;
&lt;li&gt;Gather all the evidences before forming hypothesis on the root cause&lt;/li&gt;
&lt;li&gt;Certainly, read the docs thoroughly before hypothesizing&lt;/li&gt;
&lt;li&gt;Expect problems when switching environments&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;I haven&amp;rsquo;t been blogging for a while, partly because life catches up, and partly because I&amp;rsquo;ve been less than disciplined but I spent some time writing down this experience worth remembering :)&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Realtime notification delivery using rabbitmq</title>
      <link>http://blog.idempotent.ca/2012/04/07/realtime-notification-delivery-using-rabbitmq/</link>
      <pubDate>Sat, 07 Apr 2012 16:50:00 +0000</pubDate>
      
      <guid>http://blog.idempotent.ca/2012/04/07/realtime-notification-delivery-using-rabbitmq/</guid>
      <description>

&lt;p&gt;Our company has &amp;ldquo;hack-off&amp;rdquo; days once a while, where we developers get to choose whatever we would like to work on and present it to the entire company by the end of the day. I have been hearing this &lt;a href=&#34;http://en.wikipedia.org/wiki/WebSocket&#34;&gt;websocket&lt;/a&gt; buzz for a while now and would like to build something interesting with it.&lt;/p&gt;

&lt;h2 id=&#34;websocket:3652469de01842bf96882033c0b91b72&#34;&gt;WebSocket&lt;/h2&gt;

&lt;p&gt;Websocket is a persistent bi-directional connection between the browser and the server. With websocket, web browser can post message to the server, but what&amp;rsquo;s more interesting is that the server is able to push messages to the client (browser). This breaks away from the traditional web application request/response model. Traditionally, the client makes the request and waits for the server to give an answer. AJAX is revolutionary, but essentially, it&amp;rsquo;s still the same model: the client asks the server whether there&amp;rsquo;s anything interesting, but not the other way around. With websocket, the server suddenly becomes more involved and able to deliver more engaged user experience.&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;http://www.freshbooks.com/&#34;&gt;Our company&lt;/a&gt; provides web application for online invoicing. The web application allows users to create clients, create invoices, send them to clients, and so on. Each one of these are &amp;ldquo;events&amp;rdquo; which gets sent to &lt;a href=&#34;http://www.rabbitmq.com/&#34;&gt;RabbitMQ&lt;/a&gt;. We then have a plethora of RabbitMQ consumers that read messages off the queue and do interesting stuff with them.&lt;/p&gt;

&lt;h2 id=&#34;proof-of-concept:3652469de01842bf96882033c0b91b72&#34;&gt;Proof of concept&lt;/h2&gt;

&lt;p&gt;For this hack-off, my goal is to write a RabbitMQ consumer that reads the messages off the message queue, and deliver (notify) them to the front-end using websocket.&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;http://reminiscential.files.wordpress.com/2012/04/websocket-1.png&#34;&gt;&lt;img src=&#34;http://reminiscential.files.wordpress.com/2012/04/websocket-1.png?w=300&#34; alt=&#34;&#34; title=&#34;architecture&#34; width=&#34;300&#34; height=&#34;181&#34; class=&#34;aligncenter size-medium wp-image-292&#34; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;I&amp;rsquo;ve heard good things about &lt;a href=&#34;http://www.tornadoweb.org&#34;&gt;Tornado&lt;/a&gt;. Having read their docs on &lt;a href=&#34;http://www.tornadoweb.org/documentation/websocket.html&#34;&gt;websocket request handler&lt;/a&gt;, I felt it&amp;rsquo;s straightforward enough for me, so I chose Tornado as my backend.&lt;/p&gt;

&lt;h2 id=&#34;pika:3652469de01842bf96882033c0b91b72&#34;&gt;Pika&lt;/h2&gt;

&lt;p&gt;One problem arises, though: The tornado server will run as a regular server, waiting for incoming websocket connections. The RabbitMQ consumer also needs to be in the same process event loop, waiting for incoming messages from the message queue. I looked into a few solutions such as &lt;a href=&#34;http://pypi.python.org/pypi/sparkplug/&#34;&gt;sparkplug&lt;/a&gt; and &lt;a href=&#34;http://pypi.python.org/pypi/stormed-amqp/0.1&#34;&gt;stormed-amqp&lt;/a&gt;, neither seem to be a good hit here. Finally, I stumbled on &lt;a href=&#34;https://github.com/pika/pika&#34;&gt;Pika&lt;/a&gt;. It comes with a Tornado event loop adapter, which allows rabbitmq consumer and websocket handlers to run inside the same event loop. Perfect.&lt;/p&gt;

&lt;p&gt;The entry point looks like this:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;application = tornado.web.Application([
    (r&#39;/ws&#39;, handlers.MyWebSocketHandler),
])

def main():
    pika.log.setup(color=True)

    io_loop = tornado.ioloop.IOLoop.instance()

    # PikaClient is our rabbitmq consumer
    pc = client.PikaClient(io_loop)
    application.pc = pc
    application.pc.connect()

    application.listen(8888)
    io_loop.start()
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;class MyWebSocketHandler(tornado.websocket.WebSocketHandler):

    def open(self, *args, **kwargs):
        pika.log.info(&amp;quot;WebSocket opened&amp;quot;)

    def on_close(self):
        pika.log.info(&amp;quot;WebSocket closed&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;That was straightforward. However, I&amp;rsquo;m faced with the problem of how to make the amqp consumer notify websocket handlers when we receive a message from the message queue. We cannot get the handler instances from the tornado application object. Note, each websocket connection has a corresponding &lt;code&gt;MyWebSocketHandler&lt;/code&gt; instance. The instances are not available from the application object. Maybe there&amp;rsquo;s a way to get them by other means, but I&amp;rsquo;m not familiar with the tornado API enough to know that.&lt;/p&gt;

&lt;p&gt;However, from the handler, we do get the &lt;code&gt;application&lt;/code&gt; object, and because we attached pika_client (our amqp consumer) to the application, we have access to it inside our socket handler. Hey, how about registering the handler with the client when the websocket is connected, and let the client &amp;ldquo;notify&amp;rdquo; the handler when events are received? Hey, isn&amp;rsquo;t that the &lt;a href=&#34;http://en.wikipedia.org/wiki/Observer_pattern&#34;&gt;observer pattern&lt;/a&gt;?&lt;/p&gt;

&lt;p&gt;Here&amp;rsquo;s the code:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;class MyWebSocketHandler(websocket.WebSocketHandler):

    def open(self, *args, **kwargs):
        self.application.pc.add_event_listener(self)
        pika.log.info(&amp;quot;WebSocket opened&amp;quot;)

    def on_close(self):
        pika.log.info(&amp;quot;WebSocket closed&amp;quot;)
        self.application.pc.remove_event_listener(self)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Now, our &lt;code&gt;PikaClient&lt;/code&gt; object need to support &lt;code&gt;add_event_listener()&lt;/code&gt; and &lt;code&gt;remove_event_listener()&lt;/code&gt; methods.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;class PikaClient(object):

    def __init__(self, io_loop):
        pika.log.info(&#39;PikaClient: __init__&#39;)
        self.io_loop = io_loop

        self.connected = False
        self.connecting = False
        self.connection = None
        self.channel = None

        self.event_listeners = set([])

    def connect(self):
        if self.connecting:
            pika.log.info(&#39;PikaClient: Already connecting to RabbitMQ&#39;)
            return

        pika.log.info(&#39;PikaClient: Connecting to RabbitMQ&#39;)
        self.connecting = True

        cred = pika.PlainCredentials(&#39;guest&#39;, &#39;guest&#39;)
        param = pika.ConnectionParameters(
            host=&#39;localhost&#39;,
            port=5672,
            virtual_host=&#39;/&#39;,
            credentials=cred
        )

        self.connection = TornadoConnection(param,
            on_open_callback=self.on_connected)
        self.connection.add_on_close_callback(self.on_closed)

    def on_connected(self, connection):
        pika.log.info(&#39;PikaClient: connected to RabbitMQ&#39;)
        self.connected = True
        self.connection = connection
        self.connection.channel(self.on_channel_open)

    def on_channel_open(self, channel):
        pika.log.info(&#39;PikaClient: Channel open, Declaring exchange&#39;)
        self.channel = channel
        # declare exchanges, which in turn, declare
        # queues, and bind exchange to queues

    def on_closed(self, connection):
        pika.log.info(&#39;PikaClient: rabbit connection closed&#39;)
        self.io_loop.stop()

    def on_message(self, channel, method, header, body):
        pika.log.info(&#39;PikaClient: message received: %s&#39; % body)
        self.notify_listeners(event_factory(body))

    def notify_listeners(self, event_obj):
        # here we assume the message the sourcing app
        # post to the message queue is in JSON format
        event_json = json.dumps(event_ostener in self.event_listeners:
            listener.write_message(event_json)
            pika.log.info(&#39;PikaClient: notified %s&#39; % repr(listener))

    def add_event_listener(self, listener):
        self.event_listeners.add(listener)
        pika.log.info(&#39;PikaClient: listener %s added&#39; % repr(listener))

    def remove_event_listener(self, listener):
        try:
            self.event_listeners.remove(listener)
            pika.log.info(&#39;PikaClient: listener %s removed&#39; % repr(listener))
        except KeyError:
            pass
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;I left out the queue setup code here for brevity. &lt;code&gt;on_message&lt;/code&gt; callback is called when the consumer gets a message from the queue. The client, in turn, notifies all registered websocket handlers. Obviously, in real applications, you may want to do some kind of credentials and filtering, so the right message get to the right receiver. Then we simply call &lt;code&gt;handler.write_message()&lt;/code&gt;, so the message gets relayed to the front-end&amp;rsquo;s websocket.onmessage callback.&lt;/p&gt;

&lt;p&gt;Here&amp;rsquo;s some front-end code:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-javascript&#34;&gt;(function($){
    $(document).ready(function() {
        var ws = new WebSocket(&#39;ws://localhost:8888/ws&#39;);
        ws.onmessage = function(evt){
            alert(evt.data);
        }
    });
})(jQuery);
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Yes, we simply echo the message back. For the hackoff, I did parse the data, render a slightly more detailed notification message, and display the notification using jquery-toaster.&lt;/p&gt;

&lt;h2 id=&#34;conclusion:3652469de01842bf96882033c0b91b72&#34;&gt;Conclusion&lt;/h2&gt;

&lt;p&gt;This is my first stab at websocket and the tornado web framework. I&amp;rsquo;m not an expert on either subject, so chances are there are better ways to achieve the same result.&lt;/p&gt;

&lt;p&gt;I think websocket is a very interesting technology. It opens a wide range of possibilities for more interactive and engaging web applications. Our web application is of traditional architecture: server renders most of the page, and every request involves page loads. Having a websocket may not be very beneficial as the application doesn&amp;rsquo;t have that much of user interaction. My hackoff is more of a proof of concept. However, if the application is a one-page web app (no full page reloads), the websocket model works very well.&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>